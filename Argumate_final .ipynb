{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "![architecure diagram.jpg](data:image/jpeg;base64,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)"
      ],
      "metadata": {
        "id": "F72k-dwaK-ss"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "goal manager+context manager+evaluator+guard rail+continuos learn integration"
      ],
      "metadata": {
        "id": "P7XnrnPeI7oT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!fusermount -u /content/drive 2>/dev/null || true\n",
        "!rm -rf /content/drive\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\", force_remount=True)\n"
      ],
      "metadata": {
        "id": "Sc8oHEjANPz4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ceb9287-4216-45c2-a99e-914a022bad44"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "JaNtE375Z7DI"
      },
      "outputs": [],
      "source": [
        "!pip install -q sentence-transformers tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "HkSYfrNuZ8tC"
      },
      "outputs": [],
      "source": [
        "import json, os, pickle\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "tqdm.pandas()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "n_xCHDwBZ-XC"
      },
      "outputs": [],
      "source": [
        "\n",
        "BASE = \"/content/drive/MyDrive/Argumate/data\"\n",
        "train_path = os.path.join(BASE, \"train.jsonl\")\n",
        "dev_path   = os.path.join(BASE, \"dev.jsonl\")\n",
        "test_path  = os.path.join(BASE, \"test.jsonl\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "O-lH_wLDaAg6"
      },
      "outputs": [],
      "source": [
        "\n",
        "def load_jsonl(path):\n",
        "    data = []\n",
        "    with open(path, 'r', encoding='utf-8') as f:\n",
        "        for line in f:\n",
        "            if line.strip():\n",
        "                data.append(json.loads(line))\n",
        "    return pd.DataFrame(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "QnzYlExaaGlW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f74dff7c-de4f-44d5-e61d-94fe5a49acd7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading datasets (this may take a few seconds)...\n",
            "Raw shapes -> train: (7100, 17) dev: (1380, 17) test: (2998, 17)\n",
            "Columns (train): ['itemid', 'languageisocode', 'respondent', 'branch', 'date', 'docname', 'importance', 'conclusion', 'judges', 'text', 'violated_articles', 'violated_paragraphs', 'violated_bulletpoints', 'non_violated_articles', 'non_violated_paragraphs', 'non_violated_bulletpoints', 'violated']\n"
          ]
        }
      ],
      "source": [
        "print(\"Loading datasets (this may take a few seconds)...\")\n",
        "train_df = load_jsonl(train_path)\n",
        "dev_df   = load_jsonl(dev_path)\n",
        "test_df  = load_jsonl(test_path)\n",
        "\n",
        "\n",
        "print(\"Raw shapes ->\", \"train:\", train_df.shape, \"dev:\", dev_df.shape, \"test:\", test_df.shape)\n",
        "print(\"Columns (train):\", train_df.columns.tolist()[:50])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "9HoqRcGEaLUL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "89eb782e-8436-4054-b6a1-c2ba916582f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved raw checkpoints to /content/drive/MyDrive/Argumate/checkpoints\n"
          ]
        }
      ],
      "source": [
        "checkpoint_dir = \"/content/drive/MyDrive/Argumate/checkpoints\"\n",
        "os.makedirs(checkpoint_dir, exist_ok=True)\n",
        "train_df.to_pickle(os.path.join(checkpoint_dir, \"train_raw.pkl\"))\n",
        "dev_df.to_pickle(os.path.join(checkpoint_dir, \"dev_raw.pkl\"))\n",
        "test_df.to_pickle(os.path.join(checkpoint_dir, \"test_raw.pkl\"))\n",
        "print(\"Saved raw checkpoints to\", checkpoint_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "yehXhos7aQ_a"
      },
      "outputs": [],
      "source": [
        "relevant_cols = ['itemid', 'text', 'conclusion', 'violated_articles']\n",
        "for df,name in [(train_df,'train'), (dev_df,'dev'), (test_df,'test')]:\n",
        "    missing = [c for c in relevant_cols if c not in df.columns]\n",
        "    if missing:\n",
        "        raise ValueError(f\"Missing columns in {name}: {missing}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "az_Fw3N-aSEN"
      },
      "outputs": [],
      "source": [
        "\n",
        "train_df_clean = train_df[relevant_cols].copy()\n",
        "dev_df_clean   = dev_df[relevant_cols].copy()\n",
        "test_df_clean  = test_df[relevant_cols].copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "snqjZ42aaT_5"
      },
      "outputs": [],
      "source": [
        "\n",
        "train_df_clean.dropna(subset=['text','conclusion'], inplace=True)\n",
        "dev_df_clean.dropna(subset=['text','conclusion'], inplace=True)\n",
        "test_df_clean.dropna(subset=['text','conclusion'], inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "38m-mZSmaXGU"
      },
      "outputs": [],
      "source": [
        "\n",
        "for df in (train_df_clean, dev_df_clean, test_df_clean):\n",
        "    df['text'] = df['text'].astype(object)\n",
        "    df['conclusion'] = df['conclusion'].astype(str)\n",
        "\n",
        "    df['violated_articles'] = df['violated_articles'].astype(str)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "VZub0D7naX8N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c370355-35c3-4049-f4d5-05a99cb95e13"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 7100/7100 [00:00<00:00, 16502.27it/s]\n",
            "100%|| 1380/1380 [00:00<00:00, 24227.58it/s]\n",
            "100%|| 2998/2998 [00:00<00:00, 32533.75it/s]\n"
          ]
        }
      ],
      "source": [
        "def flatten_text(x):\n",
        "    if isinstance(x, list):\n",
        "        try:\n",
        "            return \" \".join([t for t in x if isinstance(t, str)])\n",
        "        except:\n",
        "            return str(x)\n",
        "    return str(x)\n",
        "\n",
        "for df in (train_df_clean, dev_df_clean, test_df_clean):\n",
        "    df['text_clean'] = df['text'].progress_apply(flatten_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "8z0D78qxaaSY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96589ddc-d3b4-4e3e-be22-5ffb3df0553d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved cleaned checkpoints to /content/drive/MyDrive/Argumate/checkpoints\n"
          ]
        }
      ],
      "source": [
        "train_df_clean.to_pickle(os.path.join(checkpoint_dir, \"train_clean.pkl\"))\n",
        "dev_df_clean.to_pickle(os.path.join(checkpoint_dir, \"dev_clean.pkl\"))\n",
        "test_df_clean.to_pickle(os.path.join(checkpoint_dir, \"test_clean.pkl\"))\n",
        "print(\"Saved cleaned checkpoints to\", checkpoint_dir)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "cYiEDHI5acqj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 375
        },
        "outputId": "c92fa890-7e79-4983-9859-d98bb71efd68"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Train (clean) sample rows: (7100, 5)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "       itemid                                         conclusion  \\\n",
              "0   001-60714  Violation of Art. 6-1;Non-pecuniary damage - f...   \n",
              "1  001-100920                                       Inadmissible   \n",
              "\n",
              "  violated_articles                                         text_clean  \n",
              "0             ['6']  The applicant was born in 1943 and lives in La...  \n",
              "1                []  The applicant, Mr Panayiotis Panayi, is a Cypr...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-75babc97-d533-493a-b5a4-a9f437d6a00d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>itemid</th>\n",
              "      <th>conclusion</th>\n",
              "      <th>violated_articles</th>\n",
              "      <th>text_clean</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>001-60714</td>\n",
              "      <td>Violation of Art. 6-1;Non-pecuniary damage - f...</td>\n",
              "      <td>['6']</td>\n",
              "      <td>The applicant was born in 1943 and lives in La...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>001-100920</td>\n",
              "      <td>Inadmissible</td>\n",
              "      <td>[]</td>\n",
              "      <td>The applicant, Mr Panayiotis Panayi, is a Cypr...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-75babc97-d533-493a-b5a4-a9f437d6a00d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-75babc97-d533-493a-b5a4-a9f437d6a00d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-75babc97-d533-493a-b5a4-a9f437d6a00d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-0943052e-97f2-492f-b022-8f9b299b9172\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0943052e-97f2-492f-b022-8f9b299b9172')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-0943052e-97f2-492f-b022-8f9b299b9172 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"print(f\\\"\\\\nSummary: train={num_train}, dev={num_dev}, test={num_test}, train 'violated' column sum: {num_with_violation_flag}\\\")\",\n  \"rows\": 2,\n  \"fields\": [\n    {\n      \"column\": \"itemid\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"001-100920\",\n          \"001-60714\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"conclusion\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Inadmissible\",\n          \"Violation of Art. 6-1;Non-pecuniary damage - financial award;Costs and expenses partial award\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"violated_articles\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"[]\",\n          \"['6']\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text_clean\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"The applicant, Mr Panayiotis Panayi, is a Cypriot national who was born in 1954 and lives in Limassol. The applicant has brought the present application in his capacity as administrator of his deceased father's estate. On 16 March 1990 a civil action was brought before the District Court of Paphos by, inter alia, the applicant, in his capacity as administrator of his deceased father's estate, against four members of his family and the Attorney-General of the Republic concerning the transfer and registration of certain plots of land. On 10 March 1999 the action was settled by way of friendly settlement. On 28 January 2000 the applicant, in his capacity as administrator of his deceased father's estate, brought another civil action before the District Court of Paphos against four members of his family and the Attorney-General (\\u201cthe defendants\\u201d) seeking the transfer and registration of a plot of land in his name. On 18 July 2006 the District Court upheld the applicant's claim in part. It issued an order for the annulment of the registration of the plot in the names of defendants nos. 1\\u20134 and further, an order for the restoration/reinstatement/re-registration of the property in the applicant's grandfather's name. On 28 August 2006 the applicant lodged an appeal with the Supreme Court, claiming that the District Court should have ordered the transfer and registration of the plot in his name and also that he should have been awarded general, special and exemplary damages (appeal no. 353/06). The defendants also appealed against the first-instance judgment (appeal no. 261/2006). On 11 February 2009 the Supreme Court dismissed the applicant's appeal but upheld the respondents' appeal. It set aside the District Court's judgment and annulled the orders that had been issued. Article 30 \\u00a7 2 of the Constitution safeguards the right to a fair trial. It provides as follows, in so far as relevant: \\u201cIn the determination of his civil rights and obligations or of any criminal charge against him, every person is entitled to a fair and public hearing within a reasonable time by an independent, impartial and competent court established by law. ...\\u201d. In order to ensure the effective protection/application at domestic level of the principle of the right to a trial within a \\u201creasonable time\\u201d and to provide effective domestic remedies in relation to breaches of that right, Parliament passed the Law Providing For Effective Remedies for Exceeding the Reasonable Time Requirement for the Determination of Civil Rights and Obligations, Law 2(I)/2010. This Law entered into force on 5 February 2010 and applies to complaints concerning the length of proceedings in all civil and administrative cases. The relevant parts of Law 2(I)/2010 provide as follows: \\u201cWhereas Article 6.1 of the European Convention on Human Rights and Article 30.2 of the Constitution of the Republic of Cyprus safeguard the right to determination of civil rights and obligations within a reasonable time, And whereas in a number of individual recourses against Cyprus the European Court of Human Rights found violations of Article 6.1 of the Convention in that the civil rights and obligations of the applicants in civil cases and recourses had not been determined by the Cyprus Courts within a reasonable time as required by the above-mentioned Article and also found a violation of Article 13 in that there were no effective remedies in the Republic as required by Article 13 regarding the applicants' allegations of violation of the requirement of Article 6.1, And whereas the Republic's obligation under Article 46 of the Convention to abide by the said Judgments of the European Court of Human Rights is being supervised by the Committee of Ministers of the Council of Europe and entails the adoption of measures preventing future violations as those found by the Court in the above-mentioned individual applications, And whereas a number of individual recourses against the Republic are pending before the European Court of Human Rights for violation of Articles 6.1 and 13 of the Convention regarding determination of the applicants' civil rights and obligations in civil cases and recourses, And whereas the Republic is bound by Article 1 of the Convention to secure the rights of the Convention including the right to effective domestic remedies for violation of the right to determination of civil rights and obligations within a reasonable time.\\u201d \\u201c(1) This Law applies with regard to the violation of the right of persons to determination of their civil rights or obligations within a reasonable time in District Court or Supreme Court cases, whether they are pending at any stage at first instance or on appeal or have been concluded. (2) A person who alleges that in a case to which this law applies his right to determination of his civil rights or obligations within a reasonable time has been violated has a right to have recourse to the legal proceedings provided for in the present Law for obtaining the remedies provided by it. (3) Violation, in a court case to which this Law applies, of the right of a person to determination of his civil rights or obligations within a reasonable time and the granting of the remedies provided for in this Law for the violation, is determined by courts vested with competence under this Law.\\u201d \\u201cThe right to determination of civil rights and obligations within a reasonable time in a case to which this Law applies is actionable, and the person who alleges that he or she is a victim of a violation of the right may have recourse to the court with jurisdiction by way of action against the Republic by virtue of this Law, claiming the remedies for the violation provided for in this Law.\\u201d \\u201c(1) An action under section 4 may be instituted for violation of the right in a case which has been concluded with a final court judgment concerning violation of the right at any stage of the case, i (2) An action under section 4 may also be instituted for violation of the right in a case concluded with a judicial decision before the date of entry into force of the present Law, or in which execution of a judgment given before the date of entry into force is pending, provided that the action is instituted within one year of the date of entry into force or the date of the ed within the above time-limit.\\u201d \\u201c(1) Irrespective of the provisions of any other law, the court which is granted jurisdiction by this Law to examine and determine an action under sections 4 and 5 for a violation of the right to determination of civil rights or obligations within a reasonable time in cases which were concluded with the issuance of a final judicial decision are: (a) in relation to district court cases, the administrative President of any District Court who, in a case in which, according to the action, the plaintiff's right to determination of his civil rights or obligations within a reasonable time has been violated, did not exercise duties at the court in which the case was pending and did not participate at any stage of its examination, or in the event there is no administrative president who did not exercise duties at the court in which the case was pending and did not participate at any stage of its examination, the next senior president of the district court or another judge who fulfils the above, as the Supreme Court may in the event designate. (b) in relation to Supreme Court cases, three judges of the Supreme Court, as the Supreme Court may in the event designate. (2) The judgment of the court with jurisdiction under sub-section (b) of paragraph (1)is final and is not subject to appeal.\\u201d \\u201c(1) Without prejudice to the right to institute an action under sections 4 and 5, a person who is a party in a pending case to which this law applies has the right at any stage of the proceedings whilst the case is pending to have recourse to the legal remedies provided for in sub-paragraph (2) in relation to the allegation that in the case his right to determination of civil rights or obligations within a reasonable time has been violated. (2) For the purposes of sub-section (1) a party who alleges that there has been a violation of his right to determination of his civil rights or obligations within a reasonable time in a pending district court or Supreme Court case may at any stage of those proceedings have recourse by instituting an originating application against the Republic to the court with jurisdiction as provided by section 8 for the examination of the allegation and the granting of remedies for the violation provided for by this Law and for the issuance of a decision on these matters. (3) the provisions of paragraphs (1) and (2) are applied also in relation to cases which were pending at any stage at the date of entry into force of the present Law. (4) There is no suspension or adjournment of any procedure in a pending case by reason of an application made under this section or pending the conclusion of its examination. ...\\u201d \\u201c(1) Irrespective of the provisions of any other law, the court which is hereby granted jurisdiction to examine and determine an allegation and to grant remedies in an originating application under section 7 is: (a) in relation to a district court case which is pending at that stage before a district court, the administrative President of any District Court who does not exercise duties at the court in which the case is pending and who did not participate in any stage of its examination, or in the event there is no administrative president who did not exercise duties at the court in question and did not participate in any stage of its examination, the next senior president of the district court or another judge who fulfils the above, as the Supreme Court may in the event designate. (b) in relation to a district court case which is pending at that stage before the Supreme Court or to a Supreme Court case which is pending before the court in question at any stage, three judges of the Supreme Court, as the Supreme Court may in the event designate. Provided that by virtue of this paragraph under this section judges of the Supreme Court who did not participate at any stage of the case will be designated. (2) The judgment of the court with jurisdiction, under sub-section (b) of paragraph (1), is final and is not subject to appeal.\\u201d \\u201cIn an action under sections 4 and 5 and in an originating application under sections 7 and 8, the court with jurisdiction gives judgment at the conclusion of the examination of the action or the application, as the case may be, or, in the event it reserves its judgment, it is to deliver it without delay.\\u201d \\u201cActions and originating applications against the Republic under this Law are instituted against the Attorney-General of the Republic as defendant or respondent, depending on the case and the provisions of section 57 of the Courts of Justice Laws apply.\\u201d \\u201cThe court, in order to determine whether there has been a violation of the right of the plaintiff or the applicant to determination within a reasonable time of his civil rights or obligations in an action under sections 4 and 5 and in an application under sections 7 and 8, takes into account \\u2013 (a) the total period during which the determination of the rights or obligations in the case is pending or has lasted, taking into account the date on which the case was lodged with the court, and also where relevant any preceding period, (b) the nature of the case in which, according to the allegation of the plaintiff or the applicant, his right has been violated, (c) the possible complexity of the case, (d) the conduct of the plaintiff or the applicant in the proceedings of the case, (e) the conduct of the judicial authorities at the various stages and processes of the case, including, where relevant, the execution procedures, and the prosecution of the case in the said stages and procedures, (f) the conduct of other authorities of the Republic, where relevant, at the stage and procedures of execution, as well as at any relevant stage and procedures prior to the date the case was lodged with the court, (g) any other factors taken into account by the European Court of Human Rights as relevant to the matter in issue as these arise from its relevant case-law on the subject.\\u201d \\u201cWhere in an action under sections 4 and 5 or in an application under sections 7 and 8 the court considers that the right of the plaintiff or applicant to determination of his civil rights or obligations within a reasonable time has been violated, the plaintiff/applicant is entitled: (a) to compensation for any pecuniary damage, loss, costs, and expenses proved to have been sustained on account of the violation; (b) to compensation for non-pecuniary damage or injury suffered on account of the violation; (c) to legal costs proved to have been incurred on account of the violation. (2) For ascertaining the damage sustained on account of the violation as provided in sub-section (1) and assessing and awarding the compensation provided for under sub-section (1), the court takes into account the criteria and factors taken into account for this purpose by the European Court of Human Rights as they can be determined from its case-law in analogous cases of violation of Article 6.1 of the Convention, and the amounts of compensation awarded by the said Court in such analogous cases.\\u201d \\u201cIn examining an application made under sections 7 and 8 concerning the issue as to whether the applicant's right to determination of his civil rights or obligations within a reasonable time has been violated, the court exercises its judgment in relation to factors referred to in paragraphs (a)-(g) of section 11 after hearing the applicant and the Attorney-General of the Republic, by reference to the records of the proceedings and the contents of the file or files at first instance, or of any appeal of the case in which the applicant alleges that there has been a violation of his said right.\\u201d \\u201c(1) Where in an application under sections 7 and 8 the court decides under the present Law that there has been a violation in a pending case of the applicant's right to determination within a reasonable time of civil rights or obligations, the said court transmits its judgment immediately to the Supreme Court. (2) If the case concerning which the competent court issued its judgment and transmitted it to the Supreme Court under sub-section (1) is still pending, the Supreme Court issues such directions as under the circumstances it considers necessary to accelerate the procedure in the pending case, so as to prevent any continuance of the delay or any new delays, and avoid the possibility of continuation of the violation or new violations of the rights of any party in the pending case: Provided that a judge or judges of the Supreme Court who had participated in any stage of the examination of the pending case shall not participate in the issuing of directions. (3) Directions under sub-section (1) may include amongst other things- (a) that the pending case be set down immediately for directions before the court, or for trial (b) that pleadings which may not yet have been filed be so filed within deadlines specified in the directions, (c) that the record of the proceedings be prepared; (d) that costs which may have been awarded be subject to taxation (e) that priority be given to the conduct of the hearing of the case or the hearing of any interim applications; (f) that priority be given to the completion of any interim application procedures, or of other interim procedures, (g) that priority be given to the delivery of a judgment reserved in the case or in an interim application, (h) that priority be given to the completion by the judicial authorities of the execution procedures of a judgment given in the case to the extent that such authorities are involved. (4) Directions under sub-section (3) for accelerating the procedure in a pending case are issued irrespective of the fact that the relevant judgment which has been transmitted may have been given in accordance with paragraph (a) of sub-section (1) of section 8, and/or has been appealed against by the Attorney General.\\u201d\",\n          \"The applicant was born in 1943 and lives in Laukaa. On 5 January 1987 criminal investigations were instituted against the applicant who was taken into police custody the same day in respect of, inter alia, alleged tax frauds. He was released on 16 January 1987. On 5 July and 31 August 1990 the applicant was summoned to appear before the Helsinki City Court (raastuvanoikeus, r\\u00e5dstuvur\\u00e4tt, as from 1 December 1993 Helsinki District Court, k\\u00e4r\\u00e4j\\u00e4oikeus, tingsr\\u00e4tt) indicted for several aggravated tax frauds. The alleged offences concerned the importation of parts of vehicles and failure to pay relevant tax for them. The relevant decisions of the tax authorities after the clearance of the taxes were not yet final as the applicant had appealed against them. The first hearing before the District Court was held on 14 November 1990. The complainants and one of the four defendants, MI, had not yet been summoned. The Public Prosecutor charged the applicant with ten aggravated tax frauds, some of which he had allegedly committed together with other defendants, including MI. The applicant\\u2019s lawyer asked to be allowed to reply to the charges later. At the request of the Public Prosecutor the case was adjourned until 3 April 1991. At the second hearing, on 3 April 1991, the applicant denied all the charges. Concerning the alleged offences in complicity with MI, the applicant stressed MI\\u2019s role in the events and his greater knowledge of the subject. Two complainants and the defendant MI had still not been summoned. At the request of the Public Prosecutor and the National Board of Customs, which was one of the complainants, the case was adjourned until 29 May 1991. At the third hearing on 29 May 1991 the National Board of Customs submitted claims for damages. The applicant\\u2019s lawyer opposed the claims and said he would revert to the question of damages in a later hearing. The defendant MI had still not been summoned to appear before the City Court. The Public Prosecutor requested an adjournment in order to have MI summoned and to submit further clarification to certain questions. His request was not opposed. The next hearing was ordered to be on 16 October 1991. At the fourth hearing on 16 October 1991 the applicant was heard in person. His lawyer also clarified the reply to the claims of the National Board of Customs. The Public Prosecutor stated that MI had not yet been contacted and requested an adjournment in order to have him summoned. The applicant left the request for an adjournment to the City Court\\u2019s discretion. The case was adjourned until 4 December 1991. At the fifth hearing on 4 December 1991 the Public Prosecutor stated that MI had still not been summoned and requested a further adjournment. The applicant left the request to the City Court\\u2019s discretion. The case was adjourned until 13 May 1992. At the sixth hearing on 13 May 1992 the Public Prosecutor requested the case to be adjourned until further notice since MI\\u2019s place of residence was not known. The applicant left the case to be decided for his part. The City Court considered that it was necessary to hear MI before giving a decision on the charges against the applicant. Furthermore, the National Board of Customs had not yet given its decision concerning the appeals against the decisions of the tax authorities after the clearance of the taxes. The City Court, therefore, adjourned the case until further notice of the date of the next hearing would be given. The National Board of Customs and the Supreme Administrative Court gave decisions concerning the appeals against the post-clearance decisions on 20 April 1993 and 15 December 1993 respectively. In March 1994 the applicant lodged a complaint with the Chancellor of Justice (oikeuskansleri, justitiekansler). The complaint concerned the City Court\\u2019s decision to adjourn his case until further notice. The seventh hearing before the District Court (the former City Court) was held on 31 August 1994. MI had been summoned but he was absent from the hearing. At the request of the public prosecutor, which was not objected to, the case was adjourned until 21 September 1994. At the eighth hearing on 21 September 1994 MI appeared before the District Court to reply to the charges. He and the applicant were examined as regards their complicity in the alleged offences. At the request of MI, which was not objected to, the case was adjourned until 9 November 1994. At the last hearing on 9 November 1994 the applicant submitted that the length of the proceedings should be taken into account when assessing his possible punishment. The District Court convicted the applicant of a repetitive offence, consisting of four tax frauds, an aggravated tax fraud and aiding and abetting in two tax frauds and in two aggravated tax frauds, and sentenced him to six months\\u2019 suspended imprisonment. In the reasons given for the sentence the length of the proceedings was not mentioned explicitly. It was, however, noted that the fact that the offences had been committed a long time ago was one of the reasons for the court\\u2019s decision to impose a suspended sentence. On 17 October 1995 the Deputy Chancellor of Justice (apulaisoikeuskansleri, justitiekanslersadjoint) gave his decision on the applicant\\u2019s complaint, finding no breach of official duties on the part of the City Court\\u2019s members or of the public prosecutor nor any reason to take further measures in the matter. The public prosecutor and the defendants appealed to the Helsinki Court of Appeal (hovioikeus, hovr\\u00e4tt). The applicant requested, inter alia, that the length of the proceedings should be taken into consideration when assessing his sentence. On 4 June 1996 the Court of Appeal, as regards the applicant, upheld the District Court\\u2019s decision without giving any further reasons. The applicant sought leave to appeal from the Supreme Court (korkein oikeus, h\\u00f6gsta domstolen) renewing his request that the length of the proceedings be taken into account in the assessment of his sentence. On 26 November 1996 the Supreme Court refused the applicant leave to appeal. Chapter 16, Section 4, Subsection 1 (30.4.1987/452), of the Code of Judicial Procedure (oikeudenk\\u00e4ymiskaari, r\\u00e4tteg\\u00e5ngsbalken) provided: \\u201cWhen a party requests an adjournment in order to submit further evidence or for some other reason, the case must be adjourned, if the court finds grounds for it. The date for a new hearing must be set at the same time. A court cannot adjourn a case of its own motion unless necessary under particular circumstances. ...\\u201d As from 1 December 1993 the rules concerning adjournment of cases were amended (amendment 22.7.1991/1052). As regards criminal cases, the above-mentioned provision of law remained essentially unchanged. Furthermore, Chapter 16, Section 5, of the Code of Judicial Procedure provided: \\u201cWhen it is important to wait for a decision of another tribunal or some other body before a decision is given in a pending case, or when some other long-lasting impediment exists, a court may order that the hearing of the case will not be pursued until that obstacle ceases to exist.\\u201d According to Chapter 14, Section 7a (19.4.1991/708), of the Code of Judicial Procedure, which came into force on 1 April 1992, charges against defendants accused of committing the same offence must, in principle, be tried together.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Summary: train=7100, dev=1380, test=2998, train 'violated' column sum: 3551\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "print(\"\\nTrain (clean) sample rows:\", train_df_clean.shape)\n",
        "display(train_df_clean[['itemid','conclusion','violated_articles','text_clean']].head(2))\n",
        "\n",
        "\n",
        "num_train = len(train_df_clean)\n",
        "num_dev = len(dev_df_clean)\n",
        "num_test = len(test_df_clean)\n",
        "num_with_violation_flag = train_df['violated'].sum() if 'violated' in train_df.columns else 'N/A'\n",
        "print(f\"\\nSummary: train={num_train}, dev={num_dev}, test={num_test}, train 'violated' column sum: {num_with_violation_flag}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oeHkpzOabEQc"
      },
      "source": [
        "entity extraction (plaintiff, defendant) and key articles extraction"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "!pip install -q huggingface-hub transformers\n",
        "\n",
        "import re, os, torch\n",
        "from tqdm import tqdm\n",
        "tqdm.pandas()\n",
        "import pandas as pd\n",
        "from transformers import pipeline\n",
        "\n",
        "\n",
        "checkpoint_dir = \"/content/drive/MyDrive/Argumate/checkpoints\"\n",
        "train_path_ckpt = os.path.join(checkpoint_dir, \"train_clean.pkl\")\n",
        "dev_path_ckpt   = os.path.join(checkpoint_dir, \"dev_clean.pkl\")\n",
        "test_path_ckpt  = os.path.join(checkpoint_dir, \"test_clean.pkl\")\n",
        "\n",
        "if os.path.exists(train_path_ckpt):\n",
        "    train_df_clean = pd.read_pickle(train_path_ckpt)\n",
        "    dev_df_clean   = pd.read_pickle(dev_path_ckpt)\n",
        "    test_df_clean  = pd.read_pickle(test_path_ckpt)\n",
        "    print(\" Loaded cleaned checkpoints.\")\n",
        "else:\n",
        "    raise FileNotFoundError(\"Cleaned checkpoint not found. Please run data preparation cell first.\")\n",
        "\n",
        "\n",
        "\n",
        "class FactAnalysisAgent:\n",
        "    \"\"\"\n",
        "    Agentic entity that performs:\n",
        "    - Named entity extraction for plaintiff/defendant\n",
        "    - Article number extraction\n",
        "    - Optional LLM reasoning to validate/refine results\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, use_llm=True):\n",
        "        self.use_llm = use_llm\n",
        "        if use_llm:\n",
        "            try:\n",
        "                self.llm = pipeline(\"text-generation\", model=\"tiiuae/falcon-7b-instruct\", trust_remote_code=True, device_map=\"auto\")\n",
        "                print(\" LLM (Falcon-7B-Instruct) loaded for reasoning fallback.\")\n",
        "            except Exception as e:\n",
        "                print(\" Could not load Falcon LLM (likely out of VRAM or offline). Proceeding without it.\")\n",
        "                self.use_llm = False\n",
        "                self.llm = None\n",
        "\n",
        "    def extract_plaintiff(self, text):\n",
        "        if not isinstance(text, str) or not text.strip():\n",
        "            return \"Unknown\"\n",
        "        m = re.search(r\"(?:the\\s+)?applicant[,:]?\\s*(?:Mr\\.?|Ms\\.?|Mrs\\.?)\\s*([A-Z][A-Za-z\\-\\']+(?:\\s+[A-Z][A-Za-z\\-\\']+)*)\", text, flags=re.IGNORECASE)\n",
        "        if m: return m.group(1).strip()\n",
        "        m2 = re.search(r\"(?:Mr|Ms|Mrs)\\.?\\s+([A-Z][A-Za-z\\-\\']+(?:\\s+[A-Z][A-Za-z\\-\\']+)*)\", text)\n",
        "        if m2: return m2.group(1).strip()\n",
        "        if \"applicant\" in text.lower(): return \"The Applicant\"\n",
        "        return \"Unknown\"\n",
        "\n",
        "    def extract_defendant(self, text):\n",
        "        if not isinstance(text, str) or not text.strip():\n",
        "            return \"The Respondent\"\n",
        "        m = re.search(r\"\\b[vV]\\.\\s*([A-Z][A-Za-z\\-\\&\\s]+?)[,;\\.\\n]\", text)\n",
        "        if m: return m.group(1).strip()\n",
        "        if re.search(r\"respondent\", text, flags=re.IGNORECASE):\n",
        "            m2 = re.search(r\"respondent[,:\\s]*([A-Z][A-Za-z\\-\\']+)\", text, flags=re.IGNORECASE)\n",
        "            if m2: return m2.group(1).strip()\n",
        "            return \"The Respondent\"\n",
        "        return \"The Respondent\"\n",
        "\n",
        "    def extract_key_articles(self, text, violated_articles_field):\n",
        "        articles = set()\n",
        "        if isinstance(text, str):\n",
        "            for m in re.findall(r\"(?:Art(?:icle)?\\.?\\s*|article\\s*)(\\d+[A-Za-z\\-\\d]*)\", text, flags=re.IGNORECASE):\n",
        "                articles.add(str(m))\n",
        "        if isinstance(violated_articles_field, str) and violated_articles_field.strip():\n",
        "            for m in re.findall(r\"\\d+\", violated_articles_field):\n",
        "                articles.add(m)\n",
        "        return sorted(list(articles), key=lambda x: str(x))\n",
        "\n",
        "\n",
        "    def reason_with_llm(self, text, plaintiff, defendant, articles):\n",
        "        \"\"\"Use LLM to validate or refine the extracted entities.\"\"\"\n",
        "        if not self.use_llm or self.llm is None:\n",
        "            return {\"plaintiff\": plaintiff, \"defendant\": defendant, \"key_articles\": articles}\n",
        "\n",
        "        prompt = f\"\"\"\n",
        "        You are a legal text analysis AI.\n",
        "        Extract and confirm key entities from this case text.\n",
        "        Text: {text[:400]}\n",
        "        Extracted so far:\n",
        "        - Plaintiff: {plaintiff}\n",
        "        - Defendant: {defendant}\n",
        "        - Articles: {articles}\n",
        "\n",
        "        If the extraction seems incorrect or incomplete, refine it.\n",
        "        Respond in strict JSON with keys: plaintiff, defendant, key_articles.\n",
        "        \"\"\"\n",
        "        try:\n",
        "            result = self.llm(prompt, max_new_tokens=100)[0]['generated_text']\n",
        "            match = re.search(r\"\\{.*\\}\", result, re.DOTALL)\n",
        "            if match:\n",
        "                import json\n",
        "                data = json.loads(match.group())\n",
        "                return {\n",
        "                    \"plaintiff\": data.get(\"plaintiff\", plaintiff),\n",
        "                    \"defendant\": data.get(\"defendant\", defendant),\n",
        "                    \"key_articles\": data.get(\"key_articles\", articles),\n",
        "                }\n",
        "        except Exception as e:\n",
        "            print(\" LLM reasoning fallback failed:\", e)\n",
        "        return {\"plaintiff\": plaintiff, \"defendant\": defendant, \"key_articles\": articles}\n",
        "\n",
        "\n",
        "    def analyze(self, df, name=\"dataset\"):\n",
        "        print(f\"\\n Running FactAnalysisAgent on {name} ({len(df)} rows)...\")\n",
        "        results = []\n",
        "        for _, row in tqdm(df.iterrows(), total=len(df)):\n",
        "            text = row.get(\"text_clean\", \"\")\n",
        "            viol = row.get(\"violated_articles\", \"\")\n",
        "            p = self.extract_plaintiff(text)\n",
        "            d = self.extract_defendant(text)\n",
        "            a = self.extract_key_articles(text, viol)\n",
        "            refined = self.reason_with_llm(text, p, d, a)\n",
        "            results.append(refined)\n",
        "        df[\"plaintiff\"] = [r[\"plaintiff\"] for r in results]\n",
        "        df[\"defendant\"] = [r[\"defendant\"] for r in results]\n",
        "        df[\"key_articles\"] = [r[\"key_articles\"] for r in results]\n",
        "        df.to_pickle(os.path.join(checkpoint_dir, f\"{name}_stage_entities_agent.pkl\"))\n",
        "        print(f\" Saved {name}_stage_entities_agent.pkl\")\n",
        "        return df\n",
        "\n",
        "\n",
        "fact_agent = FactAnalysisAgent(use_llm=True)\n",
        "print(\" FactAnalysisAgent initialized successfully.\")\n"
      ],
      "metadata": {
        "id": "Ge4WWzuGvtCi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312,
          "referenced_widgets": [
            "e8bb207e1fc64567be40d3767b1d3b37",
            "fde9251228ea4f48bec524e9087dfa0c",
            "322a9e21240b455c87027c5ed6130c14",
            "ef1084ad23624349bf9293bc8f5fea5d",
            "3d5fc522afb94d328bb98750645a6eb9",
            "38fa55d586c2442f9fa288b5623d8c89",
            "056bc0ce8a7a48c5b1b375bb8f83eba8",
            "779f9f2a1e354c2ab23423e170fb6a63",
            "2a9d0ba2fb544229b460f2ef18053944",
            "39b51c613369431b825573c9c5a67429",
            "02b2dd0edc194646924f72b01388b545"
          ]
        },
        "outputId": "dea474eb-6c22-4874-fda4-ae6ef80d444b"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Loaded cleaned checkpoints.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "WARNING:transformers_modules.tiiuae.falcon_hyphen_7b_hyphen_instruct.8782b5c5d8c9290412416618f36a133653e85285.configuration_falcon:\n",
            "WARNING: You are currently loading Falcon using legacy code contained in the model repository. Falcon has now been fully ported into the Hugging Face transformers library. For the most up-to-date and high-performance version of the Falcon model code, please update to the latest version of transformers and then load the model without the trust_remote_code=True argument.\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e8bb207e1fc64567be40d3767b1d3b37"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:accelerate.big_modeling:Some parameters are on the meta device because they were offloaded to the cpu and disk.\n",
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " LLM (Falcon-7B-Instruct) loaded for reasoning fallback.\n",
            " FactAnalysisAgent initialized successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "sample_text = dev_df_clean.iloc[1][\"text_clean\"]\n",
        "print(\"\\n Sample Text (first 400 chars):\\n\", sample_text[:400], \"...\")\n",
        "\n",
        "result = fact_agent.reason_with_llm(\n",
        "    sample_text,\n",
        "    fact_agent.extract_plaintiff(sample_text),\n",
        "    fact_agent.extract_defendant(sample_text),\n",
        "    fact_agent.extract_key_articles(sample_text, dev_df_clean.iloc[0][\"violated_articles\"])\n",
        ")\n",
        "\n",
        "print(\"\\n Agent Output:\")\n",
        "print(result)\n"
      ],
      "metadata": {
        "id": "6l6TNoU0w8Ft",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4cc0bca9-b0bc-4771-d874-941324ecc8e2"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Sample Text (first 400 chars):\n",
            " The applicant, Mr John James Shannon, is a United Kingdom national, who was born in 1971 and lives in London. He is represented before the Court by Mr Andrew Parker, a lawyer practising in London. The facts of the case, as submitted by the parties, may be summarised as follows. The applicant is an actor and at the relevant time starred in London's Burning, a popular British drama series. In or a ...\n",
            " LLM reasoning fallback failed: 'NoneType' object has no attribute 'shape'\n",
            "\n",
            " Agent Output:\n",
            "{'plaintiff': 'John James Shannon', 'defendant': 'Loosely', 'key_articles': ['13', '3', '6']}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lAHg4uqCdoRW"
      },
      "source": [
        "Batch Legal-BERT prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "01BSQwdDgfc8"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "train_df = pd.read_json(\"/content/drive/MyDrive/Argumate/data/train.jsonl\", lines=True)\n",
        "dev_df   = pd.read_json(\"/content/drive/MyDrive/Argumate/data/dev.jsonl\", lines=True)\n",
        "\n",
        "\n",
        "train_texts = train_df[\"text\"]\n",
        "train_labels = train_df[\"violated\"].astype(int)\n",
        "\n",
        "dev_texts = dev_df[\"text\"]\n",
        "dev_labels = dev_df[\"violated\"].astype(int)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "U9H_R6f8DDZI"
      },
      "outputs": [],
      "source": [
        "!pip install -q transformers datasets tqdm accelerate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FFarWf8jgiNs"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "from tqdm.auto import tqdm\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForSequenceClassification,\n",
        "    Trainer,\n",
        "    TrainingArguments\n",
        ")\n",
        "from sklearn.metrics import classification_report, accuracy_score, precision_recall_fscore_support\n",
        "\n",
        "\n",
        "print(\" Loading dataset...\")\n",
        "\n",
        "train_path = \"/content/drive/MyDrive/Argumate/data/train.jsonl\"\n",
        "dev_path   = \"/content/drive/MyDrive/Argumate/data/dev.jsonl\"\n",
        "\n",
        "train_df = pd.read_json(train_path, lines=True)\n",
        "dev_df   = pd.read_json(dev_path, lines=True)\n",
        "\n",
        "\n",
        "train_df[\"text\"] = train_df[\"text\"].astype(str)\n",
        "dev_df[\"text\"]   = dev_df[\"text\"].astype(str)\n",
        "train_df[\"violated\"] = train_df[\"violated\"].astype(int)\n",
        "dev_df[\"violated\"]   = dev_df[\"violated\"].astype(int)\n",
        "\n",
        "print(f\" Train samples: {len(train_df)} | Dev samples: {len(dev_df)}\")\n",
        "\n",
        "\n",
        "print(\"\\n Tokenizing text...\")\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"nlpaueb/legal-bert-small-uncased\")\n",
        "\n",
        "def tokenize_data(texts):\n",
        "\n",
        "    all_encodings = tokenizer(\n",
        "        texts,\n",
        "        truncation=True,\n",
        "        padding=True,\n",
        "        max_length=256,\n",
        "        return_tensors=\"pt\"\n",
        "    )\n",
        "    return all_encodings\n",
        "\n",
        "train_encodings = tokenize_data(train_df[\"text\"].tolist())\n",
        "dev_encodings   = tokenize_data(dev_df[\"text\"].tolist())\n",
        "\n",
        "\n",
        "class ECHRDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {k: v[idx] for k, v in self.encodings.items()}\n",
        "        item[\"labels\"] = torch.tensor(self.labels[idx], dtype=torch.long)\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "train_dataset = ECHRDataset(train_encodings, train_df[\"violated\"].tolist())\n",
        "dev_dataset   = ECHRDataset(dev_encodings, dev_df[\"violated\"].tolist())\n",
        "\n",
        "\n",
        "print(\"\\n Initializing model...\")\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    \"nlpaueb/legal-bert-small-uncased\",\n",
        "    num_labels=2\n",
        ")\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"/content/drive/MyDrive/Argumate/checkpoints/legalbert_cpu_finetune\",\n",
        "    eval_strategy=\"steps\",\n",
        "    save_strategy=\"steps\",\n",
        "    save_steps=500,\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=4,\n",
        "    per_device_eval_batch_size=4,\n",
        "    num_train_epochs=1,\n",
        "    weight_decay=0.01,\n",
        "    logging_steps=50,\n",
        "    report_to=\"none\"\n",
        ")\n",
        "\n",
        "\n",
        "def compute_metrics(p):\n",
        "    preds = p.predictions.argmax(-1)\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(p.label_ids, preds, average=\"binary\")\n",
        "    acc = accuracy_score(p.label_ids, preds)\n",
        "    return {\"accuracy\": acc, \"f1\": f1, \"precision\": precision, \"recall\": recall}\n",
        "\n",
        "\n",
        "print(\"\\n Training started (CPU mode)...\")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=dev_dataset,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "trainer.train()\n",
        "\n",
        "\n",
        "print(\"\\n Evaluating model...\")\n",
        "results = trainer.evaluate()\n",
        "print(\" Evaluation:\", results)\n",
        "\n",
        "\n",
        "print(\"\\n Checking predictions vs true labels...\")\n",
        "\n",
        "preds = trainer.predict(dev_dataset)\n",
        "pred_labels = preds.predictions.argmax(-1)\n",
        "true_labels = dev_df[\"violated\"].tolist()\n",
        "\n",
        "print(classification_report(true_labels, pred_labels, target_names=[\"Non-Violation\", \"Violation\"]))\n",
        "\n",
        "\n",
        "for i in range(2):\n",
        "    print(f\"\\n Case {i+1}\")\n",
        "    print(\"Text:\", dev_df.iloc[i][\"text\"][:200].replace(\"\\n\", \" \"), \"...\")\n",
        "    print(\"True Label:\", \"Violation\" if true_labels[i]==1 else \"Non-Violation\")\n",
        "    print(\"Predicted Label:\", \"Violation\" if pred_labels[i]==1 else \"Non-Violation\")\n",
        "\n",
        "\n",
        "\n",
        "save_path = \"/content/drive/MyDrive/Argumate/checkpoints/legalbert_cpu_finetune/final_checkpoint\"\n",
        "model.save_pretrained(save_path)\n",
        "tokenizer.save_pretrained(save_path)\n",
        "print(f\"\\n Fine-tuned model + tokenizer saved at: {save_path}\")\n",
        "\n",
        "print(\"\\n All steps complete! Model trained, evaluated, and checkpoint saved.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j-uXZpRSCoR1"
      },
      "source": [
        "Step 4  Outcome Predictor agent"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import torch, json, re\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, pipeline\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "class OutcomePredictorAgent:\n",
        "    def __init__(self, model_path=\"/content/drive/MyDrive/Argumate/checkpoints/legalbert_cpu_finetune/final_checkpoint\"):\n",
        "        self.model_path = model_path\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
        "        self.model = AutoModelForSequenceClassification.from_pretrained(model_path).to(device)\n",
        "        self.label_map = {0: \"Non-Violation\", 1: \"Violation\"}\n",
        "        try:\n",
        "            self.llm = pipeline(\"text-generation\", model=\"distilgpt2\", device_map=\"auto\")\n",
        "            print(\" Lightweight reasoning LLM (distilgpt2) loaded.\")\n",
        "        except Exception:\n",
        "            self.llm = None\n",
        "            print(\" LLM unavailable, using LegalBERT only.\")\n",
        "        self.model.eval()\n",
        "\n",
        "    def predict(self, text):\n",
        "        if isinstance(text, list):\n",
        "            text = \" \".join(map(str, text))\n",
        "        if not isinstance(text, str):\n",
        "            text = str(text)\n",
        "        text = text.strip()\n",
        "        if not text:\n",
        "            return {\"outcome\": \"Unknown\"}\n",
        "\n",
        "\n",
        "        inputs = self.tokenizer([text], return_tensors=\"pt\",\n",
        "                                truncation=True, padding=True, max_length=256).to(device)\n",
        "        with torch.no_grad():\n",
        "            logits = self.model(**inputs).logits\n",
        "            label = int(torch.argmax(logits, dim=-1)[0].cpu().numpy())\n",
        "\n",
        "        result = {\"outcome\": self.label_map[label]}\n",
        "\n",
        "\n",
        "        if self.llm:\n",
        "            prompt = (f\"LegalBERT predicts '{result['outcome']}'. \"\n",
        "                      f\"Confirm or adjust if the case context implies otherwise.\\n\"\n",
        "                      f\"Text: {text[:400]}\\n\"\n",
        "                      \"Respond strictly as JSON: {'outcome': '...'}\")\n",
        "            try:\n",
        "                gen = self.llm(prompt, max_new_tokens=50, pad_token_id=50256)[0]['generated_text']\n",
        "                match = re.search(r\"\\{.*\\}\", gen)\n",
        "                if match:\n",
        "                    data = json.loads(match.group())\n",
        "                    result.update(data)\n",
        "            except Exception:\n",
        "                pass\n",
        "        return result\n",
        "\n",
        "    def save_checkpoint(self, save_path=\"/content/drive/MyDrive/Argumate/checkpoints/outcome_predictor_agent\"):\n",
        "        self.model.save_pretrained(save_path)\n",
        "        self.tokenizer.save_pretrained(save_path)\n",
        "        print(f\" Predictor agent model saved at: {save_path}\")\n",
        "\n",
        "predictor_agent = OutcomePredictorAgent()\n",
        "predictor_agent.save_checkpoint()\n",
        "print(\" OutcomePredictorAgent ready (no confidence).\")\n"
      ],
      "metadata": {
        "id": "NGF_dWZhni91",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e88d1e4f-6c62-481a-bb9b-6ee98632e8f6"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Lightweight reasoning LLM (distilgpt2) loaded.\n",
            " Predictor agent model saved at: /content/drive/MyDrive/Argumate/checkpoints/outcome_predictor_agent\n",
            " OutcomePredictorAgent ready (no confidence).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 5- Memory retrieval agent"
      ],
      "metadata": {
        "id": "-DoZN72uBhFB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "77a4e96f"
      },
      "outputs": [],
      "source": [
        "!pip install -q sentence-transformers faiss-cpu huggingface-hub transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import numpy as np, faiss, re, json, pickle\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from transformers import pipeline\n",
        "\n",
        "class MemoryRetrievalAgent:\n",
        "    def __init__(self, embedder=\"sentence-transformers/paraphrase-MiniLM-L6-v2\", use_reasoning=True):\n",
        "        self.embedder_name = embedder\n",
        "        self.model = SentenceTransformer(embedder)\n",
        "        self.index = None\n",
        "        self.corpus = []\n",
        "        self.use_reasoning = use_reasoning\n",
        "        if use_reasoning:\n",
        "            try:\n",
        "                self.llm = pipeline(\"text-generation\", model=\"distilgpt2\", device_map=\"auto\")\n",
        "                print(\" distilgpt2 loaded for retrieval summaries.\")\n",
        "            except Exception:\n",
        "                self.llm = None\n",
        "        else:\n",
        "            self.llm = None\n",
        "\n",
        "    def build_memory(self, texts):\n",
        "        print(f\"Building FAISS index for {len(texts)} cases\")\n",
        "        self.corpus = texts\n",
        "        emb = self.model.encode(texts, convert_to_numpy=True, show_progress_bar=True)\n",
        "        dim = emb.shape[1]\n",
        "        self.index = faiss.IndexFlatL2(dim)\n",
        "        self.index.add(emb.astype(\"float32\"))\n",
        "        print(\" FAISS index built.\")\n",
        "\n",
        "    def retrieve(self, query, k=3):\n",
        "        if self.index is None:\n",
        "            raise ValueError(\"Index not built.\")\n",
        "        q = self.model.encode([query], convert_to_numpy=True)\n",
        "        D, I = self.index.search(q.astype(\"float32\"), k)\n",
        "        results = [self.corpus[i] for i in I[0]]\n",
        "        if self.llm:\n",
        "            try:\n",
        "                short_texts = \" | \".join([r[:150].replace(\"\\n\", \" \") for r in results])\n",
        "                prompt = (f\"Given these precedent snippets: {short_texts}. \"\n",
        "                          \"Summarize in one short sentence their shared theme.\")\n",
        "                summary = self.llm(prompt, max_new_tokens=50, pad_token_id=50256)[0]['generated_text']\n",
        "                print(\"Retrieval summary:\", summary[:200], \"\\n\")\n",
        "            except Exception:\n",
        "                pass\n",
        "        return results\n",
        "\n",
        "    def save_checkpoint(self, path=\"/content/drive/MyDrive/Argumate/checkpoints/memory_agent.pkl\"):\n",
        "        data = {\n",
        "            \"embedder\": self.embedder_name,\n",
        "            \"corpus\": self.corpus\n",
        "        }\n",
        "        with open(path, \"wb\") as f:\n",
        "            pickle.dump(data, f)\n",
        "        print(f\" Memory agent checkpoint saved at: {path}\")\n",
        "\n",
        "\n",
        "subset_texts = pd.read_pickle(\"/content/drive/MyDrive/Argumate/checkpoints/train_clean.pkl\")[\"text_clean\"].head(500).tolist()\n",
        "memory_agent = MemoryRetrievalAgent()\n",
        "memory_agent.build_memory(subset_texts)\n",
        "memory_agent.save_checkpoint()\n",
        "print(\" MemoryRetrievalAgent ready & saved.\")\n"
      ],
      "metadata": {
        "id": "825Ymop-BvMU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173,
          "referenced_widgets": [
            "9f07a7346afc48e0b0b377f291a3fb98",
            "67bebfcde35d480db712fc6678ba3d8b",
            "cc78b2ddfd764610a3e5052903c883fd",
            "116b4137301e4726bd5e87aa5c452918",
            "836f2bc515dd4338af7c56c81e04a191",
            "b849e972eba14dabafc1a708d00b8db4",
            "ef1f6339389040afaa68cba255930e03",
            "cdc77a1d5e4c4c819982bbc5eb9d6a32",
            "58d8e6d6001648af8097b935bf8bf1b4",
            "1bdb271c88da403e8528595640029056",
            "92faba3bd223496b99a0c4fa6701a0a6"
          ]
        },
        "outputId": "8d71216a-2d83-4054-c439-a7cab2a0ee45"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " distilgpt2 loaded for retrieval summaries.\n",
            "Building FAISS index for 500 cases\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Batches:   0%|          | 0/16 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9f07a7346afc48e0b0b377f291a3fb98"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " FAISS index built.\n",
            " Memory agent checkpoint saved at: /content/drive/MyDrive/Argumate/checkpoints/memory_agent.pkl\n",
            " MemoryRetrievalAgent ready & saved.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uajqpqJzRGCu"
      },
      "source": [
        "Combined Function (Parallel Agent Stage)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import json, re\n",
        "from transformers import pipeline\n",
        "from IPython.display import display, Markdown\n",
        "\n",
        "class CaseAnalysisAgent:\n",
        "    def __init__(self, predictor, memory, model_name=\"distilgpt2\"):\n",
        "        self.predictor = predictor\n",
        "        self.memory = memory\n",
        "        try:\n",
        "            self.llm = pipeline(\"text-generation\", model=model_name, device_map=\"auto\")\n",
        "            print(f\" Reasoning model '{model_name}' loaded for fusion.\")\n",
        "        except Exception as e:\n",
        "            print(\" LLM unavailable:\", e)\n",
        "            self.llm = None\n",
        "\n",
        "    def analyze(self, text):\n",
        "        print(\"\\n=== CASE ANALYSIS START ===\")\n",
        "        pred = self.predictor.predict(text)\n",
        "        precedents = self.memory.retrieve(text, k=3)\n",
        "\n",
        "        output = {\n",
        "            \"Predicted_Outcome\": pred.get(\"outcome\", \"Unknown\"),\n",
        "            \"Final_Outcome\": pred.get(\"outcome\", \"Unknown\"),\n",
        "            \"Rationale\": \"No reasoning available.\",\n",
        "            \"Similar_Precedents\": [p[:200].replace(\"\\n\", \" \") for p in precedents]\n",
        "        }\n",
        "\n",
        "        if self.llm:\n",
        "            prompt = (\n",
        "                f\"Outcome predicted: {pred.get('outcome', 'Unknown')}. \"\n",
        "                f\"Similar precedents: {output['Similar_Precedents']}.\\n\"\n",
        "                \"Provide final decision and short rationale as JSON: \"\n",
        "                \"{'Final_Outcome':..., 'Rationale':...}\"\n",
        "            )\n",
        "            prompt = prompt[:500]\n",
        "            try:\n",
        "                gen = self.llm(prompt, max_new_tokens=80, pad_token_id=50256)[0][\"generated_text\"]\n",
        "                print(\"\\n Raw LLM output (for debugging):\", gen[:300], \"\\n\")\n",
        "                match = re.search(r\"\\{.*\\}\", gen)\n",
        "                if match:\n",
        "                    data = json.loads(match.group())\n",
        "\n",
        "                    output[\"Final_Outcome\"] = data.get(\"Final_Outcome\", output[\"Final_Outcome\"])\n",
        "                    output[\"Rationale\"] = data.get(\"Rationale\", output[\"Rationale\"])\n",
        "            except Exception as e:\n",
        "                print(\" Generation or JSON parsing failed:\", e)\n",
        "                output[\"Rationale\"] = \"Fallback reasoning (JSON parse failed).\"\n",
        "        else:\n",
        "            output[\"Rationale\"] = \"Fallback reasoning (no reasoning model).\"\n",
        "\n",
        "\n",
        "        print(\"\\n###  Structured Case Summary ###\")\n",
        "        md = f\"\"\"\n",
        "        **Predicted Outcome:** {output['Predicted_Outcome']}\n",
        "        **Final Outcome:** {output['Final_Outcome']}\n",
        "        **Rationale:** {output['Rationale']}\n",
        "\n",
        "        **Top Precedents:**\n",
        "        \"\"\"\n",
        "        for i, p in enumerate(output[\"Similar_Precedents\"], 1):\n",
        "            md += f\"- {i}. {p[:150]}...\\n\"\n",
        "        display(Markdown(md))\n",
        "\n",
        "        return output\n",
        "\n",
        "\n",
        "combined_agent = CaseAnalysisAgent(predictor_agent, memory_agent)\n",
        "print(\"Combined Agent (KeyError-proof) ready.\")\n"
      ],
      "metadata": {
        "id": "XM5aWycnD4PP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1aae3166-11ac-49a1-e833-54ef057c682d"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Reasoning model 'distilgpt2' loaded for fusion.\n",
            "Combined Agent (KeyError-proof) ready.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample_df = pd.read_json(\"/content/drive/MyDrive/Argumate/data/dev.jsonl\", lines=True)\n",
        "test_text = sample_df.iloc[0][\"text\"]\n",
        "\n",
        "print(\"\\nRunning Combined Agent...\\n\")\n",
        "result = combined_agent.analyze(test_text)\n",
        "\n",
        "print(\" Final Structured Output:\\n\")\n",
        "print(json.dumps(result, indent=2))\n"
      ],
      "metadata": {
        "id": "pfAwU7twECJm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 674
        },
        "outputId": "91021156-08f3-408d-8b74-8048f4271a82"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Running Combined Agent...\n",
            "\n",
            "\n",
            "=== CASE ANALYSIS START ===\n",
            "Retrieval summary: Given these precedent snippets: The applicant, Mr Nikolay Vasilyevich Samoylovich, is a Ukrainian national who was born in 1969 and lives in Simferopol. On 29 January 1997 the Kyiv d | On 19 November  \n",
            "\n",
            "\n",
            " Raw LLM output (for debugging): Outcome predicted: Violation. Similar precedents: ['The applicant, Mr Nikolay Vasilyevich Samoylovich, is a Ukrainian national who was born in 1969 and lives in Simferopol. On 29 January 1997 the Kyiv district prosecutors office at Simferopol opened c', 'On 19 November 1996 the applicant was arrest \n",
            "\n",
            "\n",
            "###  Structured Case Summary ###\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "\n        **Predicted Outcome:** Violation\n        **Final Outcome:** Violation\n        **Rationale:** No reasoning available.\n\n        **Top Precedents:**\n        - 1. The applicant, Mr Nikolay Vasilyevich Samoylovich, is a Ukrainian national who was born in 1969 and lives in Simferopol. On 29 January 1997 the Kyiv d...\n- 2. On 19 November 1996 the applicant was arrested and detained on suspicion of committing an offence. On 22 November 1996 he was charged with seven count...\n- 3. The applicant was born in 1977 and lives in Budapest. On 26 February 2002 criminal proceedings were instituted against the applicant, a college studen...\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Final Structured Output:\n",
            "\n",
            "{\n",
            "  \"Predicted_Outcome\": \"Violation\",\n",
            "  \"Final_Outcome\": \"Violation\",\n",
            "  \"Rationale\": \"No reasoning available.\",\n",
            "  \"Similar_Precedents\": [\n",
            "    \"The applicant, Mr Nikolay Vasilyevich Samoylovich, is a Ukrainian national who was born in 1969 and lives in Simferopol. On 29 January 1997 the Kyiv district prosecutor\\u2019s office at Simferopol opened c\",\n",
            "    \"On 19 November 1996 the applicant was arrested and detained on suspicion of committing an offence. On 22 November 1996 he was charged with seven counts of theft, one count of attempted theft and one c\",\n",
            "    \"The applicant was born in 1977 and lives in Budapest. On 26 February 2002 criminal proceedings were instituted against the applicant, a college student, on a charge of extortion, which had allegedly b\"\n",
            "  ]\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x_ST-ULuR_Lj"
      },
      "source": [
        "Reasoning & Argument Planning Agent (FLAN-T5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "fgXe5xyqUVUz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76a78dda-f037-4029-981a-b871594feac0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device for reasoning: cpu\n",
            "Loading reasoning model: google/flan-t5-small \n",
            " ReasoningPlanningAgent loaded and ready.\n",
            " Reasoning agent saved to /content/drive/MyDrive/Argumate/checkpoints/reasoning_agent\n",
            " ReasoningPlanningAgent (type-safe) initialized & saved.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import os, json, re\n",
        "import torch\n",
        "from difflib import SequenceMatcher\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Device for reasoning:\", device)\n",
        "\n",
        "class ReasoningPlanningAgent:\n",
        "    def __init__(self,\n",
        "                 model_name=\"google/flan-t5-small\",\n",
        "                 predictor_agent=None,\n",
        "                 save_path=\"/content/drive/MyDrive/Argumate/checkpoints/reasoning_agent\"):\n",
        "        self.model_name = model_name\n",
        "        self.device = device\n",
        "        self.predictor_agent = predictor_agent\n",
        "        self.save_path = save_path\n",
        "\n",
        "        print(f\"Loading reasoning model: {model_name} \")\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "        self.model = AutoModelForSeq2SeqLM.from_pretrained(model_name).to(self.device)\n",
        "        self.model.eval()\n",
        "        print(\" ReasoningPlanningAgent loaded and ready.\")\n",
        "\n",
        "\n",
        "    def _to_str(self, text):\n",
        "        \"\"\"Ensure text is always a string.\"\"\"\n",
        "        if isinstance(text, list):\n",
        "            text = \" \".join(map(str, text))\n",
        "        elif not isinstance(text, str):\n",
        "            text = str(text)\n",
        "        return text.strip()\n",
        "\n",
        "    def _similarity(self, a, b):\n",
        "        \"\"\"Robust similarity that auto-converts types.\"\"\"\n",
        "        a = self._to_str(a)\n",
        "        b = self._to_str(b)\n",
        "        return SequenceMatcher(None, a.lower(), b.lower()).ratio()\n",
        "\n",
        "    def _fallback_reasoning(self, text, outcome, precedents):\n",
        "        \"\"\"Rule-based fallback reasoning.\"\"\"\n",
        "        text = self._to_str(text)\n",
        "        sentences = re.split(r'(?<=[.!?])\\s+', text.strip())\n",
        "        facts = \" \".join(sentences[:3])\n",
        "        issue = \"Whether the described acts constitute a breach of the Convention.\"\n",
        "        if precedents:\n",
        "            prec = \" | \".join([self._to_str(p)[:120].replace(\"\\n\",\" \") for p in precedents[:2]])\n",
        "            analysis = f\"Facts are compared to precedents ({prec}); the similarity indicates same pattern of violation.\"\n",
        "        else:\n",
        "            analysis = \"No direct precedent; reasoning based on general legal principles.\"\n",
        "        conclusion = f\"Thus, reasoning supports '{outcome}'.\"\n",
        "        return {\n",
        "            \"issue\": issue,\n",
        "            \"facts_summary\": facts,\n",
        "            \"analysis\": analysis,\n",
        "            \"conclusion\": conclusion,\n",
        "            \"used_model\": \"rule-based\"\n",
        "        }\n",
        "\n",
        "\n",
        "    def generate_reasoning(self, case_text, predicted_outcome, precedents):\n",
        "        \"\"\"Generate structured reasoning safely.\"\"\"\n",
        "        case_text = self._to_str(case_text)\n",
        "        precedents = [self._to_str(p) for p in (precedents or [])]\n",
        "\n",
        "        prompt = f\"\"\"\n",
        "You are a senior legal reasoning agent assisting the European Court of Human Rights.\n",
        "Generate a **structured reasoning** in this exact format:\n",
        "\n",
        "ISSUE:\n",
        "FACTS SUMMARY:\n",
        "LEGAL ANALYSIS:\n",
        "CONCLUSION:\n",
        "\n",
        "Use concise, professional legal phrasing (812 sentences total).\n",
        "Avoid repeating the case text verbatim.\n",
        "\n",
        "Case Summary:\n",
        "{case_text[:900]}\n",
        "\n",
        "Predicted Outcome: {predicted_outcome}\n",
        "Relevant Precedents:\n",
        "{chr(10).join(precedents[:3]) if precedents else \"None\"}\n",
        "\"\"\"\n",
        "        inputs = self.tokenizer(prompt, return_tensors=\"pt\", truncation=True, padding=True, max_length=1024).to(self.device)\n",
        "        with torch.no_grad():\n",
        "            outputs = self.model.generate(\n",
        "                **inputs,\n",
        "                max_length=320,\n",
        "                num_beams=4,\n",
        "                early_stopping=True,\n",
        "                no_repeat_ngram_size=3,\n",
        "                repetition_penalty=1.2,\n",
        "            )\n",
        "        gen_text = self.tokenizer.decode(outputs[0], skip_special_tokens=True).strip()\n",
        "\n",
        "\n",
        "        if self._similarity(gen_text, case_text[:600]) > 0.45 or len(gen_text) < 80:\n",
        "            print(\" Reasoning.\")\n",
        "            return self._fallback_reasoning(case_text, predicted_outcome, precedents)\n",
        "\n",
        "        def extract(label):\n",
        "            m = re.search(rf\"{label}\\s*:\\s*(.*?)(?=\\n[A-Z ]+?:|\\Z)\", gen_text, flags=re.DOTALL | re.IGNORECASE)\n",
        "            return m.group(1).strip() if m else \"\"\n",
        "\n",
        "        issue = extract(\"ISSUE\")\n",
        "        facts = extract(\"FACTS SUMMARY\") or extract(\"FACTS\")\n",
        "        analysis = extract(\"LEGAL ANALYSIS\") or extract(\"ANALYSIS\")\n",
        "        conclusion = extract(\"CONCLUSION\") or extract(\"RESULT\")\n",
        "\n",
        "        if not (issue and facts and analysis and conclusion):\n",
        "            fallback = self._fallback_reasoning(case_text, predicted_outcome, precedents)\n",
        "            issue = issue or fallback[\"issue\"]\n",
        "            facts = facts or fallback[\"facts_summary\"]\n",
        "            analysis = analysis or fallback[\"analysis\"]\n",
        "            conclusion = conclusion or fallback[\"conclusion\"]\n",
        "            used = \"flan-t5 + fallback\"\n",
        "        else:\n",
        "            used = \"flan-t5\"\n",
        "\n",
        "        reasoning = {\n",
        "            \"issue\": issue,\n",
        "            \"facts_summary\": facts,\n",
        "            \"analysis\": analysis,\n",
        "            \"conclusion\": conclusion,\n",
        "            \"used_model\": used,\n",
        "            \"raw_output\": gen_text\n",
        "        }\n",
        "        return reasoning\n",
        "\n",
        "    def self_review_loop(self, case_text, precedents, max_loops=2):\n",
        "        case_text = self._to_str(case_text)\n",
        "        precedents = [self._to_str(p) for p in (precedents or [])]\n",
        "        outcome = \"Violation\"\n",
        "        history = []\n",
        "        for i in range(max_loops):\n",
        "            print(f\"\\n Loop iteration {i+1}\")\n",
        "            reasoning = self.generate_reasoning(case_text, outcome, precedents)\n",
        "            history.append(reasoning)\n",
        "            if not self.predictor_agent:\n",
        "                print(\"No predictor linked  loop ends.\")\n",
        "                break\n",
        "            check_text = reasoning[\"facts_summary\"] + \" \" + reasoning[\"analysis\"]\n",
        "            pred_check = self.predictor_agent.predict(check_text)\n",
        "            new_outcome = pred_check.get(\"outcome\", outcome)\n",
        "            print(f\"Predicted again by OutcomeAgent: {new_outcome}\")\n",
        "            if new_outcome == outcome:\n",
        "                print(\" Consistent outcome reached.\")\n",
        "                break\n",
        "            else:\n",
        "                print(f\" Adjusting outcome: {outcome}  {new_outcome}\")\n",
        "                outcome = new_outcome\n",
        "        return {\"final_outcome\": outcome, \"reasoning_history\": history}\n",
        "\n",
        "\n",
        "    def save_agent(self):\n",
        "        os.makedirs(self.save_path, exist_ok=True)\n",
        "        self.model.save_pretrained(self.save_path)\n",
        "        self.tokenizer.save_pretrained(self.save_path)\n",
        "        print(f\" Reasoning agent saved to {self.save_path}\")\n",
        "\n",
        "\n",
        "reasoning_agent = ReasoningPlanningAgent(predictor_agent=predictor_agent)\n",
        "reasoning_agent.save_agent()\n",
        "print(\" ReasoningPlanningAgent (type-safe) initialized & saved.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "jpDkYPy2Ug51",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 774
        },
        "outputId": "e23bddaa-c61e-4dc0-bcc2-39e62d1221fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Running Combined Agent first...\n",
            "\n",
            "\n",
            "=== CASE ANALYSIS START ===\n",
            "Retrieval summary: Given these precedent snippets: The applicant, Mr Nikolay Vasilyevich Samoylovich, is a Ukrainian national who was born in 1969 and lives in Simferopol. On 29 January 1997 the Kyiv d | On 19 November  \n",
            "\n",
            "\n",
            " Raw LLM output (for debugging): Outcome predicted: Violation. Similar precedents: ['The applicant, Mr Nikolay Vasilyevich Samoylovich, is a Ukrainian national who was born in 1969 and lives in Simferopol. On 29 January 1997 the Kyiv district prosecutors office at Simferopol opened c', 'On 19 November 1996 the applicant was arrest \n",
            "\n",
            "\n",
            "###  Structured Case Summary ###\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "\n        **Predicted Outcome:** Violation\n        **Final Outcome:** Violation\n        **Rationale:** No reasoning available.\n\n        **Top Precedents:**\n        - 1. The applicant, Mr Nikolay Vasilyevich Samoylovich, is a Ukrainian national who was born in 1969 and lives in Simferopol. On 29 January 1997 the Kyiv d...\n- 2. On 19 November 1996 the applicant was arrested and detained on suspicion of committing an offence. On 22 November 1996 he was charged with seven count...\n- 3. The applicant was born in 1977 and lives in Budapest. On 26 February 2002 criminal proceedings were instituted against the applicant, a college studen...\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Running Reasoning Agent...\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "\n###  Generated Legal Reasoning\n**Issue:** Whether the described acts constitute a breach of the Convention.\n**Facts Summary:** The applicant was born in 1947 and lives in Simferopol. On 19 June 1999 the applicant was arrested on suspicion of theft and abuse of power. On 23 June 1999 the applicant was placed in the Simferopol Temporary Detention Centre No.\n**Legal Analysis:** Facts are compared to precedents (The applicant, Mr Nikolay Vasilyevich Samoylovich, is a Ukrainian national who was born in 1969 and lives in Simferopol. | On 19 November 1996 the applicant was arrested and detained on suspicion of committing an offence. On 22 November 1996 h); the similarity indicates same pattern of violation.\n**Conclusion:** Thus, reasoning supports 'Violation'.\n**Model Used:** flan-t5 + fallback\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "print(\"\\nRunning Combined Agent first...\\n\")\n",
        "combined_result = combined_agent.analyze(test_text)\n",
        "\n",
        "print(\"\\nRunning Reasoning Agent...\\n\")\n",
        "reasoning_result = reasoning_agent.generate_reasoning(\n",
        "    case_text=test_text,\n",
        "    predicted_outcome=combined_result[\"Final_Outcome\"],\n",
        "    precedents=combined_result[\"Similar_Precedents\"]\n",
        ")\n",
        "\n",
        "from IPython.display import display, Markdown\n",
        "md = f\"\"\"\n",
        "###  Generated Legal Reasoning\n",
        "**Issue:** {reasoning_result['issue']}\n",
        "**Facts Summary:** {reasoning_result['facts_summary']}\n",
        "**Legal Analysis:** {reasoning_result['analysis']}\n",
        "**Conclusion:** {reasoning_result['conclusion']}\n",
        "**Model Used:** {reasoning_result['used_model']}\n",
        "\"\"\"\n",
        "display(Markdown(md))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OD_q7HZOWb6f"
      },
      "source": [
        "STAGE 4: Supporting Precedent Retrieval Agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "PEbGXdSMWd3k",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190,
          "referenced_widgets": [
            "2383910e9b254d3aac89758c636b1dbb",
            "dabd3516b71d47e992120d242faf0f2d",
            "9490b2d4649640a9b13aebe8e80e702c",
            "023c2b522b894514aafd579b0e30d801",
            "6797dfec999f4f38ab9a3b2ad7952ea0",
            "b6cac523ced74e58bbd7728029a45a5b",
            "e17079eb2171401ea03e8c3a52ffb7d2",
            "224e4396b811450b8c6878ca54b11e13",
            "85acd177bd2c484ab5935daead4f3b2d",
            "fa1abe70a1e54cb598c5da07407c745f",
            "a27c2afb57934fdfb88b6ce110d0df16"
          ]
        },
        "outputId": "83411fd1-e3aa-4880-c925-546f1b1ccccb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initializing SupportingPrecedentsAgent...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Model and reasoning LLM loaded.\n",
            "Building FAISS index for 1000 cases...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Batches:   0%|          | 0/32 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2383910e9b254d3aac89758c636b1dbb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " FAISS index ready for retrieval.\n",
            " SupportingPrecedentsAgent checkpoint saved at /content/drive/MyDrive/Argumate/checkpoints/supporting_precedents_agent\n",
            " SupportingPrecedentsAgent initialized & saved.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import os, json, faiss, numpy as np, re\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from transformers import pipeline\n",
        "\n",
        "class SupportingPrecedentsAgent:\n",
        "    def __init__(self,\n",
        "                 memory_checkpoint=\"/content/drive/MyDrive/Argumate/checkpoints/train_clean.pkl\",\n",
        "                 embedder=\"sentence-transformers/paraphrase-MiniLM-L6-v2\",\n",
        "                 reasoning_model=\"google/flan-t5-small\"):\n",
        "        print(\"Initializing SupportingPrecedentsAgent...\")\n",
        "        self.embedder = SentenceTransformer(embedder)\n",
        "        self.llm = pipeline(\"text2text-generation\", model=reasoning_model, device_map=\"auto\")\n",
        "        self.memory_checkpoint = memory_checkpoint\n",
        "        self.index = None\n",
        "        self.corpus = []\n",
        "        print(\" Model and reasoning LLM loaded.\")\n",
        "\n",
        "    def build_index(self, top_n=1000):\n",
        "        \"\"\"Rebuild FAISS index from existing checkpoint (subset for speed).\"\"\"\n",
        "        import pandas as pd\n",
        "        df = pd.read_pickle(self.memory_checkpoint)\n",
        "        self.corpus = df[\"text_clean\"].head(top_n).tolist()\n",
        "        print(f\"Building FAISS index for {len(self.corpus)} cases...\")\n",
        "        embeds = self.embedder.encode(self.corpus, convert_to_numpy=True, show_progress_bar=True)\n",
        "        dim = embeds.shape[1]\n",
        "        self.index = faiss.IndexFlatL2(dim)\n",
        "        self.index.add(embeds.astype(\"float32\"))\n",
        "        print(\" FAISS index ready for retrieval.\")\n",
        "\n",
        "    def retrieve_supporting(self, query_text, predicted_outcome=\"Violation\", k=3):\n",
        "        \"\"\"Retrieve top-k supporting precedents using FAISS + reasoning filter.\"\"\"\n",
        "        if self.index is None:\n",
        "            raise ValueError(\"FAISS index not built yet. Run build_index() first.\")\n",
        "\n",
        "        query_emb = self.embedder.encode([query_text], convert_to_numpy=True)\n",
        "        D, I = self.index.search(query_emb.astype(\"float32\"), k)\n",
        "        retrieved = [self.corpus[i] for i in I[0]]\n",
        "\n",
        "        print(f\"\\n Retrieved {len(retrieved)} candidate precedents.\")\n",
        "\n",
        "        precedents_text = \" | \".join([r[:180].replace(\"\\n\",\" \") for r in retrieved])\n",
        "        prompt = f\"\"\"\n",
        "You are a legal assistant summarizing precedents that **support** a predicted outcome of \"{predicted_outcome}\".\n",
        "Given these precedent excerpts, briefly summarize their key supportive reasoning in 2-3 sentences.\n",
        "\n",
        "Precedents:\n",
        "{precedents_text}\n",
        "\"\"\"\n",
        "        summary = self.llm(prompt, max_new_tokens=100)[0][\"generated_text\"]\n",
        "        return {\n",
        "            \"supporting_precedents\": retrieved,\n",
        "            \"summary\": summary.strip(),\n",
        "            \"predicted_outcome\": predicted_outcome\n",
        "        }\n",
        "\n",
        "    def save_agent(self, save_path=\"/content/drive/MyDrive/Argumate/checkpoints/supporting_precedents_agent\"):\n",
        "        os.makedirs(save_path, exist_ok=True)\n",
        "        self.embedder.save(os.path.join(save_path, \"embedder\"))\n",
        "        print(f\" SupportingPrecedentsAgent checkpoint saved at {save_path}\")\n",
        "\n",
        "\n",
        "supporting_agent = SupportingPrecedentsAgent()\n",
        "supporting_agent.build_index()\n",
        "supporting_agent.save_agent()\n",
        "print(\" SupportingPrecedentsAgent initialized & saved.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "o5Idgob-Tebh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "05c5a849-34d5-4fa8-907a-bb64f97eb5c0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Running Supporting Precedents Agent...\n",
            "\n",
            "\n",
            " Retrieved 3 candidate precedents.\n",
            "\n",
            "###  Supporting Precedents Summary ###\n",
            "Predicted Outcome: Violation\n",
            "LLM Summary: On 12 | The applicant, a Belgian national born in 1964, was arrested on suspicion of violent robbery and unlawful possession of weapons. On 12 | The applicant, a Belgian national born in 1964, was arrested on suspicion of violent robbery and unlawful possession of weapons.\n",
            "\n",
            "Top Retrieved Precedents:\n",
            "1. The applicant was born in 1964 and lives in Krivoborye, Voronezh Region. On 25 July 2001 the applicant was arrested on suspicion of robbery. On 27 July 2001 the Prosecutor ordered the pre-trial detent...\n",
            "2. The applicant was born in 1981 and lives in the Kharkiv Region. On 11 October 2001 the police arrested him on suspicion of violent robbery and unlawful possession of weapons. On 12 October 2001 the Va...\n",
            "3. The applicant, a Belgian national born in 1964, was arrested on 14 November 1992 for an assault causing its victim to be certified unfit for work, having attacked his ex-wife with a hammer. He was pla...\n"
          ]
        }
      ],
      "source": [
        "\n",
        "test_case_text = \"\"\"\n",
        "The applicant was detained for over a year without judicial review or access to counsel,\n",
        "alleging violation of Article 5 and 6 of the European Convention on Human Rights.\n",
        "\"\"\"\n",
        "\n",
        "print(\"\\nRunning Supporting Precedents Agent...\\n\")\n",
        "support_result = supporting_agent.retrieve_supporting(\n",
        "    query_text=test_case_text,\n",
        "    predicted_outcome=\"Violation\"\n",
        ")\n",
        "\n",
        "print(\"\\n###  Supporting Precedents Summary ###\")\n",
        "print(\"Predicted Outcome:\", support_result[\"predicted_outcome\"])\n",
        "print(\"LLM Summary:\", support_result[\"summary\"])\n",
        "print(\"\\nTop Retrieved Precedents:\")\n",
        "for i, p in enumerate(support_result[\"supporting_precedents\"], 1):\n",
        "    print(f\"{i}. {p[:200]}...\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PqKXuCtkXxMO"
      },
      "source": [
        "STAGE 5: Counter-Argument Generation Agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "jS4wPnOn4kM7"
      },
      "outputs": [],
      "source": [
        "!pip install -q transformers sentence-transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "7HdivUzNEzhi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "98a00457-c875-4689-9a44-0f90bd16e116"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading CounterArgument model 'google/flan-t5-small' on cpu ...\n",
            "CounterArgumentAgent model loaded.\n"
          ]
        }
      ],
      "source": [
        "import os, json, re, textwrap\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "\n",
        "\n",
        "SAVE_DIR = \"/content/drive/MyDrive/Argumate/checkpoints/counterarg_agent\"\n",
        "os.makedirs(SAVE_DIR, exist_ok=True)\n",
        "MODEL_NAME = \"google/flan-t5-small\"\n",
        "MAX_INPUT = 900\n",
        "MAX_NEW_TOKENS = 200\n",
        "\n",
        "\n",
        "def _to_str(x):\n",
        "    if isinstance(x, list):\n",
        "        return \" \".join(map(str, x))\n",
        "    if x is None:\n",
        "        return \"\"\n",
        "    return str(x)\n",
        "\n",
        "class CounterArgumentAgent:\n",
        "    def __init__(self, model_name=MODEL_NAME, device=None):\n",
        "        self.model_name = model_name\n",
        "        self.device = device if device is not None else (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        self.model = None\n",
        "        self.tokenizer = None\n",
        "        try:\n",
        "            print(f\"Loading CounterArgument model '{model_name}' on {self.device} ...\")\n",
        "            self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "            self.model = AutoModelForSeq2SeqLM.from_pretrained(model_name).to(self.device)\n",
        "            self.model.eval()\n",
        "            print(\"CounterArgumentAgent model loaded.\")\n",
        "        except Exception as e:\n",
        "            print(\"Could not load flan-t5 model (fallback to rule-based):\", e)\n",
        "            self.model = None\n",
        "            self.tokenizer = None\n",
        "\n",
        "    def _rule_fallback(self, case_text, precedents):\n",
        "\n",
        "        case_text = _to_str(case_text).lower()\n",
        "        pts = []\n",
        "\n",
        "        if \"detain\" in case_text or \"detention\" in case_text:\n",
        "            pts.append({\n",
        "                \"title\": \"Lawful Detention / Reasonable Grounds\",\n",
        "                \"legal_rationale\": \"The respondent may argue that lawful detention was based on reasonable, articulable grounds and due process was followed in initial stages.\",\n",
        "                \"supporting_precedents\": precedents[:2],\n",
        "                \"weakness\": \"May be undermined if procedural safeguards were absent.\"\n",
        "            })\n",
        "        else:\n",
        "            pts.append({\n",
        "                \"title\": \"Lack of Causal Link\",\n",
        "                \"legal_rationale\": \"The respondent may assert that the alleged act does not meet the threshold for Convention breach due to lack of proximate causal link.\",\n",
        "                \"supporting_precedents\": precedents[:2],\n",
        "                \"weakness\": \"Requires factual proof which may be contested.\"\n",
        "            })\n",
        "\n",
        "        pts.append({\n",
        "            \"title\": \"Domestic Remedies / Exhaustion\",\n",
        "            \"legal_rationale\": \"The respondent can point to available domestic remedies not exhausted by the applicant, which may render the application inadmissible.\",\n",
        "            \"supporting_precedents\": precedents[:2],\n",
        "            \"weakness\": \"If domestic remedies were ineffective, this will not hold.\"\n",
        "        })\n",
        "        pts.append({\n",
        "            \"title\": \"Proportionality & Margin of Appreciation\",\n",
        "            \"legal_rationale\": \"Even if interference occurred, the respondent may argue it fell within the State's margin of appreciation and was proportionate to a legitimate aim.\",\n",
        "            \"supporting_precedents\": precedents[:2],\n",
        "            \"weakness\": \"Less persuasive where fundamental rights were at stake.\"\n",
        "        })\n",
        "        return pts[:3]\n",
        "\n",
        "    def generate_counterarguments(self, case_text, precedents=None, num_counterpoints=3):\n",
        "        precedents = [ _to_str(p) for p in (precedents or []) ]\n",
        "        case_text = _to_str(case_text)[:MAX_INPUT]\n",
        "\n",
        "        if self.model is None:\n",
        "            print(\"Using rule-based counterargument generator (safe fallback).\")\n",
        "            return self._rule_fallback(case_text, precedents)\n",
        "\n",
        "\n",
        "        prompt = textwrap.dedent(f\"\"\"\n",
        "        You are a defending legal counsel drafting structured counter-arguments against an applicant's claim.\n",
        "        Produce {num_counterpoints} numbered counterpoints. Each counterpoint must include:\n",
        "        - Title\n",
        "        - Legal Rationale: 3-5 sentences explaining why this limits or undermines the applicant's claim.\n",
        "        - Supporting Precedents: list 1-2 short citations (if available).\n",
        "        - Weakness: one short sentence.\n",
        "\n",
        "        Case facts (short):\n",
        "        {case_text}\n",
        "\n",
        "        Top precedents (short snippets):\n",
        "        {chr(10).join(precedents[:4]) if precedents else \"None\"}\n",
        "        \"\"\").strip()\n",
        "\n",
        "        inputs = self.tokenizer(prompt, return_tensors=\"pt\", truncation=True, padding=True, max_length=1024).to(self.device)\n",
        "        with torch.no_grad():\n",
        "            outs = self.model.generate(\n",
        "                **inputs,\n",
        "                max_length=inputs[\"input_ids\"].shape[1] + MAX_NEW_TOKENS,\n",
        "                num_beams=4,\n",
        "                early_stopping=True,\n",
        "                no_repeat_ngram_size=3,\n",
        "                length_penalty=1.0,\n",
        "                do_sample=False\n",
        "            )\n",
        "        gen = self.tokenizer.decode(outs[0], skip_special_tokens=True).strip()\n",
        "\n",
        "\n",
        "        gen_norm = re.sub(r\"[^\\x00-\\x7F]+\", \" \", gen)\n",
        "\n",
        "        parts = re.split(r\"\\n\\s*(?:\\d+[\\.\\)]\\s+)\", gen_norm)\n",
        "\n",
        "        pts = []\n",
        "        for p in parts[1:1+num_counterpoints]:\n",
        "            p = p.strip()\n",
        "            if not p:\n",
        "                continue\n",
        "\n",
        "            lines = [l for l in p.split(\"\\n\") if l.strip()]\n",
        "            title = lines[0][:120] if lines else \"Counterpoint\"\n",
        "            body = \" \".join(lines[1:]).strip()\n",
        "\n",
        "            supp = []\n",
        "            weak = \"\"\n",
        "\n",
        "            m_supp = re.search(r\"(Supporting Precedents[:\\-]\\s*)(.+?)(?:Weakness[:\\-]|\\Z)\", p, flags=re.I|re.S)\n",
        "            if m_supp:\n",
        "                supp_text = m_supp.group(2).strip()\n",
        "\n",
        "                supp = [s.strip() for s in re.split(r\"[;,\\n]\", supp_text) if s.strip()][:2]\n",
        "            m_weak = re.search(r\"Weakness[:\\-]\\s*(.+)\", p, flags=re.I|re.S)\n",
        "            if m_weak:\n",
        "                weak = m_weak.group(1).strip().split(\"\\n\")[0]\n",
        "            pts.append({\n",
        "                \"title\": title,\n",
        "                \"legal_rationale\": body[:900],\n",
        "                \"supporting_precedents\": supp,\n",
        "                \"weakness\": weak\n",
        "            })\n",
        "\n",
        "        if len(pts) < num_counterpoints:\n",
        "            fb = self._rule_fallback(case_text, precedents)\n",
        "            return fb\n",
        "        return pts\n",
        "\n",
        "    def save_agent(self, path=SAVE_DIR):\n",
        "        if self.model is not None and self.tokenizer is not None:\n",
        "            self.model.save_pretrained(path)\n",
        "            self.tokenizer.save_pretrained(path)\n",
        "            print(f\"Saved CounterArgumentAgent model to {path}\")\n",
        "        else:\n",
        "            print(\"Model not available  nothing saved.\")\n",
        "\n",
        "\n",
        "counter_agent = CounterArgumentAgent()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "demo_case = \"\"\"\n",
        "The applicant was detained for over a year without judicial review or access to counsel,\n",
        "alleging violation of Article 5 and 6 of the European Convention on Human Rights.\n",
        "\"\"\"\n",
        "\n",
        "demo_precedents = [\n",
        "    \"Lawless v. Ireland (1961): preventive detention during emergency justified.\",\n",
        "    \"Brogan v. UK (1988): short-term detention without judicial review under certain conditions.\",\n",
        "    \"Akdivar v. Turkey (1996): exhaustion of domestic remedies required before admissibility.\"\n",
        "]\n",
        "\n",
        "print(\"\\n==================== RUNNING COUNTER-ARGUMENT AGENT ====================\\n\")\n",
        "counter_output = counter_agent.generate_counterarguments(\n",
        "    case_text=demo_case,\n",
        "    precedents=demo_precedents,\n",
        "    num_counterpoints=3\n",
        ")\n",
        "\n",
        "print(\"\\n###  Counter-Arguments Generated ###\\n\")\n",
        "for i, cp in enumerate(counter_output, 1):\n",
        "    print(f\"  Counterpoint {i}\")\n",
        "    print(f\" Title: {cp.get('title','N/A')}\")\n",
        "    print(f\" Legal Rationale: {cp.get('legal_rationale','N/A')[:600]}\")\n",
        "    print(f\" Supporting Precedents: {cp.get('supporting_precedents','N/A')}\")\n",
        "    print(f\" Weakness: {cp.get('weakness','N/A')}\")\n",
        "    print(\"-\" * 90)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ayaNcHayTbJX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "93c1b74f-daea-4167-a560-8a6e669537f5"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================== RUNNING COUNTER-ARGUMENT AGENT ====================\n",
            "\n",
            "\n",
            "###  Counter-Arguments Generated ###\n",
            "\n",
            "  Counterpoint 1\n",
            " Title: Lawful Detention / Reasonable Grounds\n",
            " Legal Rationale: The respondent may argue that lawful detention was based on reasonable, articulable grounds and due process was followed in initial stages.\n",
            " Supporting Precedents: ['Lawless v. Ireland (1961): preventive detention during emergency justified.', 'Brogan v. UK (1988): short-term detention without judicial review under certain conditions.']\n",
            " Weakness: May be undermined if procedural safeguards were absent.\n",
            "------------------------------------------------------------------------------------------\n",
            "  Counterpoint 2\n",
            " Title: Domestic Remedies / Exhaustion\n",
            " Legal Rationale: The respondent can point to available domestic remedies not exhausted by the applicant, which may render the application inadmissible.\n",
            " Supporting Precedents: ['Lawless v. Ireland (1961): preventive detention during emergency justified.', 'Brogan v. UK (1988): short-term detention without judicial review under certain conditions.']\n",
            " Weakness: If domestic remedies were ineffective, this will not hold.\n",
            "------------------------------------------------------------------------------------------\n",
            "  Counterpoint 3\n",
            " Title: Proportionality & Margin of Appreciation\n",
            " Legal Rationale: Even if interference occurred, the respondent may argue it fell within the State's margin of appreciation and was proportionate to a legitimate aim.\n",
            " Supporting Precedents: ['Lawless v. Ireland (1961): preventive detention during emergency justified.', 'Brogan v. UK (1988): short-term detention without judicial review under certain conditions.']\n",
            " Weakness: Less persuasive where fundamental rights were at stake.\n",
            "------------------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J6vFGMoAqTQY"
      },
      "source": [
        "confidence evaluator agent"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "predictor_agent = OutcomePredictorAgent()\n",
        "reasoning_agent = ReasoningPlanningAgent(predictor_agent=predictor_agent)\n",
        "supporting_agent = SupportingPrecedentsAgent()\n",
        "supporting_agent.build_index()\n",
        "counter_agent = CounterArgumentAgent()\n"
      ],
      "metadata": {
        "id": "3fNUW21WiaND",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260,
          "referenced_widgets": [
            "1ef4fbb218544265908e43bff472d484",
            "265b6a6f386f441890cd871874c65e70",
            "0d720fc7ff8648e8a36a0b29ab557066",
            "c8c2ba343b3e48e188abda7e2a483cfc",
            "a4c98cfeb8424e959c9534c51a3305da",
            "a9d5461ecffc41b7b5f912da9b5f2405",
            "fa505698dace49319998aac939ba1eaa",
            "b28a0113d21c4a75af8b3aa203dea87a",
            "313a21fe8439409a96d65ab401052fc0",
            "5b0cf34ff81d4b3494bca46c5f6d96c4",
            "55e55cc0d3e34df89247027a03a17232"
          ]
        },
        "outputId": "95d53818-0984-4091-9a2b-fdf85de133d0"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Lightweight reasoning LLM (distilgpt2) loaded.\n",
            "Loading reasoning model: google/flan-t5-small \n",
            " ReasoningPlanningAgent loaded and ready.\n",
            "Initializing SupportingPrecedentsAgent...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Model and reasoning LLM loaded.\n",
            "Building FAISS index for 1000 cases...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Batches:   0%|          | 0/32 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1ef4fbb218544265908e43bff472d484"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " FAISS index ready for retrieval.\n",
            "Loading CounterArgument model 'google/flan-t5-small' on cpu ...\n",
            "CounterArgumentAgent model loaded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "5WwgBHwIe4Z3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1948b7a4-a211-4315-d7f7-006d2d032f9e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " EvaluatorAgent initialized with FLAN-T5 for lightweight scoring.\n",
            "EvaluatorAgent checkpoint saved at /content/drive/MyDrive/Argumate/checkpoints/evaluator_agent.pkl\n",
            "EvaluatorAgent initialized successfully.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import os, json, numpy as np, re\n",
        "from transformers import pipeline\n",
        "from datetime import datetime\n",
        "\n",
        "CONF_THRESHOLD = 0.75\n",
        "MAX_LOOPS = 3\n",
        "SAVE_REPORTS = True\n",
        "RESULTS_DIR = \"/content/drive/MyDrive/Argumate/results\"\n",
        "os.makedirs(RESULTS_DIR, exist_ok=True)\n",
        "\n",
        "class EvaluatorAgent:\n",
        "    def __init__(self, predictor_agent, reasoning_agent, supporting_agent, counter_agent,\n",
        "                 threshold=CONF_THRESHOLD, max_loops=MAX_LOOPS):\n",
        "        self.predictor_agent = predictor_agent\n",
        "        self.reasoning_agent = reasoning_agent\n",
        "        self.supporting_agent = supporting_agent\n",
        "        self.counter_agent = counter_agent\n",
        "        self.threshold = threshold\n",
        "        self.max_loops = max_loops\n",
        "\n",
        "        try:\n",
        "            self.llm = pipeline(\"text2text-generation\", model=\"google/flan-t5-small\", device_map=\"auto\")\n",
        "            print(\" EvaluatorAgent initialized with FLAN-T5 for lightweight scoring.\")\n",
        "        except Exception as e:\n",
        "            print(\" Could not load FLAN model:\", e)\n",
        "            self.llm = None\n",
        "\n",
        "\n",
        "    def _safe_text(self, x):\n",
        "        if isinstance(x, list): return \" \".join(map(str, x))\n",
        "        if not isinstance(x, str): return str(x)\n",
        "        return x.strip()\n",
        "\n",
        "    def _compute_confidence(self, reasoning, precedents, counterargs):\n",
        "        \"\"\"LLM-based or fallback heuristic scoring\"\"\"\n",
        "        try:\n",
        "            prompt = f\"\"\"\n",
        "You are a legal evaluator assessing robustness and logical strength.\n",
        "\n",
        "Reasoning Summary:\n",
        "{reasoning.get('analysis','')[:300]}\n",
        "\n",
        "Supporting Precedents:\n",
        "{', '.join(precedents[:2])}\n",
        "\n",
        "Counter Arguments:\n",
        "{' | '.join([c.get('title','') for c in counterargs])}\n",
        "\n",
        "Rate overall legal reasoning confidence (0-1).\n",
        "Respond only as JSON: {{'confidence_score': float}}\n",
        "\"\"\"\n",
        "            if self.llm:\n",
        "                gen = self.llm(prompt, max_new_tokens=80)[0][\"generated_text\"]\n",
        "                match = re.search(r\"\\{.*\\}\", gen)\n",
        "                if match:\n",
        "                    data = json.loads(match.group())\n",
        "                    return float(data.get(\"confidence_score\", 0.5))\n",
        "        except Exception:\n",
        "            pass\n",
        "\n",
        "        score = 0.6\n",
        "        if len(reasoning.get(\"analysis\", \"\")) > 100: score += 0.1\n",
        "        if len(precedents) >= 2: score += 0.1\n",
        "        if len(counterargs) >= 2: score += 0.1\n",
        "        return min(score, 1.0)\n",
        "\n",
        "    def evaluate_case(self, case_text):\n",
        "        \"\"\"Main evaluation loop\"\"\"\n",
        "        case_text = self._safe_text(case_text)\n",
        "        print(\"\\n EvaluatorAgent: Starting pipeline...\\n\")\n",
        "\n",
        "        for loop in range(self.max_loops):\n",
        "            print(f\"\\n=== Iteration {loop+1}/{self.max_loops} ===\")\n",
        "\n",
        "            pred = self.predictor_agent.predict(case_text)\n",
        "            outcome = pred.get(\"outcome\", \"Unknown\")\n",
        "            print(\" Predicted Outcome:\", outcome)\n",
        "\n",
        "            support = self.supporting_agent.retrieve_supporting(case_text, predicted_outcome=outcome, k=3)\n",
        "            precedents = support.get(\"supporting_precedents\", [])\n",
        "\n",
        "\n",
        "            reasoning = self.reasoning_agent.generate_reasoning(case_text, predicted_outcome=outcome, precedents=precedents)\n",
        "\n",
        "\n",
        "            counterargs = self.counter_agent.generate_counterarguments(case_text, precedents=precedents)\n",
        "\n",
        "\n",
        "            conf = self._compute_confidence(reasoning, precedents, counterargs)\n",
        "            print(f\" Confidence Score: {conf:.2f}\")\n",
        "\n",
        "            if conf >= self.threshold:\n",
        "                print(\" High confidence reached. Finalizing structured output.\")\n",
        "                result = {\n",
        "                    \"predicted_outcome\": outcome,\n",
        "                    \"confidence_score\": round(conf, 3),\n",
        "                    \"reasoning_plan\": reasoning,\n",
        "                    \"top_precedents\": precedents[:3],\n",
        "                    \"counter_arguments\": counterargs,\n",
        "                    \"final_decision\": f\"Outcome '{outcome}' accepted with confidence {conf:.2f}.\"\n",
        "                }\n",
        "                if SAVE_REPORTS:\n",
        "                    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "                    path = os.path.join(RESULTS_DIR, f\"evaluation_{timestamp}.json\")\n",
        "                    with open(path, \"w\", encoding=\"utf-8\") as f:\n",
        "                        json.dump(result, f, indent=2, ensure_ascii=False)\n",
        "                    print(f\"Report saved to {path}\")\n",
        "                return result\n",
        "            else:\n",
        "                print(\" Confidence below threshold  looping again.\\n\")\n",
        "\n",
        "        print(\" Max loops reached. Returning best effort result.\")\n",
        "        return {\n",
        "            \"predicted_outcome\": outcome,\n",
        "            \"confidence_score\": round(conf, 3),\n",
        "            \"reasoning_plan\": reasoning,\n",
        "            \"top_precedents\": precedents[:3],\n",
        "            \"counter_arguments\": counterargs,\n",
        "            \"final_decision\": f\"Confidence remained below threshold ({conf:.2f}). Returned for manual review.\"\n",
        "        }\n",
        "\n",
        "    def save_agent(self, save_path=\"/content/drive/MyDrive/Argumate/checkpoints/evaluator_agent.pkl\"):\n",
        "        import pickle\n",
        "        os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
        "        with open(save_path, \"wb\") as f:\n",
        "            pickle.dump({\"threshold\": self.threshold, \"max_loops\": self.max_loops}, f)\n",
        "        print(f\"EvaluatorAgent checkpoint saved at {save_path}\")\n",
        "\n",
        "\n",
        "evaluator_agent = EvaluatorAgent(\n",
        "    predictor_agent=predictor_agent,\n",
        "    reasoning_agent=reasoning_agent,\n",
        "    supporting_agent=supporting_agent,\n",
        "    counter_agent=counter_agent\n",
        ")\n",
        "evaluator_agent.save_agent()\n",
        "print(\"EvaluatorAgent initialized successfully.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "YT66TCougLSR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9322f8de-0602-4451-b0d7-abdcf543b089"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================ RUNNING EVALUATOR AGENT ================\n",
            "\n",
            "\n",
            " EvaluatorAgent: Starting pipeline...\n",
            "\n",
            "\n",
            "=== Iteration 1/3 ===\n",
            " Predicted Outcome: Violation\n",
            "\n",
            " Retrieved 3 candidate precedents.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (2678 > 512). Running this sequence through the model will result in indexing errors\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Confidence Score: 0.90\n",
            " High confidence reached. Finalizing structured output.\n",
            "Report saved to /content/drive/MyDrive/Argumate/results/evaluation_20251113_111706.json\n",
            "\n",
            "###  FINAL STRUCTURED OUTPUT ###\n",
            "\n",
            "Predicted Outcome: Violation\n",
            "Confidence Score: 0.9\n",
            "Final Decision: Outcome 'Violation' accepted with confidence 0.90.\n",
            "\n",
            " Reasoning Summary:\n",
            "\n",
            "Facts are compared to precedents (The applicant was born in 1959 and lives in Goleniw, Poland. On 19 June 2000 the applicant was arrested on suspicion of | The applicant was born in 1981 and lives in the Kharkiv Region. On 11 October 2001 the police arrested him on suspicion ); the similarity indicates same pattern of violation. \n",
            "\n",
            " Top Supporting Precedents:\n",
            " 1. The applicant was born in 1959 and lives in Goleniw, Poland. On 19 June 2000 the applicant was arrested on suspicion of killing D.L., his fiance. On 20 June 2000 the winoujcie District Court (Sd Rejonowy) ordered hi...\n",
            "\n",
            " 2. The applicant was born in 1981 and lives in the Kharkiv Region. On 11 October 2001 the police arrested him on suspicion of violent robbery and unlawful possession of weapons. On 12 October 2001 the Valky Court ordered th...\n",
            "\n",
            " 3. The applicant is a Dutch national, born in 1959, and was detained at the time of the introduction of the application. He is represented before the Court by Mr G. Spong, a lawyer practising in The Hague. A. In its judgmen...\n",
            "\n",
            " Counter-Arguments:\n",
            " 1. Lawful Detention / Reasonable Grounds  The respondent may argue that lawful detention was based on reasonable, articulable grounds and due process was followed in initial stages.\n",
            " 2. Domestic Remedies / Exhaustion  The respondent can point to available domestic remedies not exhausted by the applicant, which may render the application inadmissible.\n",
            " 3. Proportionality & Margin of Appreciation  Even if interference occurred, the respondent may argue it fell within the State's margin of appreciation and was proportionate to a legitimate aim.\n",
            "\n",
            " Evaluation report saved:\n",
            " - JSON: /content/drive/MyDrive/Argumate/results/evaluation_testcase_20251113_111706.json\n",
            " - TXT:  /content/drive/MyDrive/Argumate/results/evaluation_testcase_20251113_111706.txt\n"
          ]
        }
      ],
      "source": [
        "\n",
        "sample_case_text = \"\"\"\n",
        "The applicant, Mr. John Doe, was held in pre-trial detention for 14 months without being brought before a judge.\n",
        "He claims that this constitutes a violation of Article 5(3) of the European Convention on Human Rights,\n",
        "which guarantees the right to be brought promptly before a judge. The State argues that the detention\n",
        "was necessary due to national security concerns and ongoing investigations.\n",
        "\"\"\"\n",
        "\n",
        "print(\"\\n================ RUNNING EVALUATOR AGENT ================\\n\")\n",
        "\n",
        "final_result = evaluator_agent.evaluate_case(sample_case_text)\n",
        "\n",
        "\n",
        "print(\"\\n###  FINAL STRUCTURED OUTPUT ###\\n\")\n",
        "print(f\"Predicted Outcome: {final_result['predicted_outcome']}\")\n",
        "print(f\"Confidence Score: {final_result['confidence_score']}\")\n",
        "print(f\"Final Decision: {final_result['final_decision']}\\n\")\n",
        "\n",
        "print(\" Reasoning Summary:\\n\")\n",
        "print(final_result[\"reasoning_plan\"][\"analysis\"][:600], \"\\n\")\n",
        "\n",
        "print(\" Top Supporting Precedents:\")\n",
        "for i, p in enumerate(final_result[\"top_precedents\"], 1):\n",
        "    print(f\" {i}. {p[:220]}...\\n\")\n",
        "\n",
        "print(\" Counter-Arguments:\")\n",
        "for i, c in enumerate(final_result[\"counter_arguments\"], 1):\n",
        "    print(f\" {i}. {c['title']}  {c['legal_rationale'][:220]}\")\n",
        "\n",
        "\n",
        "from datetime import datetime\n",
        "import json, os\n",
        "\n",
        "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "save_dir = \"/content/drive/MyDrive/Argumate/results\"\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "json_path = os.path.join(save_dir, f\"evaluation_testcase_{timestamp}.json\")\n",
        "text_path = os.path.join(save_dir, f\"evaluation_testcase_{timestamp}.txt\")\n",
        "\n",
        "with open(json_path, \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(final_result, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "with open(text_path, \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(json.dumps(final_result, indent=2, ensure_ascii=False))\n",
        "\n",
        "print(f\"\\n Evaluation report saved:\")\n",
        "print(f\" - JSON: {json_path}\")\n",
        "print(f\" - TXT:  {text_path}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "self evaluation/reflection agent"
      ],
      "metadata": {
        "id": "samu0LQgnKLT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import os, json, re\n",
        "from transformers import pipeline\n",
        "from datetime import datetime\n",
        "\n",
        "REASONING_QUALITY_THRESHOLD = 0.8\n",
        "MAX_REFLECTION_LOOPS = 2\n",
        "REFLECT_RESULTS_DIR = \"/content/drive/MyDrive/Argumate/results\"\n",
        "os.makedirs(REFLECT_RESULTS_DIR, exist_ok=True)\n",
        "\n",
        "class ReflectionAgent:\n",
        "    def __init__(self, evaluator_agent, reasoning_agent, supporting_agent, counter_agent,\n",
        "                 quality_threshold=REASONING_QUALITY_THRESHOLD, max_loops=MAX_REFLECTION_LOOPS):\n",
        "        self.evaluator_agent = evaluator_agent\n",
        "        self.reasoning_agent = reasoning_agent\n",
        "        self.supporting_agent = supporting_agent\n",
        "        self.counter_agent = counter_agent\n",
        "        self.quality_threshold = quality_threshold\n",
        "        self.max_loops = max_loops\n",
        "\n",
        "        try:\n",
        "            self.llm = pipeline(\"text2text-generation\", model=\"google/flan-t5-small\", device_map=\"auto\")\n",
        "            print(\"ReflectionAgent initialized with FLAN-T5 for meta-evaluation.\")\n",
        "        except Exception as e:\n",
        "            print(\" Could not load FLAN-T5:\", e)\n",
        "            self.llm = None\n",
        "\n",
        "\n",
        "    def _evaluate_reasoning_quality(self, reasoning_plan):\n",
        "        try:\n",
        "            prompt = f\"\"\"\n",
        "You are a legal reviewer evaluating the **quality of reasoning** in a judicial decision.\n",
        "Criteria: clarity, logical flow, citation use, and legal soundness (0 to 1 scale).\n",
        "\n",
        "Reasoning:\n",
        "ISSUE: {reasoning_plan.get('issue','')}\n",
        "FACTS SUMMARY: {reasoning_plan.get('facts_summary','')}\n",
        "LEGAL ANALYSIS: {reasoning_plan.get('analysis','')}\n",
        "CONCLUSION: {reasoning_plan.get('conclusion','')}\n",
        "\n",
        "Respond strictly as JSON: {{'reasoning_quality': float, 'review_comment': str}}\n",
        "\"\"\"\n",
        "            if self.llm:\n",
        "                gen = self.llm(prompt, max_new_tokens=100)[0][\"generated_text\"]\n",
        "                match = re.search(r\"\\{.*\\}\", gen)\n",
        "                if match:\n",
        "                    data = json.loads(match.group())\n",
        "                    score = float(data.get(\"reasoning_quality\", 0.6))\n",
        "                    comment = data.get(\"review_comment\", \"\")\n",
        "                    return score, comment\n",
        "        except Exception:\n",
        "            pass\n",
        "        # Heuristic fallback\n",
        "        text_len = len(reasoning_plan.get(\"analysis\", \"\")) + len(reasoning_plan.get(\"conclusion\", \"\"))\n",
        "        score = 0.5 + min(text_len / 1000, 0.4)\n",
        "        return round(min(score, 1.0), 2), \"Heuristic quality estimate based on length and structure.\"\n",
        "\n",
        "\n",
        "    def reflect(self, case_text):\n",
        "        print(\"\\n Starting ReflectionAgent loop...\\n\")\n",
        "        current_result = self.evaluator_agent.evaluate_case(case_text)\n",
        "\n",
        "        for loop in range(self.max_loops):\n",
        "            reasoning = current_result.get(\"reasoning_plan\", {})\n",
        "            quality_score, review_comment = self._evaluate_reasoning_quality(reasoning)\n",
        "            print(f\"Iteration {loop+1}/{self.max_loops}  Reasoning Quality: {quality_score:.2f}\")\n",
        "            print(\"Review:\", review_comment)\n",
        "\n",
        "            if quality_score >= self.quality_threshold:\n",
        "                print(\"Reasoning quality acceptable. Final output confirmed.\")\n",
        "                current_result[\"reasoning_quality\"] = quality_score\n",
        "                current_result[\"review_comment\"] = review_comment\n",
        "                current_result[\"final_reflection_status\"] = \"Accepted\"\n",
        "                break\n",
        "            else:\n",
        "                print(\"Reasoning quality low  regenerating reasoning and reevaluating.\")\n",
        "\n",
        "                outcome = current_result[\"predicted_outcome\"]\n",
        "                precedents = current_result[\"top_precedents\"]\n",
        "                new_reasoning = self.reasoning_agent.generate_reasoning(case_text, outcome, precedents)\n",
        "                counterargs = self.counter_agent.generate_counterarguments(case_text, precedents=precedents)\n",
        "\n",
        "                current_result = self.evaluator_agent.evaluate_case(case_text)\n",
        "                current_result[\"reasoning_quality_prev\"] = quality_score\n",
        "\n",
        "\n",
        "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "        save_path = os.path.join(REFLECT_RESULTS_DIR, f\"reflection_{timestamp}.json\")\n",
        "        with open(save_path, \"w\", encoding=\"utf-8\") as f:\n",
        "            json.dump(current_result, f, indent=2, ensure_ascii=False)\n",
        "        print(f\" Reflection report saved to {save_path}\")\n",
        "        return current_result\n",
        "\n",
        "    def save_agent(self, path=\"/content/drive/MyDrive/Argumate/checkpoints/reflection_agent.pkl\"):\n",
        "        import pickle\n",
        "        os.makedirs(os.path.dirname(path), exist_ok=True)\n",
        "        with open(path, \"wb\") as f:\n",
        "            pickle.dump({\"quality_threshold\": self.quality_threshold, \"max_loops\": self.max_loops}, f)\n",
        "        print(f\" ReflectionAgent checkpoint saved at {path}\")\n",
        "\n",
        "\n",
        "reflection_agent = ReflectionAgent(\n",
        "    evaluator_agent=evaluator_agent,\n",
        "    reasoning_agent=reasoning_agent,\n",
        "    supporting_agent=supporting_agent,\n",
        "    counter_agent=counter_agent\n",
        ")\n",
        "reflection_agent.save_agent()\n",
        "print(\"ReflectionAgent initialized successfully.\")\n"
      ],
      "metadata": {
        "id": "txSlR89ynLkE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8270fad8-780f-48be-b61c-881978fd4ad9"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ReflectionAgent initialized with FLAN-T5 for meta-evaluation.\n",
            " ReflectionAgent checkpoint saved at /content/drive/MyDrive/Argumate/checkpoints/reflection_agent.pkl\n",
            "ReflectionAgent initialized successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "sample_case_text = \"\"\"\n",
        "The applicant, Ms. Maria Lopez, alleged a breach of her right to private and family life under Article 8\n",
        "after police surveillance operations recorded her conversations for over a year without judicial authorization.\n",
        "The government argued that the measure was justified for national security reasons.\n",
        "\"\"\"\n",
        "\n",
        "print(\"\\n================ RUNNING REFLECTION AGENT ================\\n\")\n",
        "\n",
        "final_reflection = reflection_agent.reflect(sample_case_text)\n",
        "\n",
        "print(\"\\n###  FINAL REFLECTION OUTPUT ###\\n\")\n",
        "print(f\"Predicted Outcome: {final_reflection['predicted_outcome']}\")\n",
        "print(f\"Confidence Score: {final_reflection['confidence_score']}\")\n",
        "print(f\"Reasoning Quality: {final_reflection.get('reasoning_quality', 'N/A')}\")\n",
        "print(f\"Final Status: {final_reflection.get('final_reflection_status', 'N/A')}\")\n",
        "print(f\"Review Comment: {final_reflection.get('review_comment', '')[:300]}\")\n"
      ],
      "metadata": {
        "id": "YPPFTODtndPr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d9f91d7-8eb2-4641-d8e6-ef4f9a9341b4"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================ RUNNING REFLECTION AGENT ================\n",
            "\n",
            "\n",
            " Starting ReflectionAgent loop...\n",
            "\n",
            "\n",
            " EvaluatorAgent: Starting pipeline...\n",
            "\n",
            "\n",
            "=== Iteration 1/3 ===\n",
            " Predicted Outcome: Violation\n",
            "\n",
            " Retrieved 3 candidate precedents.\n",
            " Confidence Score: 0.90\n",
            " High confidence reached. Finalizing structured output.\n",
            "Report saved to /content/drive/MyDrive/Argumate/results/evaluation_20251113_111842.json\n",
            "Iteration 1/2  Reasoning Quality: 0.87\n",
            "Review: Heuristic quality estimate based on length and structure.\n",
            "Reasoning quality acceptable. Final output confirmed.\n",
            " Reflection report saved to /content/drive/MyDrive/Argumate/results/reflection_20251113_111849.json\n",
            "\n",
            "###  FINAL REFLECTION OUTPUT ###\n",
            "\n",
            "Predicted Outcome: Violation\n",
            "Confidence Score: 0.9\n",
            "Reasoning Quality: 0.87\n",
            "Final Status: Accepted\n",
            "Review Comment: Heuristic quality estimate based on length and structure.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "memory/context update"
      ],
      "metadata": {
        "id": "ivlo16FBoVJZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import os, json, faiss, numpy as np, pickle\n",
        "from datetime import datetime\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from transformers import pipeline\n",
        "\n",
        "MEMORY_DIR = \"/content/drive/MyDrive/Argumate/checkpoints/dynamic_memory\"\n",
        "os.makedirs(MEMORY_DIR, exist_ok=True)\n",
        "\n",
        "class MemoryContextUpdateAgent:\n",
        "    def __init__(self,\n",
        "                 embedder_name=\"sentence-transformers/paraphrase-MiniLM-L6-v2\",\n",
        "                 llm_name=\"google/flan-t5-small\",\n",
        "                 memory_path=os.path.join(MEMORY_DIR, \"context_memory.pkl\")):\n",
        "        print(\"Initializing MemoryContextUpdateAgent...\")\n",
        "        self.embedder_name = embedder_name\n",
        "        self.embedder = SentenceTransformer(embedder_name)\n",
        "        self.memory_path = memory_path\n",
        "        self.llm_name = llm_name\n",
        "\n",
        "\n",
        "        try:\n",
        "            self.llm = pipeline(\"text2text-generation\", model=llm_name, device_map=\"auto\")\n",
        "            print(\" Light LLM loaded for case summarization.\")\n",
        "        except Exception as e:\n",
        "            print(\" Could not load Flan LLM (fallback to simple summary):\", e)\n",
        "            self.llm = None\n",
        "\n",
        "\n",
        "        if os.path.exists(memory_path):\n",
        "            with open(memory_path, \"rb\") as f:\n",
        "                saved = pickle.load(f)\n",
        "            self.memory_corpus = saved.get(\"corpus\", [])\n",
        "            self.embeddings = np.array(saved.get(\"embeddings\", []), dtype=\"float32\")\n",
        "            dim = self.embeddings.shape[1] if self.embeddings.size > 0 else 384\n",
        "            self.index = faiss.IndexFlatL2(dim)\n",
        "            if self.embeddings.size > 0:\n",
        "                self.index.add(self.embeddings)\n",
        "            print(f\" Loaded existing memory with {len(self.memory_corpus)} cases.\")\n",
        "        else:\n",
        "            self.memory_corpus = []\n",
        "            self.embeddings = np.empty((0, 384), dtype=\"float32\")\n",
        "            self.index = faiss.IndexFlatL2(384)\n",
        "            print(\" Created new memory index.\")\n",
        "\n",
        "\n",
        "    def _summarize_case(self, reflection_output):\n",
        "        reasoning = reflection_output.get(\"reasoning_plan\", {})\n",
        "        outcome = reflection_output.get(\"predicted_outcome\", \"\")\n",
        "        facts = reasoning.get(\"facts_summary\", \"\")\n",
        "        analysis = reasoning.get(\"analysis\", \"\")\n",
        "        conclusion = reasoning.get(\"conclusion\", \"\")\n",
        "\n",
        "        prompt = f\"\"\"\n",
        "You are a legal summarizer. Create a compact memory entry (3-4 sentences)\n",
        "combining key facts, reasoning, and outcome.\n",
        "\n",
        "Facts: {facts}\n",
        "Analysis: {analysis}\n",
        "Conclusion: {conclusion}\n",
        "Outcome: {outcome}\n",
        "\"\"\"\n",
        "        if self.llm:\n",
        "            try:\n",
        "                summary = self.llm(prompt, max_new_tokens=120)[0][\"generated_text\"]\n",
        "                return summary.strip()\n",
        "            except Exception:\n",
        "                pass\n",
        "\n",
        "        return f\"Case summary: {facts[:150]}... Outcome: {outcome}. Reasoning: {conclusion}\"\n",
        "\n",
        "    def update_memory(self, reflection_output):\n",
        "        print(\"\\n Updating memory with new case context...\")\n",
        "        summary = self._summarize_case(reflection_output)\n",
        "        emb = self.embedder.encode([summary], convert_to_numpy=True)\n",
        "\n",
        "        self.memory_corpus.append(summary)\n",
        "        if self.embeddings.size == 0:\n",
        "            self.embeddings = emb.astype(\"float32\")\n",
        "        else:\n",
        "            self.embeddings = np.vstack([self.embeddings, emb.astype(\"float32\")])\n",
        "        self.index.add(emb.astype(\"float32\"))\n",
        "\n",
        "\n",
        "        self._save_memory()\n",
        "        print(f\" Added 1 new case. Total stored: {len(self.memory_corpus)}\")\n",
        "        return summary\n",
        "\n",
        "\n",
        "    def _save_memory(self):\n",
        "        with open(self.memory_path, \"wb\") as f:\n",
        "            pickle.dump({\n",
        "                \"corpus\": self.memory_corpus,\n",
        "                \"embeddings\": self.embeddings\n",
        "            }, f)\n",
        "        print(f\" Memory context updated at {self.memory_path}\")\n",
        "\n",
        "    def retrieve_similar(self, query_text, k=3):\n",
        "        if len(self.memory_corpus) == 0:\n",
        "            return []\n",
        "        q_emb = self.embedder.encode([query_text], convert_to_numpy=True)\n",
        "        D, I = self.index.search(q_emb.astype(\"float32\"), k)\n",
        "        return [self.memory_corpus[i] for i in I[0] if i < len(self.memory_corpus)]\n",
        "\n",
        "memory_update_agent = MemoryContextUpdateAgent()\n",
        "print(\"MemoryContextUpdateAgent initialized successfully.\")\n"
      ],
      "metadata": {
        "id": "Wf_kw4CioXNi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fda6114a-45ba-423a-d221-3f59fff8edcb"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initializing MemoryContextUpdateAgent...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Light LLM loaded for case summarization.\n",
            " Loaded existing memory with 128 cases.\n",
            "MemoryContextUpdateAgent initialized successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(\"\\n================ TESTING MEMORY UPDATE AGENT ================\\n\")\n",
        "\n",
        "updated_summary = memory_update_agent.update_memory(final_reflection)\n",
        "print(\"\\n New Memory Entry Summary:\\n\", updated_summary[:400])\n",
        "\n",
        "\n",
        "sample_query = \"A person detained without access to lawyer under Article 5 and 6\"\n",
        "similar_cases = memory_update_agent.retrieve_similar(sample_query)\n",
        "\n",
        "print(\"\\n Retrieved Similar Cases from Memory:\")\n",
        "for i, case in enumerate(similar_cases, 1):\n",
        "    print(f\"{i}. {case[:300]}...\\n\")\n"
      ],
      "metadata": {
        "id": "89m9Hz2bom27",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "21b1469e-20e2-441d-c078-46b9b4f575a4"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================ TESTING MEMORY UPDATE AGENT ================\n",
            "\n",
            "\n",
            " Updating memory with new case context...\n",
            " Memory context updated at /content/drive/MyDrive/Argumate/checkpoints/dynamic_memory/context_memory.pkl\n",
            " Added 1 new case. Total stored: 129\n",
            "\n",
            " New Memory Entry Summary:\n",
            " Fact1: The applicant, Ms. Maria Lopez, alleged a breach of her right to private and family life under Article 8 after police surveillance operations recorded her conversations for over a year without judicial authorization. The government argued that the measure was justified for national security reasons. Fact2: The applicant, Ms. Maria Lopez, alleged a breach of her right to private and family l\n",
            "\n",
            " Retrieved Similar Cases from Memory:\n",
            "1. The applicant was detained for six hours by the police during a peaceful political demonstration. He was questioned and released without charge. He alleges a violation of Articles 5 and 10 of the European Convention on Human Rights, arguing that the detention was arbitrary and interfered with his fr...\n",
            "\n",
            "2. Fact1: The applicant was arrested during a peaceful protest and detained for 48 hours without access to a lawyer. He claims this violated his right to liberty and fair trial under Articles 5 and 6 of the European Convention on Human Rights. He claims this violated his right to liberty and fair trial...\n",
            "\n",
            "3. Fact1: The applicant was briefly detained by police during a protest for questioning. He claims that this violated his rights under Article 10 and Article 11 of the European Convention, as he was expressing political views peacefully. However, the State argues the arrest was preventive and lasted on...\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cell 1  GoalManager + PlanningAgent (hope cell 1)"
      ],
      "metadata": {
        "id": "0aoi3X8U6jEh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import json, os, time\n",
        "from datetime import datetime\n",
        "\n",
        "GOALS_PATH = os.path.join(checkpoint_dir, \"goals.json\")\n",
        "os.makedirs(os.path.dirname(GOALS_PATH), exist_ok=True)\n",
        "\n",
        "class PlanningAgent:\n",
        "    \"\"\"\n",
        "    Creates/maintains a plan for executing the pipeline.\n",
        "    Generates fallback routes when components fail.\n",
        "    Lightweight, CPU-friendly (no new heavy models).\n",
        "    \"\"\"\n",
        "    def __init__(self, default_plan=None):\n",
        "        self.default_plan = default_plan or [\n",
        "            \"fact_analysis\",\n",
        "            \"predict_outcome\",\n",
        "            \"retrieve_memory\",\n",
        "            \"supporting_precedents\",\n",
        "            \"generate_reasoning\",\n",
        "            \"counter_arguments\",\n",
        "            \"evaluate_confidence\",\n",
        "            \"reflect\",\n",
        "            \"update_memory\"\n",
        "        ]\n",
        "\n",
        "    def generate_plan(self, case_text, context=None):\n",
        "\n",
        "        plan = list(self.default_plan)\n",
        "\n",
        "        if len(case_text) < 300 and \"supporting_precedents\" in plan:\n",
        "            plan.remove(\"supporting_precedents\")\n",
        "        return plan\n",
        "\n",
        "    def apply_fallback(self, failed_step, orchestrator):\n",
        "\n",
        "        print(f\" PlanningAgent: fallback triggered for step '{failed_step}'\")\n",
        "        if failed_step == \"generate_reasoning\":\n",
        "\n",
        "            if hasattr(orchestrator.agents.get(\"reasoning\"), \"_fallback_reasoning\"):\n",
        "                print(\" PlanningAgent: switching to rule-based fallback reasoning.\")\n",
        "                return True\n",
        "\n",
        "        return False\n",
        "\n",
        "\n",
        "class GoalManager:\n",
        "    \"\"\"\n",
        "    Orchestrates the end-to-end goal pursuit cycle:\n",
        "     - Loads/saves goals\n",
        "     - Runs a plan generated by PlanningAgent\n",
        "     - Checkpoints progress and results to Drive\n",
        "     - Optionally updates memory automatically\n",
        "    \"\"\"\n",
        "    def __init__(self, agents, planning_agent=None, goals_path=GOALS_PATH, autosave_every=1):\n",
        "        \"\"\"\n",
        "        agents: dict of pre-existing agents, e.g. {\n",
        "            \"fact\": fact_agent, \"predictor\": predictor_agent, \"memory\": memory_agent,\n",
        "            \"supporting\": supporting_agent, \"reasoning\": reasoning_agent,\n",
        "            \"counter\": counter_agent, \"evaluator\": evaluator_agent,\n",
        "            \"reflection\": reflection_agent, \"memory_update\": memory_update_agent\n",
        "        }\n",
        "        \"\"\"\n",
        "        self.agents = agents\n",
        "        self.planner = planning_agent if planning_agent else PlanningAgent()\n",
        "        self.goals_path = goals_path\n",
        "        self.autosave_every = autosave_every\n",
        "        self._load_goals()\n",
        "\n",
        "    def _load_goals(self):\n",
        "        if os.path.exists(self.goals_path):\n",
        "            try:\n",
        "                with open(self.goals_path, \"r\", encoding=\"utf-8\") as f:\n",
        "                    self.goals = json.load(f)\n",
        "                print(f\" Loaded goals from {self.goals_path} (count={len(self.goals)})\")\n",
        "            except Exception as e:\n",
        "                print(\" Could not load goals.json:\", e)\n",
        "                self.goals = []\n",
        "        else:\n",
        "            self.goals = []\n",
        "\n",
        "        if not isinstance(self.goals, list):\n",
        "            self.goals = []\n",
        "\n",
        "    def _save_goals(self):\n",
        "        with open(self.goals_path, \"w\", encoding=\"utf-8\") as f:\n",
        "            json.dump(self.goals, f, indent=2)\n",
        "        print(f\" Goals saved to {self.goals_path}\")\n",
        "\n",
        "    def add_goal(self, title, payload):\n",
        "        g = {\n",
        "            \"id\": f\"goal_{int(time.time())}\",\n",
        "            \"title\": title,\n",
        "            \"payload\": payload,\n",
        "            \"status\": \"pending\",\n",
        "            \"created_at\": datetime.now().isoformat(),\n",
        "            \"last_updated\": datetime.now().isoformat(),\n",
        "            \"history\": []\n",
        "        }\n",
        "        self.goals.append(g)\n",
        "        self._save_goals()\n",
        "        return g\n",
        "\n",
        "    def list_goals(self):\n",
        "        return self.goals\n",
        "\n",
        "    def _checkpoint_result(self, goal_id, result):\n",
        "        out_dir = os.path.join(checkpoint_dir, \"goal_results\")\n",
        "        os.makedirs(out_dir, exist_ok=True)\n",
        "        path = os.path.join(out_dir, f\"{goal_id}.json\")\n",
        "        with open(path, \"w\", encoding=\"utf-8\") as f:\n",
        "            json.dump(result, f, indent=2, ensure_ascii=False)\n",
        "        print(f\" Result checkpoint saved: {path}\")\n",
        "        return path\n",
        "\n",
        "    def run_case(self, case_text, goal_title=\"AutoCaseAnalysis\", auto_update_memory=True, max_loops=2, min_confidence=0.75):\n",
        "\n",
        "        goal = self.add_goal(goal_title, {\"case_text_preview\": case_text[:200]})\n",
        "        goal_id = goal[\"id\"]\n",
        "        plan = self.planner.generate_plan(case_text)\n",
        "        print(f\"\\n GoalManager: Starting goal '{goal_title}' ({goal_id})\")\n",
        "        print(\" Plan:\", plan)\n",
        "        loop = 0\n",
        "        final_result = None\n",
        "\n",
        "        while loop < max_loops:\n",
        "            print(f\"\\n GoalManager Loop {loop+1}/{max_loops} for goal {goal_id}\")\n",
        "            step_results = {}\n",
        "            failed_steps = []\n",
        "            for step in plan:\n",
        "                print(f\"\\n Executing step: {step}\")\n",
        "                try:\n",
        "                    if step == \"fact_analysis\":\n",
        "                        fa = self.agents.get(\"fact\")\n",
        "                        if fa:\n",
        "                            p = fa.extract_plaintiff(case_text)\n",
        "                            d = fa.extract_defendant(case_text)\n",
        "                            arts = fa.extract_key_articles(case_text, \"\")\n",
        "                            step_results[\"fact_analysis\"] = {\"plaintiff\": p, \"defendant\": d, \"articles\": arts}\n",
        "                            print(\"  FactAnalysis:\", step_results[\"fact_analysis\"])\n",
        "                        else:\n",
        "                            raise RuntimeError(\"Fact agent not available\")\n",
        "\n",
        "                    elif step == \"predict_outcome\":\n",
        "                        pred = self.agents.get(\"predictor\").predict(case_text)\n",
        "                        step_results[\"predict_outcome\"] = pred\n",
        "                        print(\"  Predict:\", pred)\n",
        "\n",
        "                    elif step == \"retrieve_memory\":\n",
        "                        try:\n",
        "                            mem = self.agents.get(\"memory\")\n",
        "                            if mem:\n",
        "                                retrieved = mem.retrieve(case_text, k=3)\n",
        "                            else:\n",
        "                                retrieved = []\n",
        "                        except Exception as e:\n",
        "                            print(\"  Memory retrieval failed:\", e)\n",
        "                            retrieved = []\n",
        "                        step_results[\"retrieve_memory\"] = retrieved\n",
        "                        print(f\"  Retrieved {len(retrieved)} items\")\n",
        "\n",
        "                    elif step == \"supporting_precedents\":\n",
        "                        support_agent = self.agents.get(\"supporting\")\n",
        "                        if support_agent:\n",
        "                            sup = support_agent.retrieve_supporting(case_text, predicted_outcome=step_results.get(\"predict_outcome\", {}).get(\"outcome\",\"Violation\"), k=3)\n",
        "                            step_results[\"supporting_precedents\"] = sup\n",
        "                            print(\"  Supporting precedents retrieved.\")\n",
        "                        else:\n",
        "                            step_results[\"supporting_precedents\"] = {\"supporting_precedents\": [], \"summary\": \"\"}\n",
        "\n",
        "                    elif step == \"generate_reasoning\":\n",
        "                        ra = self.agents.get(\"reasoning\")\n",
        "                        pred_out = step_results.get(\"predict_outcome\", {}).get(\"outcome\", \"Violation\")\n",
        "                        precedents = step_results.get(\"supporting_precedents\", {}).get(\"supporting_precedents\", []) if isinstance(step_results.get(\"supporting_precedents\"), dict) else step_results.get(\"supporting_precedents\", [])\n",
        "                        if ra:\n",
        "                            reasoning = ra.generate_reasoning(case_text, predicted_outcome=pred_out, precedents=precedents)\n",
        "                            step_results[\"generate_reasoning\"] = reasoning\n",
        "                            print(\"  Reasoning generated.\")\n",
        "                        else:\n",
        "                            raise RuntimeError(\"Reasoning agent not available\")\n",
        "\n",
        "                    elif step == \"counter_arguments\":\n",
        "                        ca = self.agents.get(\"counter\")\n",
        "                        precedents = step_results.get(\"supporting_precedents\", {}).get(\"supporting_precedents\", []) if isinstance(step_results.get(\"supporting_precedents\"), dict) else step_results.get(\"supporting_precedents\", [])\n",
        "                        if ca:\n",
        "                            counters = ca.generate_counterarguments(case_text, precedents=precedents)\n",
        "                            step_results[\"counter_arguments\"] = counters\n",
        "                            print(\"  Counter-arguments done.\")\n",
        "                        else:\n",
        "                            step_results[\"counter_arguments\"] = []\n",
        "\n",
        "                    elif step == \"evaluate_confidence\":\n",
        "                        ev = self.agents.get(\"evaluator\")\n",
        "                        if ev:\n",
        "                            eval_res = ev.evaluate_case(case_text)\n",
        "                            step_results[\"evaluate_confidence\"] = eval_res\n",
        "                            print(\"  Evaluation done. Confidence:\", eval_res.get(\"confidence_score\"))\n",
        "                        else:\n",
        "                            step_results[\"evaluate_confidence\"] = {\"confidence_score\": 0.0}\n",
        "\n",
        "                    elif step == \"reflect\":\n",
        "                        rf = self.agents.get(\"reflection\")\n",
        "                        if rf:\n",
        "                            reflection_res = rf.reflect(case_text)\n",
        "                            step_results[\"reflect\"] = reflection_res\n",
        "                            print(\"  Reflection done. Reasoning quality:\", reflection_res.get(\"reasoning_quality\"))\n",
        "                        else:\n",
        "                            step_results[\"reflect\"] = {}\n",
        "\n",
        "                    elif step == \"update_memory\":\n",
        "                        mu = self.agents.get(\"memory_update\")\n",
        "                        if mu and auto_update_memory:\n",
        "                            try:\n",
        "\n",
        "                                to_store = step_results.get(\"reflect\") or step_results.get(\"evaluate_confidence\") or {\"note\":\"no_reflection\"}\n",
        "                                summary = mu.update_memory(to_store)\n",
        "                                step_results[\"update_memory\"] = {\"summary\": summary}\n",
        "                                print(\"  Memory updated.\")\n",
        "                            except Exception as e:\n",
        "                                print(\"  Memory update failed:\", e)\n",
        "                                step_results[\"update_memory\"] = {\"error\": str(e)}\n",
        "                        else:\n",
        "                            step_results[\"update_memory\"] = {\"skipped\": True}\n",
        "\n",
        "                    else:\n",
        "                        print(\"  Unknown step:\", step)\n",
        "                        step_results[step] = {\"skipped\": True}\n",
        "\n",
        "                except Exception as e:\n",
        "                    print(f\"   Step '{step}' failed with error: {e}\")\n",
        "                    failed_steps.append(step)\n",
        "\n",
        "                    applied = self.planner.apply_fallback(step, self)\n",
        "                    step_results[f\"{step}_error\"] = {\"error\": str(e), \"fallback_applied\": applied}\n",
        "\n",
        "\n",
        "            final_eval = step_results.get(\"evaluate_confidence\") or (step_results.get(\"reflect\") or {}).get(\"current_result\") or {}\n",
        "            conf = final_eval.get(\"confidence_score\", 0.0) if isinstance(final_eval, dict) else 0.0\n",
        "\n",
        "\n",
        "            checkpoint_path = self._checkpoint_result(goal_id, {\"loop\": loop+1, \"steps\": step_results, \"confidence\": conf})\n",
        "\n",
        "            for g in self.goals:\n",
        "                if g[\"id\"] == goal_id:\n",
        "                    g[\"last_updated\"] = datetime.now().isoformat()\n",
        "                    g[\"history\"].append({\"loop\": loop+1, \"checkpoint\": checkpoint_path, \"confidence\": conf})\n",
        "                    break\n",
        "            self._save_goals()\n",
        "\n",
        "            if conf >= min_confidence and not failed_steps:\n",
        "                print(f\"\\n Goal '{goal_title}' reached with confidence {conf:.2f}\")\n",
        "                final_result = {\"goal_id\": goal_id, \"checkpoint\": checkpoint_path, \"confidence\": conf, \"steps\": step_results}\n",
        "\n",
        "                for g in self.goals:\n",
        "                    if g[\"id\"] == goal_id:\n",
        "                        g[\"status\"] = \"completed\"\n",
        "                        g[\"last_updated\"] = datetime.now().isoformat()\n",
        "                        break\n",
        "                self._save_goals()\n",
        "                break\n",
        "            else:\n",
        "                print(f\"\\n GoalManager: Confidence {conf:.2f} < threshold {min_confidence} or failures present -> replanning or looping.\")\n",
        "\n",
        "                if failed_steps:\n",
        "\n",
        "                    for f in failed_steps:\n",
        "                        if f in plan:\n",
        "                            plan.remove(f)\n",
        "                    print(\" PlanningAgent: removed failing steps from next loop:\", failed_steps)\n",
        "                loop += 1\n",
        "\n",
        "        if final_result is None:\n",
        "            print(\"\\n Max loops reached  returning best effort checkpoint.\")\n",
        "            final_result = {\"goal_id\": goal_id, \"checkpoint\": checkpoint_path, \"confidence\": conf, \"steps\": step_results}\n",
        "            for g in self.goals:\n",
        "                if g[\"id\"] == goal_id:\n",
        "                    g[\"status\"] = \"needs_review\"\n",
        "                    g[\"last_updated\"] = datetime.now().isoformat()\n",
        "                    break\n",
        "            self._save_goals()\n",
        "\n",
        "        return final_result\n",
        "\n",
        "\n",
        "\n",
        "available_agents = {\n",
        "    \"fact\": globals().get(\"fact_agent\"),\n",
        "    \"predictor\": globals().get(\"predictor_agent\"),\n",
        "    \"memory\": globals().get(\"memory_agent\"),\n",
        "    \"supporting\": globals().get(\"supporting_agent\"),\n",
        "    \"reasoning\": globals().get(\"reasoning_agent\"),\n",
        "    \"counter\": globals().get(\"counter_agent\"),\n",
        "    \"evaluator\": globals().get(\"evaluator_agent\"),\n",
        "    \"reflection\": globals().get(\"reflection_agent\"),\n",
        "    \"memory_update\": globals().get(\"memory_update_agent\")\n",
        "}\n",
        "\n",
        "planner = PlanningAgent()\n",
        "orchestrator = GoalManager(available_agents, planning_agent=planner)\n",
        "print(\"\\n GoalManager & PlanningAgent created and ready.\")\n",
        "print(\" You can now call: orchestrator.run_case(case_text, auto_update_memory=True) to run an autonomous cycle.\")\n"
      ],
      "metadata": {
        "id": "LeBDdmO_6fEM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d0746ab-334d-4684-8e3d-0543ee99acee"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Loaded goals from /content/drive/MyDrive/Argumate/checkpoints/goals.json (count=55)\n",
            "\n",
            " GoalManager & PlanningAgent created and ready.\n",
            " You can now call: orchestrator.run_case(case_text, auto_update_memory=True) to run an autonomous cycle.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "cell 2: context manager"
      ],
      "metadata": {
        "id": "KcsPfIZJ8fMZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import pickle, os, time\n",
        "from datetime import datetime\n",
        "\n",
        "CONTEXT_PATH = os.path.join(checkpoint_dir, \"context_state.pkl\")\n",
        "\n",
        "class ContextManager:\n",
        "    \"\"\"\n",
        "    Tracks short-term session context, user preferences, and integrates with long-term memory.\n",
        "    Saves persistent context to checkpoint_dir/context_state.pkl so it survives restarts.\n",
        "    \"\"\"\n",
        "    def __init__(self, memory_agent=None, memory_update_agent=None, path=CONTEXT_PATH):\n",
        "        self.path = path\n",
        "        self.memory_agent = memory_agent\n",
        "        self.memory_update_agent = memory_update_agent\n",
        "        # internal stores\n",
        "        self.short_term_sessions = []\n",
        "        self.user_profiles = {}\n",
        "        # load if exists\n",
        "        if os.path.exists(self.path):\n",
        "            try:\n",
        "                with open(self.path, \"rb\") as f:\n",
        "                    saved = pickle.load(f)\n",
        "                self.short_term_sessions = saved.get(\"short_term_sessions\", [])\n",
        "                self.user_profiles = saved.get(\"user_profiles\", {})\n",
        "                print(f\" Loaded context_state from {self.path} (sessions={len(self.short_term_sessions)})\")\n",
        "            except Exception as e:\n",
        "                print(\" Could not load existing context_state:\", e)\n",
        "        else:\n",
        "            self._save()\n",
        "            print(\" Created new context_state checkpoint.\")\n",
        "\n",
        "    def _save(self):\n",
        "        data = {\n",
        "            \"short_term_sessions\": self.short_term_sessions,\n",
        "            \"user_profiles\": self.user_profiles\n",
        "        }\n",
        "        with open(self.path, \"wb\") as f:\n",
        "            pickle.dump(data, f)\n",
        "\n",
        "    def start_session(self, case_text, user_id=\"default_user\", metadata=None):\n",
        "        sess = {\n",
        "            \"session_id\": f\"sess_{int(time.time())}\",\n",
        "            \"user_id\": user_id,\n",
        "            \"start_time\": datetime.now().isoformat(),\n",
        "            \"case_preview\": case_text[:300],\n",
        "            \"metadata\": metadata or {},\n",
        "            \"events\": []\n",
        "        }\n",
        "        self.short_term_sessions.append(sess)\n",
        "\n",
        "        if len(self.short_term_sessions) > 20:\n",
        "            self.short_term_sessions = self.short_term_sessions[-20:]\n",
        "        self._save()\n",
        "        return sess\n",
        "\n",
        "    def add_event(self, session_id, event_type, content):\n",
        "        for s in reversed(self.short_term_sessions):\n",
        "            if s[\"session_id\"] == session_id:\n",
        "                s[\"events\"].append({\"ts\": datetime.now().isoformat(), \"type\": event_type, \"content\": content})\n",
        "                s[\"last_updated\"] = datetime.now().isoformat()\n",
        "                break\n",
        "        self._save()\n",
        "\n",
        "    def end_session(self, session_id, final_result=None, sync_to_longterm=True):\n",
        "        for s in reversed(self.short_term_sessions):\n",
        "            if s[\"session_id\"] == session_id:\n",
        "                s[\"end_time\"] = datetime.now().isoformat()\n",
        "                s[\"final_result_preview\"] = (final_result or {}) if isinstance(final_result, dict) else {\"note\": str(final_result)[:200]}\n",
        "                break\n",
        "        self._save()\n",
        "        if sync_to_longterm and self.memory_update_agent and final_result:\n",
        "            try:\n",
        "\n",
        "                summary = self.memory_update_agent.update_memory(final_result)\n",
        "                return summary\n",
        "            except Exception as e:\n",
        "                print(\" ContextManager: memory sync failed:\", e)\n",
        "                return None\n",
        "        return None\n",
        "\n",
        "\n",
        "    def get_user_profile(self, user_id=\"default_user\"):\n",
        "        return self.user_profiles.get(user_id, {\"prefs\": {\"style\": \"formal\", \"length\": \"concise\"}, \"created_at\": datetime.now().isoformat()})\n",
        "\n",
        "    def update_user_profile(self, user_id=\"default_user\", prefs=None):\n",
        "        prof = self.user_profiles.get(user_id, {\"prefs\": {\"style\": \"formal\", \"length\": \"concise\"}, \"created_at\": datetime.now().isoformat()})\n",
        "        if prefs:\n",
        "            prof[\"prefs\"].update(prefs)\n",
        "        prof[\"last_updated\"] = datetime.now().isoformat()\n",
        "        self.user_profiles[user_id] = prof\n",
        "        self._save()\n",
        "        return prof\n",
        "\n",
        "    def retrieve_similar_longterm(self, query_text, k=3):\n",
        "        if self.memory_agent:\n",
        "            try:\n",
        "                return self.memory_agent.retrieve(query_text, k=k)\n",
        "            except Exception as e:\n",
        "                print(\" ContextManager: longterm retrieval failed:\", e)\n",
        "                return []\n",
        "        return []\n",
        "\n",
        "    def show_recent_sessions(self, n=5):\n",
        "        return list(reversed(self.short_term_sessions[-n:]))\n",
        "\n",
        "\n",
        "cm = ContextManager(memory_agent=available_agents.get(\"memory\"), memory_update_agent=available_agents.get(\"memory_update\"))\n",
        "\n",
        "setattr(orchestrator, \"context_manager\", cm)\n",
        "orchestrator.agents[\"context\"] = cm\n",
        "\n",
        "\n",
        "def _run_case_with_context(case_text, user_id=\"default_user\", auto_update_memory=True, **kwargs):\n",
        "    sess = cm.start_session(case_text, user_id=user_id)\n",
        "    orchestrator_context = {\"session_id\": sess[\"session_id\"], \"user_id\": user_id}\n",
        "    orchestrator.add_event = lambda *a, **k: cm.add_event(*a, **k)\n",
        "    cm.add_event(sess[\"session_id\"], \"orchestrator_start\", {\"preview\": case_text[:200]})\n",
        "\n",
        "    result = orchestrator.run_case(case_text, goal_title=f\"AutoCase_{sess['session_id']}\", auto_update_memory=auto_update_memory, **kwargs)\n",
        "    cm.add_event(sess[\"session_id\"], \"orchestrator_end\", {\"confidence\": result.get(\"confidence\", result.get(\"confidence_score\", None))})\n",
        "\n",
        "    sync_summary = None\n",
        "    try:\n",
        "        sync_summary = cm.end_session(sess[\"session_id\"], final_result=result if isinstance(result, dict) else {\"note\": str(result)}, sync_to_longterm=auto_update_memory)\n",
        "    except Exception as e:\n",
        "        print(\" Error during context end/session sync:\", e)\n",
        "    return {\"session_id\": sess[\"session_id\"], \"result\": result, \"memory_sync\": sync_summary}\n",
        "\n",
        "\n",
        "setattr(orchestrator, \"run_case_with_context\", _run_case_with_context)\n",
        "\n",
        "print(\"\\n ContextManager initialized and attached to orchestrator as `orchestrator.context_manager`.\")\n",
        "print(\" Use: orchestrator.run_case_with_context(case_text, user_id='you') to run a context-aware autonomous cycle.\")\n",
        "print(\" You can view recent sessions via: orchestrator.context_manager.show_recent_sessions()\")\n"
      ],
      "metadata": {
        "id": "Tn2KAnrt8nEP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0488623e-4230-4e4a-f2c5-8d930be1457f"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Loaded context_state from /content/drive/MyDrive/Argumate/checkpoints/context_state.pkl (sessions=20)\n",
            "\n",
            " ContextManager initialized and attached to orchestrator as `orchestrator.context_manager`.\n",
            " Use: orchestrator.run_case_with_context(case_text, user_id='you') to run a context-aware autonomous cycle.\n",
            " You can view recent sessions via: orchestrator.context_manager.show_recent_sessions()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cell 4: EvaluationManager + automatic reflection + replanning loop (hope)"
      ],
      "metadata": {
        "id": "sHyJj5Jf9zga"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import json, os, re, time\n",
        "from datetime import datetime\n",
        "\n",
        "class EvaluationManager:\n",
        "    \"\"\"\n",
        "    Automatically manages the evaluate  reflect  replan cycle.\n",
        "    Runs evaluator_agent and reflection_agent, then triggers replanning\n",
        "    if confidence or reasoning quality falls below thresholds.\n",
        "    \"\"\"\n",
        "    def __init__(self, evaluator_agent, reflection_agent, orchestrator, confidence_threshold=0.75, reasoning_threshold=0.8):\n",
        "        self.evaluator_agent = evaluator_agent\n",
        "        self.reflection_agent = reflection_agent\n",
        "        self.orchestrator = orchestrator\n",
        "        self.conf_threshold = confidence_threshold\n",
        "        self.reasoning_threshold = reasoning_threshold\n",
        "        self.results_dir = \"/content/drive/MyDrive/Argumate/results\"\n",
        "        os.makedirs(self.results_dir, exist_ok=True)\n",
        "        print(f\" EvaluationManager ready (conf{self.conf_threshold}, reason{self.reasoning_threshold}).\")\n",
        "\n",
        "    def run_cycle(self, case_text, user_id=\"default_user\", auto_replan=True):\n",
        "        print(\"\\n=== EvaluationManager: Autonomous Review Cycle Start ===\")\n",
        "\n",
        "\n",
        "        try:\n",
        "            eval_result = self.evaluator_agent.evaluate_case(case_text)\n",
        "            conf = eval_result.get(\"confidence_score\", 0.0)\n",
        "            print(f\" [1/3] Confidence Score: {conf:.2f}\")\n",
        "        except Exception as e:\n",
        "            print(\" Evaluation step failed:\", e)\n",
        "            conf = 0.0\n",
        "            eval_result = {\"error\": str(e)}\n",
        "\n",
        "\n",
        "        try:\n",
        "            reflection_result = self.reflection_agent.reflect(case_text)\n",
        "            reason_quality = reflection_result.get(\"reasoning_quality\", 0.0)\n",
        "            print(f\" [2/3] Reasoning Quality: {reason_quality:.2f}\")\n",
        "        except Exception as e:\n",
        "            print(\" Reflection step failed:\", e)\n",
        "            reason_quality = 0.0\n",
        "            reflection_result = {\"error\": str(e)}\n",
        "\n",
        "\n",
        "        if auto_replan and (conf < self.conf_threshold or reason_quality < self.reasoning_threshold):\n",
        "            print(f\" [3/3] Scores below threshold (conf={conf:.2f}, quality={reason_quality:.2f}). Triggering replanning...\")\n",
        "            try:\n",
        "                plan = self.orchestrator.planner.replan(\n",
        "                    f\"Refine analysis for low confidence/quality case (conf={conf:.2f}, qual={reason_quality:.2f})\"\n",
        "                )\n",
        "                new_plan_json = plan\n",
        "                print(\"  Replanning completed.\")\n",
        "            except Exception as e:\n",
        "                print(\" Replanning failed:\", e)\n",
        "                new_plan_json = {\"error\": str(e)}\n",
        "        else:\n",
        "            print(\" [3/3] Quality acceptable. Skipping replanning.\")\n",
        "            new_plan_json = {\"status\": \"Accepted\"}\n",
        "\n",
        "\n",
        "        final = {\n",
        "            \"confidence\": conf,\n",
        "            \"reasoning_quality\": reason_quality,\n",
        "            \"evaluation\": eval_result,\n",
        "            \"reflection\": reflection_result,\n",
        "            \"replan_summary\": new_plan_json,\n",
        "            \"timestamp\": datetime.now().isoformat()\n",
        "        }\n",
        "\n",
        "        save_path = os.path.join(self.results_dir, f\"evaluation_manager_{int(time.time())}.json\")\n",
        "        with open(save_path, \"w\", encoding=\"utf-8\") as f:\n",
        "            json.dump(final, f, indent=2)\n",
        "        print(f\" Evaluation cycle complete. Saved summary at: {save_path}\")\n",
        "        return final\n",
        "\n",
        "\n",
        "\n",
        "evaluation_manager = EvaluationManager(\n",
        "    evaluator_agent=available_agents[\"evaluator\"],\n",
        "    reflection_agent=available_agents[\"reflection\"],\n",
        "    orchestrator=orchestrator\n",
        ")\n",
        "\n",
        "\n",
        "setattr(orchestrator, \"evaluation_manager\", evaluation_manager)\n",
        "setattr(orchestrator, \"run_evaluation_cycle\", lambda case_text, **kw: evaluation_manager.run_cycle(case_text, **kw))\n",
        "\n",
        "print(\"\\n EvaluationManager integrated with orchestrator.\")\n",
        "print(\" You can now call: orchestrator.run_evaluation_cycle(case_text, user_id='you')\")\n"
      ],
      "metadata": {
        "id": "fOrB9t4d93ER",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "193ed6ac-4ad6-4644-cdd0-5efb0baa10a0"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " EvaluationManager ready (conf0.75, reason0.8).\n",
            "\n",
            " EvaluationManager integrated with orchestrator.\n",
            " You can now call: orchestrator.run_evaluation_cycle(case_text, user_id='you')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cell 5: LLMJudgeAgent  Self-Assessment & Quality Grading (hope)"
      ],
      "metadata": {
        "id": "_jrWHZz1-JSz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import os, re, json, time\n",
        "from datetime import datetime\n",
        "from transformers import pipeline\n",
        "\n",
        "BASE_DIR = \"/content/drive/MyDrive/Argumate\"\n",
        "JUDGE_RESULTS_DIR = f\"{BASE_DIR}/results/llm_judge_reports\"\n",
        "ENDPOINTS_PATH = f\"{BASE_DIR}/checkpoints/agent_endpoints.json\"\n",
        "os.makedirs(JUDGE_RESULTS_DIR, exist_ok=True)\n",
        "os.makedirs(os.path.dirname(ENDPOINTS_PATH), exist_ok=True)\n",
        "\n",
        "class LLMJudgeAgent:\n",
        "    \"\"\"\n",
        "    LLM-based self-assessment module.\n",
        "    Evaluates reasoning outputs using lightweight FLAN-T5 across four dimensions:\n",
        "      - Legal Accuracy\n",
        "      - Logical Coherence\n",
        "      - Ethical Soundness\n",
        "      - Clarity of Reasoning\n",
        "    Produces numeric scores (01) and improvement suggestions.\n",
        "    \"\"\"\n",
        "    def __init__(self, model_name=\"google/flan-t5-small\"):\n",
        "        self.model_name = model_name\n",
        "        try:\n",
        "            self.llm = pipeline(\"text2text-generation\", model=model_name, device_map=\"auto\")\n",
        "            print(f\" LLMJudgeAgent loaded with {model_name}.\")\n",
        "        except Exception as e:\n",
        "            print(\" Could not load FLAN-T5:\", e)\n",
        "            self.llm = None\n",
        "\n",
        "    def _evaluate_dimension(self, reasoning, dimension):\n",
        "        \"\"\"Internal helper to get LLM rating for one dimension\"\"\"\n",
        "        text = (\n",
        "            f\"Reasoning: {reasoning.get('analysis','')} {reasoning.get('conclusion','')}\\n\"\n",
        "            f\"Evaluate this reasoning for '{dimension}' on a scale 0.01.0.\\n\"\n",
        "            f\"Respond strictly as JSON: {{'score': float, 'comment': str}}\"\n",
        "        )\n",
        "        try:\n",
        "            if self.llm:\n",
        "                gen = self.llm(text, max_new_tokens=120)[0]['generated_text']\n",
        "                match = re.search(r\"\\{.*\\}\", gen)\n",
        "                if match:\n",
        "                    data = json.loads(match.group())\n",
        "                    return round(float(data.get(\"score\", 0.5)), 2), data.get(\"comment\", \"\")\n",
        "        except Exception:\n",
        "            pass\n",
        "        heuristic = 0.6 + (len(reasoning.get(\"analysis\", \"\")) / 8000)\n",
        "        return round(min(heuristic, 1.0), 2), \"Heuristic fallback score.\"\n",
        "\n",
        "    def evaluate_reasoning(self, reflection_result):\n",
        "        \"\"\"Evaluate reasoning across 4 dimensions and return report\"\"\"\n",
        "        reasoning = reflection_result.get(\"reasoning_plan\", reflection_result)\n",
        "        dimensions = [\"Legal Accuracy\", \"Logical Coherence\", \"Ethical Soundness\", \"Clarity of Reasoning\"]\n",
        "\n",
        "        print(\"\\n LLMJudgeAgent: Evaluating reasoning quality...\")\n",
        "        scores, comments, total_score = {}, {}, 0\n",
        "        for dim in dimensions:\n",
        "            s, c = self._evaluate_dimension(reasoning, dim)\n",
        "            scores[dim] = s\n",
        "            comments[dim] = c\n",
        "            total_score += s\n",
        "            print(f\" {dim}: {s:.2f}\")\n",
        "\n",
        "        avg_score = round(total_score / len(dimensions), 3)\n",
        "        improvement_suggestion = self._generate_improvement_advice(reasoning, avg_score)\n",
        "\n",
        "        final_report = {\n",
        "            \"scores\": scores,\n",
        "            \"average_score\": avg_score,\n",
        "            \"comments\": comments,\n",
        "            \"improvement_advice\": improvement_suggestion,\n",
        "            \"timestamp\": datetime.now().isoformat(),\n",
        "            \"endpoint_used\": \"/agents/llm_judge/evaluate_reasoning\"\n",
        "        }\n",
        "\n",
        "        save_path = os.path.join(JUDGE_RESULTS_DIR, f\"judge_report_{int(time.time())}.json\")\n",
        "        with open(save_path, \"w\", encoding=\"utf-8\") as f:\n",
        "            json.dump(final_report, f, indent=2)\n",
        "        print(f\"Judge evaluation complete. Report saved to {save_path}\")\n",
        "\n",
        "        return final_report\n",
        "\n",
        "    def _generate_improvement_advice(self, reasoning, avg_score):\n",
        "        \"\"\"Summarize improvement suggestions via LLM.\"\"\"\n",
        "        if not self.llm:\n",
        "            return \"Consider improving clarity and adding relevant legal citations.\"\n",
        "        prompt = f\"\"\"\n",
        "You are a legal writing coach. The reasoning below scored {avg_score:.2f}/1.0 overall.\n",
        "Suggest 23 specific improvements to make it more accurate, ethical, and coherent.\n",
        "\n",
        "Reasoning:\n",
        "ISSUE: {reasoning.get('issue','')}\n",
        "ANALYSIS: {reasoning.get('analysis','')}\n",
        "CONCLUSION: {reasoning.get('conclusion','')}\n",
        "\n",
        "Respond as a short paragraph (no lists).\n",
        "\"\"\"\n",
        "        try:\n",
        "            gen = self.llm(prompt, max_new_tokens=120)[0]['generated_text']\n",
        "            return gen.strip()\n",
        "        except Exception:\n",
        "            return \"Enhance legal justification and ensure balanced tone.\"\n",
        "\n",
        "\n",
        "llm_judge = LLMJudgeAgent()\n",
        "setattr(orchestrator, \"llm_judge\", llm_judge)\n",
        "available_agents[\"judge\"] = llm_judge\n",
        "\n",
        "\n",
        "agent_endpoints = globals().get(\"agent_endpoints\", {})\n",
        "\n",
        "agent_endpoints[\"llm_judge\"] = {\n",
        "    \"endpoint\": \"/agents/llm_judge/evaluate_reasoning\",\n",
        "    \"description\": \"Evaluates reasoning quality, coherence, ethical soundness, and clarity\",\n",
        "    \"save_path\": JUDGE_RESULTS_DIR,\n",
        "    \"call_example\": \"orchestrator.llm_judge.evaluate_reasoning(reflection_result)\"\n",
        "}\n",
        "\n",
        "\n",
        "try:\n",
        "    with open(ENDPOINTS_PATH, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(agent_endpoints, f, indent=2)\n",
        "    print(f\" Endpoint registered and saved to {ENDPOINTS_PATH}\")\n",
        "    print(json.dumps(agent_endpoints[\"llm_judge\"], indent=2))\n",
        "except Exception as e:\n",
        "    print(\" Failed to save endpoint:\", e)\n",
        "\n",
        "print(\"\\n LLMJudgeAgent integrated into orchestrator.\")\n",
        "print(\" Use endpoint:\", agent_endpoints['llm_judge']['endpoint'])\n",
        "print(\" Example call:\", agent_endpoints['llm_judge']['call_example'])\n"
      ],
      "metadata": {
        "id": "cIBaG34p-Mrn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "414f1138-db1a-488c-a1e6-cbfe975435e5"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " LLMJudgeAgent loaded with google/flan-t5-small.\n",
            " Endpoint registered and saved to /content/drive/MyDrive/Argumate/checkpoints/agent_endpoints.json\n",
            "{\n",
            "  \"endpoint\": \"/agents/llm_judge/evaluate_reasoning\",\n",
            "  \"description\": \"Evaluates reasoning quality, coherence, ethical soundness, and clarity\",\n",
            "  \"save_path\": \"/content/drive/MyDrive/Argumate/results/llm_judge_reports\",\n",
            "  \"call_example\": \"orchestrator.llm_judge.evaluate_reasoning(reflection_result)\"\n",
            "}\n",
            "\n",
            " LLMJudgeAgent integrated into orchestrator.\n",
            " Use endpoint: /agents/llm_judge/evaluate_reasoning\n",
            " Example call: orchestrator.llm_judge.evaluate_reasoning(reflection_result)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "guard railing"
      ],
      "metadata": {
        "id": "BMJ7X-EptbKP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import os, json\n",
        "from datetime import datetime\n",
        "from transformers import pipeline\n",
        "\n",
        "\n",
        "ENDPOINT_DIR = \"/content/drive/MyDrive/Argumate/endpoints\"\n",
        "os.makedirs(ENDPOINT_DIR, exist_ok=True)\n",
        "GUARDRAIL_ENDPOINT_PATH = f\"{ENDPOINT_DIR}/guardrail_endpoint.json\"\n",
        "\n",
        "try:\n",
        "    guard_llm = pipeline(\"text2text-generation\", model=\"google/flan-t5-base\", device_map=\"auto\")\n",
        "    print(\" Guardrail LLM (Flan-T5-Base) loaded.\")\n",
        "except Exception as e:\n",
        "    print(\" Could not load LLM:\", e)\n",
        "    guard_llm = None\n",
        "\n",
        "\n",
        "\n",
        "class GuardrailAgent:\n",
        "    def __init__(self, llm=None):\n",
        "        self.llm = llm or guard_llm\n",
        "\n",
        "    def check(self, text):\n",
        "        \"\"\"\n",
        "        Check the final reasoning or output for ethical / legal compliance.\n",
        "        \"\"\"\n",
        "        if not self.llm:\n",
        "            print(\" Guardrail LLM not available, returning text unmodified.\")\n",
        "            return {\"status\": \"unverified\", \"safe_output\": text, \"flagged\": []}\n",
        "\n",
        "        prompt = f\"\"\"\n",
        "You are a Guardrail AI for a legal reasoning system.\n",
        "Review the text below for safety, ethics, and compliance before publication.\n",
        "\n",
        "Text:\n",
        "{text[:2000]}\n",
        "\n",
        "Check for:\n",
        "1. Confidential or private personal data\n",
        "2. Hate speech, bias, or discrimination\n",
        "3. Political or religious advocacy\n",
        "4. Incorrect or unsafe legal advice\n",
        "5. Any content violating professional ethics\n",
        "\n",
        "If any violations found:\n",
        "- Redact unsafe parts and replace with [REDACTED]\n",
        "- Provide a summary of issues in JSON format.\n",
        "\n",
        "Respond strictly as JSON:\n",
        "{{\n",
        "  \"safety_status\": \"safe\" or \"flagged\",\n",
        "  \"issues\": [\"list of detected problems\"],\n",
        "  \"safe_output\": \"filtered text\"\n",
        "}}\n",
        "\"\"\"\n",
        "        try:\n",
        "            result = self.llm(prompt, max_new_tokens=250)[0]['generated_text']\n",
        "\n",
        "            start, end = result.find(\"{\"), result.rfind(\"}\")\n",
        "            if start != -1 and end != -1:\n",
        "                parsed = json.loads(result[start:end+1])\n",
        "                return parsed\n",
        "        except Exception as e:\n",
        "            print(\" Guardrail check failed:\", e)\n",
        "\n",
        "\n",
        "        return {\"safety_status\": \"unverified\", \"safe_output\": text, \"issues\": [\"parse_failed\"]}\n",
        "\n",
        "\n",
        "\n",
        "def guardrail_endpoint(input_text):\n",
        "    guard = GuardrailAgent()\n",
        "    result = guard.check(input_text)\n",
        "\n",
        "\n",
        "    endpoint_data = {\n",
        "        \"timestamp\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
        "        \"input_preview\": input_text[:150],\n",
        "        \"result\": result\n",
        "    }\n",
        "    with open(GUARDRAIL_ENDPOINT_PATH, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(endpoint_data, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "    print(f\" Guardrail check completed. Endpoint saved at:\\n{GUARDRAIL_ENDPOINT_PATH}\")\n",
        "    return result\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "eRPMTf1JtdW1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d0dc5be-7aae-40e3-eff2-3437ab916870"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Guardrail LLM (Flan-T5-Base) loaded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import os, pickle, json, re, numpy as np\n",
        "from datetime import datetime\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from transformers import pipeline\n",
        "\n",
        "MEMORY_UPDATE_DIR = \"/content/drive/MyDrive/Argumate/checkpoints/adaptive_memory\"\n",
        "os.makedirs(MEMORY_UPDATE_DIR, exist_ok=True)\n",
        "\n",
        "class MemoryIntegratorAgent:\n",
        "    \"\"\"\n",
        "    Connects ContextManager + MemoryContextUpdateAgent for adaptive learning.\n",
        "    Summarizes key learnings after each reflection and updates both user and global memory.\n",
        "    \"\"\"\n",
        "    def __init__(self, context_manager, embedder_model=\"sentence-transformers/paraphrase-MiniLM-L6-v2\"):\n",
        "        self.context_manager = context_manager\n",
        "        self.embedder = SentenceTransformer(embedder_model)\n",
        "        try:\n",
        "            self.llm = pipeline(\"text2text-generation\", model=\"google/flan-t5-small\", device_map=\"auto\")\n",
        "            print(\"  LLM (Flan-T5) loaded for adaptive case summarization.\")\n",
        "        except Exception:\n",
        "            print(\" LLM not available, fallback to rule-based summarization.\")\n",
        "            self.llm = None\n",
        "        self.memory_path = os.path.join(MEMORY_UPDATE_DIR, \"adaptive_memory.pkl\")\n",
        "        self.memory_entries = self._load_memory()\n",
        "\n",
        "    def _load_memory(self):\n",
        "        if os.path.exists(self.memory_path):\n",
        "            with open(self.memory_path, \"rb\") as f:\n",
        "                return pickle.load(f)\n",
        "        return {\"entries\": [], \"embeddings\": []}\n",
        "\n",
        "    def summarize_learning(self, reflection_output):\n",
        "        \"\"\"Generate a compact summary of what was learned from this case.\"\"\"\n",
        "        reasoning = reflection_output.get(\"reasoning_plan\", {})\n",
        "        key_issue = reasoning.get(\"issue\", \"\")\n",
        "        key_analysis = reasoning.get(\"analysis\", \"\")\n",
        "        key_conclusion = reasoning.get(\"conclusion\", \"\")\n",
        "        score = reflection_output.get(\"reasoning_quality\", 0.0)\n",
        "\n",
        "        prompt = f\"\"\"\n",
        "You are a legal knowledge synthesizer. Summarize the key legal learning from this case in 34 sentences.\n",
        "Include what article or principle was applied, and what outcome reasoning improved.\n",
        "Keep it concise and professional.\n",
        "\n",
        "ISSUE: {key_issue}\n",
        "ANALYSIS: {key_analysis[:500]}\n",
        "CONCLUSION: {key_conclusion[:300]}\n",
        "OVERALL QUALITY: {score}\n",
        "\"\"\"\n",
        "        try:\n",
        "            if self.llm:\n",
        "                summary = self.llm(prompt, max_new_tokens=120)[0]['generated_text']\n",
        "                return summary.strip()\n",
        "        except Exception:\n",
        "            pass\n",
        "        return f\"Learned reasoning pattern: {key_issue}  Outcome reasoning quality={score}. Conclusion improved understanding of {key_conclusion[:120]}.\"\n",
        "\n",
        "    def update_memory(self, reflection_output, user_id=\"default_user\"):\n",
        "        \"\"\"Encode and store the new learning into adaptive memory.\"\"\"\n",
        "        summary = self.summarize_learning(reflection_output)\n",
        "        embedding = self.embedder.encode([summary], convert_to_numpy=True)\n",
        "        self.memory_entries[\"entries\"].append({\n",
        "            \"user\": user_id,\n",
        "            \"summary\": summary,\n",
        "            \"timestamp\": datetime.now().isoformat()\n",
        "        })\n",
        "        if len(self.memory_entries[\"embeddings\"]) == 0:\n",
        "            self.memory_entries[\"embeddings\"] = embedding\n",
        "        else:\n",
        "            self.memory_entries[\"embeddings\"] = np.vstack([self.memory_entries[\"embeddings\"], embedding])\n",
        "\n",
        "        with open(self.memory_path, \"wb\") as f:\n",
        "            pickle.dump(self.memory_entries, f)\n",
        "        print(f\"  Adaptive memory updated  {len(self.memory_entries['entries'])} total learnings stored.\")\n",
        "        return summary\n",
        "\n",
        "    def retrieve_related_learnings(self, query_text, top_k=3):\n",
        "        \"\"\"Find similar past learnings using semantic similarity.\"\"\"\n",
        "        if not self.memory_entries[\"entries\"]:\n",
        "            print(\"No adaptive memory yet.\")\n",
        "            return []\n",
        "        query_emb = self.embedder.encode([query_text], convert_to_numpy=True)\n",
        "        sims = np.dot(self.memory_entries[\"embeddings\"], query_emb.T).flatten()\n",
        "        top_idx = np.argsort(sims)[::-1][:top_k]\n",
        "        results = [self.memory_entries[\"entries\"][i] for i in top_idx]\n",
        "        print(f\" Retrieved {len(results)} related learnings.\")\n",
        "        return results\n",
        "\n",
        "\n",
        "\n",
        "memory_integrator = MemoryIntegratorAgent(orchestrator.context_manager)\n",
        "available_agents[\"memory_integrator\"] = memory_integrator\n",
        "setattr(orchestrator, \"memory_integrator\", memory_integrator)\n",
        "\n",
        "print(\"\\n MemoryIntegratorAgent integrated with orchestrator.\")\n",
        "print(\" Use: orchestrator.memory_integrator.update_memory(reflection_output, user_id='you')\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xKXdXov8-A-C",
        "outputId": "dc4b4ce4-21ca-4996-c4fc-0e1accd8d233"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  LLM (Flan-T5) loaded for adaptive case summarization.\n",
            "\n",
            " MemoryIntegratorAgent integrated with orchestrator.\n",
            " Use: orchestrator.memory_integrator.update_memory(reflection_output, user_id='you')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "cell 7: Continuous Learning Integration (Memory + Context + GoalManager connection). (hope)"
      ],
      "metadata": {
        "id": "cG1ezmY0_iB5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import os, json, time\n",
        "from datetime import datetime\n",
        "from transformers import pipeline\n",
        "\n",
        "ADAPTIVE_LOG_DIR = \"/content/drive/MyDrive/Argumate/results/adaptive_learning_logs\"\n",
        "os.makedirs(ADAPTIVE_LOG_DIR, exist_ok=True)\n",
        "\n",
        "class AdaptiveMemoryUpdater:\n",
        "    \"\"\"\n",
        "    Connects ContextManager, MemoryIntegratorAgent, and GoalManager\n",
        "    for continuous learning & goal refinement after each reflection cycle.\n",
        "    Uses an LLM to summarize and evolve learning goals.\n",
        "    \"\"\"\n",
        "    def __init__(self, context_manager, memory_integrator, goal_manager=None):\n",
        "        self.context_manager = context_manager\n",
        "        self.memory_integrator = memory_integrator\n",
        "        self.goal_manager = goal_manager\n",
        "        try:\n",
        "            self.llm = pipeline(\"text2text-generation\", model=\"google/flan-t5-small\", device_map=\"auto\")\n",
        "            print(\"  LLM loaded for adaptive goal refinement.\")\n",
        "        except Exception:\n",
        "            print(\"  No GPU acceleration available, fallback to CPU summarization.\")\n",
        "            self.llm = None\n",
        "\n",
        "    def _summarize_reflection(self, reflection_result):\n",
        "        \"\"\"Generate a compact LLM summary of what was learned.\"\"\"\n",
        "        plan = reflection_result.get(\"reasoning_plan\", reflection_result)\n",
        "        prompt = f\"\"\"\n",
        "Summarize in 34 lines what the AI system just learned from this reasoning cycle.\n",
        "Highlight which legal or reasoning aspects improved, and what should be adjusted next time.\n",
        "\n",
        "ISSUE: {plan.get('issue','')}\n",
        "ANALYSIS: {plan.get('analysis','')[:400]}\n",
        "CONCLUSION: {plan.get('conclusion','')[:200]}\n",
        "\"\"\"\n",
        "        try:\n",
        "            if self.llm:\n",
        "                return self.llm(prompt, max_new_tokens=120)[0]['generated_text'].strip()\n",
        "        except Exception:\n",
        "            pass\n",
        "        return f\"Learned about case issue '{plan.get('issue','')}' and improved reasoning clarity.\"\n",
        "\n",
        "    def update_after_reflection(self, reflection_result, user_id=\"default_user\"):\n",
        "        \"\"\"Full adaptive update: summarization  memory update  context sync  goal refinement.\"\"\"\n",
        "        print(\"\\n AdaptiveMemoryUpdater: Integrating new learning...\")\n",
        "\n",
        "        learning_summary = self._summarize_reflection(reflection_result)\n",
        "        print(f\"  Learned summary: {learning_summary[:150]}...\")\n",
        "\n",
        "\n",
        "        adaptive_summary = self.memory_integrator.update_memory(reflection_result, user_id=user_id)\n",
        "\n",
        "\n",
        "        sess = self.context_manager.start_session(\n",
        "            learning_summary, user_id=user_id,\n",
        "            metadata={\"type\": \"adaptive_learning\", \"summary\": adaptive_summary}\n",
        "        )\n",
        "        self.context_manager.add_event(sess[\"session_id\"], \"adaptive_learning\", adaptive_summary)\n",
        "\n",
        "\n",
        "        if self.goal_manager:\n",
        "            try:\n",
        "                new_goal_prompt = f\"\"\"\n",
        "You are an autonomous legal AI managing evolving goals.\n",
        "Given this new learning:\n",
        "{learning_summary}\n",
        "\n",
        "Suggest a refined next-step goal that continues the AIs mission of improving case reasoning accuracy.\n",
        "Respond as JSON with keys: next_goal, reason.\n",
        "\"\"\"\n",
        "                if self.llm:\n",
        "                    gen = self.llm(new_goal_prompt, max_new_tokens=100)[0]['generated_text']\n",
        "                    if \"next_goal\" in gen:\n",
        "                        goal_json = json.loads(gen[gen.find(\"{\"):gen.rfind(\"}\")+1])\n",
        "                        next_goal = goal_json.get(\"next_goal\", \"\")\n",
        "                        print(f\"  New goal identified: {next_goal}\")\n",
        "                        if hasattr(self.goal_manager, \"update_goal\"):\n",
        "                            self.goal_manager.update_goal(next_goal)\n",
        "            except Exception as e:\n",
        "                print(\"  Goal refinement failed:\", e)\n",
        "\n",
        "\n",
        "        log_entry = {\n",
        "            \"timestamp\": datetime.now().isoformat(),\n",
        "            \"learning_summary\": learning_summary,\n",
        "            \"adaptive_summary\": adaptive_summary,\n",
        "            \"user_id\": user_id\n",
        "        }\n",
        "        log_path = os.path.join(ADAPTIVE_LOG_DIR, f\"adaptive_update_{int(time.time())}.json\")\n",
        "        with open(log_path, \"w\", encoding=\"utf-8\") as f:\n",
        "            json.dump(log_entry, f, indent=2)\n",
        "\n",
        "        print(f\" Adaptive memory update complete. Log saved: {log_path}\")\n",
        "        return learning_summary\n",
        "\n",
        "adaptive_updater = AdaptiveMemoryUpdater(\n",
        "    context_manager=orchestrator.context_manager,\n",
        "    memory_integrator=orchestrator.memory_integrator,\n",
        "    goal_manager=getattr(orchestrator, \"goal_manager\", None)\n",
        ")\n",
        "setattr(orchestrator, \"adaptive_updater\", adaptive_updater)\n",
        "available_agents[\"adaptive_updater\"] = adaptive_updater\n",
        "\n",
        "print(\"\\n AdaptiveMemoryUpdater connected to orchestrator.\")\n",
        "print(\" Use: orchestrator.adaptive_updater.update_after_reflection(reflection_result, user_id='you')\")\n"
      ],
      "metadata": {
        "id": "9xcd1ZzV_opR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5233c02a-9f0f-406f-9544-90f550d3b42c"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  LLM loaded for adaptive goal refinement.\n",
            "\n",
            " AdaptiveMemoryUpdater connected to orchestrator.\n",
            " Use: orchestrator.adaptive_updater.update_after_reflection(reflection_result, user_id='you')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "cell 8 : Autonomous File Watcher  monitor_new_cases(hope)"
      ],
      "metadata": {
        "id": "sMdI66CGBpcT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import os, time, json\n",
        "from datetime import datetime\n",
        "\n",
        "def start_auto_file_watcher(check_interval=15):\n",
        "    \"\"\"\n",
        "    Continuously monitors /new_cases folder and automatically runs the full pipeline\n",
        "    whenever a new .txt or .json file is detected.\n",
        "    Works in Colab without background threads (safe continuous loop).\n",
        "    Stop manually with Interrupt (Ctrl + M + I).\n",
        "    \"\"\"\n",
        "    WATCH_FOLDER = \"/content/drive/MyDrive/Argumate/new_cases\"\n",
        "    OUTPUT_FOLDER = \"/content/drive/MyDrive/Argumate/results/output_argumate_readable\"\n",
        "\n",
        "    os.makedirs(WATCH_FOLDER, exist_ok=True)\n",
        "    os.makedirs(OUTPUT_FOLDER, exist_ok=True)\n",
        "\n",
        "    print(f\" Watching folder: {WATCH_FOLDER}\")\n",
        "    print(f\" Checking every {check_interval} seconds for new .txt or .json files...\\n\")\n",
        "\n",
        "    processed_files = set()\n",
        "\n",
        "    while True:\n",
        "        try:\n",
        "            files = [f for f in os.listdir(WATCH_FOLDER) if f.endswith(('.txt', '.json'))]\n",
        "            for fname in files:\n",
        "                fpath = os.path.join(WATCH_FOLDER, fname)\n",
        "                if fname not in processed_files:\n",
        "                    print(f\"\\n New case detected: {fname}    Running full pipeline...\\n\")\n",
        "                    with open(fpath, 'r', encoding='utf-8') as f:\n",
        "                        case_text = f.read()\n",
        "\n",
        "\n",
        "                    try:\n",
        "                        if hasattr(orchestrator, \"run_case_with_context\"):\n",
        "                            result = orchestrator.run_case_with_context(\n",
        "                                case_text, user_id=\"auto\", auto_update_memory=True\n",
        "                            )\n",
        "                        elif hasattr(orchestrator, \"run_case\"):\n",
        "                            result = orchestrator.run_case(case_text, auto_update_memory=True)\n",
        "                        else:\n",
        "                            raise RuntimeError(\"No orchestrator.run_case method found.\")\n",
        "\n",
        "\n",
        "                        save_report_files(case_text, result)\n",
        "                        print(f\" Report saved successfully at {datetime.now().strftime('%H:%M:%S')}\")\n",
        "\n",
        "                    except Exception as e:\n",
        "                        print(\" Pipeline failed:\", e)\n",
        "\n",
        "                    processed_files.add(fname)\n",
        "\n",
        "            time.sleep(check_interval)\n",
        "\n",
        "        except KeyboardInterrupt:\n",
        "            print(\"\\n Watcher stopped manually by user.\")\n",
        "            break\n",
        "        except Exception as e:\n",
        "            print(\"Watcher error:\", e)\n",
        "            time.sleep(10)\n"
      ],
      "metadata": {
        "id": "OlRu6AypBthK"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "last combined (i'm confused)"
      ],
      "metadata": {
        "id": "74wQZi9zHV59"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install fpdf\n"
      ],
      "metadata": {
        "id": "vbW58asfS2fu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b203d45-c07f-408a-a004-47e0a97ac611"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: fpdf in /usr/local/lib/python3.12/dist-packages (1.7.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import os, json, time, html, re\n",
        "from datetime import datetime\n",
        "from IPython.display import display, HTML, clear_output\n",
        "import ipywidgets as widgets\n",
        "\n",
        "try:\n",
        "    from fpdf import FPDF\n",
        "except Exception:\n",
        "    !pip install -q fpdf2\n",
        "    from fpdf import FPDF\n",
        "\n",
        "\n",
        "BASE = \"/content/drive/MyDrive/Argumate\"\n",
        "RESULTS_FINAL_DIR = f\"{BASE}/results/final_outputs\"\n",
        "RESULTS_HUMAN_DIR = f\"{BASE}/results/output_argumate_readable\"\n",
        "WATCH_FOLDER = f\"{BASE}/new_cases\"\n",
        "CHECKPOINTS_DIR = f\"{BASE}/checkpoints\"\n",
        "PROCESSED_LOG_PATH = f\"{CHECKPOINTS_DIR}/processed_cases.json\"\n",
        "ENDPOINTS_PATH = f\"{CHECKPOINTS_DIR}/agent_endpoints.json\"\n",
        "GUARDRAIL_PATH = f\"{BASE}/endpoints/guardrail_endpoint.json\"\n",
        "\n",
        "for d in [RESULTS_FINAL_DIR, RESULTS_HUMAN_DIR, WATCH_FOLDER, CHECKPOINTS_DIR]:\n",
        "    os.makedirs(d, exist_ok=True)\n",
        "\n",
        "\n",
        "class LegalPDF(FPDF):\n",
        "    def header(self):\n",
        "        self.set_font(\"Times\", \"B\", 14)\n",
        "        self.set_text_color(11, 61, 145)\n",
        "        self.cell(0, 10, \" Argumate 2.0  Legal AI Report\", ln=1, align=\"C\")\n",
        "        self.set_font(\"Times\", \"\", 10)\n",
        "        self.set_text_color(80, 80, 80)\n",
        "        self.cell(0, 8, f\"Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\", ln=1, align=\"C\")\n",
        "        self.ln(4)\n",
        "    def footer(self):\n",
        "        self.set_y(-15)\n",
        "        self.set_font(\"Times\", \"I\", 9)\n",
        "        self.set_text_color(120, 120, 120)\n",
        "        self.cell(0, 10, f\"Page {self.page_no()} | Argumate 2.0\", 0, 0, \"C\")\n",
        "\n",
        "def generate_pdf(case_text, run_data, pdf_path):\n",
        "    steps = run_data.get(\"result\", {}).get(\"steps\", {})\n",
        "    reasoning = (steps.get(\"reflect\") or {}).get(\"reasoning_plan\", {})\n",
        "    ev = steps.get(\"evaluate_confidence\", {})\n",
        "    facts = steps.get(\"fact_analysis\", {})\n",
        "\n",
        "    pdf = LegalPDF()\n",
        "    pdf.add_page()\n",
        "    pdf.set_auto_page_break(auto=True, margin=15)\n",
        "\n",
        "    def section(title, body):\n",
        "        pdf.set_font(\"Times\", \"B\", 12)\n",
        "        pdf.set_text_color(11, 61, 145)\n",
        "        pdf.multi_cell(0, 8, title)\n",
        "        pdf.set_font(\"Times\", \"\", 11)\n",
        "        pdf.set_text_color(0, 0, 0)\n",
        "        pdf.multi_cell(0, 6, body)\n",
        "        pdf.ln(3)\n",
        "\n",
        "    section(\"1. Parties and Articles\",\n",
        "             f\"Plaintiff: {facts.get('plaintiff','Unknown')}\\nDefendant: {facts.get('defendant','Unknown')}\\nArticles: {facts.get('articles','Not specified')}\")\n",
        "    conf = ev.get(\"confidence_score\", \"N/A\")\n",
        "    rq = (steps.get(\"reflect\") or {}).get(\"reasoning_quality\", \"N/A\")\n",
        "    outc = ev.get(\"predicted_outcome\", \"Unknown\")\n",
        "    section(\"2. Predicted Outcome & Confidence\",\n",
        "             f\"Outcome: {outc}\\nConfidence: {conf}\\nReasoning Quality: {rq}\")\n",
        "    section(\"3. Legal Reasoning\",\n",
        "             f\"Issue: {reasoning.get('issue','N/A')}\\n\\nFacts: {reasoning.get('facts_summary','N/A')}\\n\\nAnalysis: {reasoning.get('analysis','N/A')}\\n\\nConclusion: {reasoning.get('conclusion','N/A')}\")\n",
        "    precs = (steps.get(\"supporting_precedents\") or {}).get(\"supporting_precedents\", [])\n",
        "    section(\"4. Supporting Precedents\", \"\\n\".join([f\"{i+1}. {str(p)[:250]}...\" for i, p in enumerate(precs[:3])]) or \"None found\")\n",
        "    counters = steps.get(\"counter_arguments\", [])\n",
        "    section(\"5. Counter-Arguments\", \"\\n\".join([f\"{i+1}. {c.get('title','')}  {c.get('legal_rationale','')[:200]}\" for i, c in enumerate(counters[:3])]) or \"None generated\")\n",
        "    section(\"6. Reflection Summary\", f\"Reasoning Quality: {rq} | Confidence: {conf}\\nNo inconsistencies detected.\")\n",
        "    final_dec = ev.get(\"final_decision\", f\"Outcome '{outc}' accepted\")\n",
        "    section(\"7. Final Decision\", final_dec)\n",
        "    pdf.output(pdf_path)\n",
        "    return pdf_path\n",
        "\n",
        "\n",
        "def save_and_display(case_text, run_data):\n",
        "    ts = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "    base = f\"argumate_report_{ts}\"\n",
        "    json_path = os.path.join(RESULTS_FINAL_DIR, base + \".json\")\n",
        "    txt_path = os.path.join(RESULTS_FINAL_DIR, base + \".txt\")\n",
        "    html_path = os.path.join(RESULTS_HUMAN_DIR, base + \".html\")\n",
        "    pdf_path = os.path.join(RESULTS_HUMAN_DIR, base + \".pdf\")\n",
        "\n",
        "    with open(json_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(run_data, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "    steps = run_data.get(\"result\", {}).get(\"steps\", {})\n",
        "    facts = steps.get(\"fact_analysis\", {})\n",
        "    ev = steps.get(\"evaluate_confidence\", {})\n",
        "    ref = steps.get(\"reflect\", {})\n",
        "    reasoning = ref.get(\"reasoning_plan\", {})\n",
        "\n",
        "\n",
        "    llm_judge_result, guardrail_result = None, None\n",
        "    try:\n",
        "        if os.path.exists(ENDPOINTS_PATH):\n",
        "            print(\"\\n Running LLMJudgeAgent (endpoint)...\")\n",
        "            llm_judge_result = orchestrator.llm_judge.evaluate_reasoning(ref)\n",
        "    except Exception as e:\n",
        "        print(\" LLMJudgeAgent failed:\", e)\n",
        "\n",
        "    try:\n",
        "        if os.path.exists(GUARDRAIL_PATH):\n",
        "            print(\"\\n Running GuardrailAgent (endpoint)...\")\n",
        "            guardrail_result = guardrail_endpoint(reasoning.get(\"analysis\", \"\") + \" \" + reasoning.get(\"conclusion\", \"\"))\n",
        "    except Exception as e:\n",
        "        print(\" GuardrailAgent failed:\", e)\n",
        "\n",
        "    # Display results in terminal\n",
        "    if llm_judge_result:\n",
        "        print(\"\\n LLMJudgeAgent Evaluation Results:\")\n",
        "        print(json.dumps(llm_judge_result, indent=2))\n",
        "    if guardrail_result:\n",
        "        print(\"\\n GuardrailAgent Safety Check Results:\")\n",
        "        print(json.dumps(guardrail_result, indent=2))\n",
        "\n",
        "    # === Build Report ===\n",
        "    html_report = f\"\"\"\n",
        "    <div style='background:white;color:black;font-family:Georgia,serif;padding:25px;line-height:1.6;max-width:900px;margin:auto;border:1px solid #ccc;border-radius:8px'>\n",
        "    <h2 style='text-align:center;color:#0B3D91'> Final Structured Legal Report</h2>\n",
        "    <h3 style='color:#0B3D91'>1. Parties and Articles</h3>\n",
        "    <b>Plaintiff:</b> {facts.get('plaintiff','Unknown')}<br>\n",
        "    <b>Defendant:</b> {facts.get('defendant','Unknown')}<br>\n",
        "    <b>Articles:</b> {facts.get('articles','Not specified')}<br><br>\n",
        "    <h3 style='color:#0B3D91'>2. Predicted Outcome & Confidence</h3>\n",
        "    Outcome: {ev.get('predicted_outcome','Unknown')}<br>\n",
        "    Confidence: {ev.get('confidence_score','N/A')}<br>\n",
        "    Reasoning Quality: {ref.get('reasoning_quality','N/A')}<br><br>\n",
        "    <h3 style='color:#0B3D91'>3. Legal Reasoning</h3>\n",
        "    <b>Issue:</b> {reasoning.get('issue','N/A')}<br>\n",
        "    <b>Facts:</b> {reasoning.get('facts_summary','N/A')}<br>\n",
        "    <b>Analysis:</b> {reasoning.get('analysis','N/A')}<br>\n",
        "    <b>Conclusion:</b> {reasoning.get('conclusion','N/A')}<br><br>\n",
        "    <h3 style='color:#0B3D91'>4. Supporting Precedents</h3>\"\"\"\n",
        "    for p in (steps.get(\"supporting_precedents\") or {}).get(\"supporting_precedents\", [])[:3]:\n",
        "        html_report += f\" {str(p)[:250]}...<br>\"\n",
        "    html_report += \"<br><h3 style='color:#0B3D91'>5. Counter-Arguments</h3>\"\n",
        "    for c in steps.get(\"counter_arguments\", [])[:3]:\n",
        "        html_report += f\" <b>{c.get('title','')}</b>  {c.get('legal_rationale','')[:200]}<br>\"\n",
        "    html_report += f\"\"\"\n",
        "    <br><h3 style='color:#0B3D91'>6. Reflection Summary</h3>\n",
        "    Reasoning Quality: {ref.get('reasoning_quality','N/A')} | Confidence: {ev.get('confidence_score','N/A')}<br>\n",
        "    No inconsistencies detected.<br><br>\n",
        "    <h3 style='color:#0B3D91'>7. Final Decision</h3>\n",
        "    <b>{ev.get('final_decision') or f\"Outcome '{ev.get('predicted_outcome','Unknown')}' accepted\"}.</b><br><br>\"\"\"\n",
        "    if llm_judge_result:\n",
        "        html_report += f\"\"\"\n",
        "        <h3 style='color:#0B3D91'>8. LLMJudgeAgent Evaluation Summary</h3>\n",
        "        Avg Score: {llm_judge_result.get('average_score','N/A')}<br>\n",
        "        Scores: {json.dumps(llm_judge_result.get('scores',{}))}<br>\n",
        "        Advice: {llm_judge_result.get('improvement_advice','N/A')}<br><br>\"\"\"\n",
        "    if guardrail_result:\n",
        "        html_report += f\"\"\"\n",
        "        <h3 style='color:#0B3D91'>9. GuardrailAgent Ethical Check</h3>\n",
        "        Status: {guardrail_result.get('safety_status','N/A')}<br>\n",
        "        Issues: {', '.join(guardrail_result.get('issues', []))}<br><br>\"\"\"\n",
        "    html_report += \"<p style='color:gray;text-align:center;font-size:0.9em'>Argumate 2.0  AI-Powered Legal Reasoning System</p></div>\"\n",
        "    with open(html_path, \"w\", encoding=\"utf-8\") as f: f.write(html_report)\n",
        "    with open(txt_path, \"w\", encoding=\"utf-8\") as f: f.write(html.unescape(html_report))\n",
        "    try:\n",
        "        generate_pdf(case_text, run_data, pdf_path)\n",
        "    except Exception as e:\n",
        "        print(\" PDF generation failed:\", e)\n",
        "\n",
        "    clear_output()\n",
        "    display(HTML(html_report))\n",
        "    print(f\"\\n Reports saved:\\n- JSON: {json_path}\\n- TXT: {txt_path}\\n- HTML: {html_path}\\n- PDF: {pdf_path}\")\n",
        "\n",
        "\n",
        "AUTO_WATCHER_ACTIVE = False\n",
        "\n",
        "def start_auto_watcher(interval=20):\n",
        "    global AUTO_WATCHER_ACTIVE\n",
        "    AUTO_WATCHER_ACTIVE = True\n",
        "    print(f\" Watching {WATCH_FOLDER} every {interval}s...\\n\")\n",
        "    if os.path.exists(PROCESSED_LOG_PATH):\n",
        "        with open(PROCESSED_LOG_PATH, \"r\", encoding=\"utf-8\") as f:\n",
        "            processed = set(json.load(f))\n",
        "    else:\n",
        "        processed = set()\n",
        "    print(f\"Previously processed files: {len(processed)}\")\n",
        "\n",
        "    try:\n",
        "        while AUTO_WATCHER_ACTIVE:\n",
        "            current_files = [f for f in os.listdir(WATCH_FOLDER) if f.endswith('.txt')]\n",
        "            new_files = [f for f in current_files if f not in processed]\n",
        "            if new_files:\n",
        "                print(f\"\\n Detected {len(new_files)} new case(s): {new_files}\\n\")\n",
        "                for fname in new_files:\n",
        "                    path = os.path.join(WATCH_FOLDER, fname)\n",
        "                    with open(path, encoding=\"utf-8\") as f:\n",
        "                        case_text = f.read()\n",
        "                    print(f\"Running pipeline for {fname}...\\n\")\n",
        "                    if hasattr(orchestrator, \"run_case_with_context\"):\n",
        "                        res = orchestrator.run_case_with_context(case_text, user_id=\"auto\", auto_update_memory=True)\n",
        "                    else:\n",
        "                        res = orchestrator.run_case(case_text, auto_update_memory=True)\n",
        "                    save_and_display(case_text, res)\n",
        "                    processed.add(fname)\n",
        "                with open(PROCESSED_LOG_PATH, \"w\", encoding=\"utf-8\") as f:\n",
        "                    json.dump(sorted(list(processed)), f, indent=2)\n",
        "            else:\n",
        "                print(\" No new files detected. Waiting...\")\n",
        "            time.sleep(interval)\n",
        "    except KeyboardInterrupt:\n",
        "        print(\"\\n Auto Watcher stopped manually.\")\n",
        "    print(\" Auto Watcher loop exited cleanly.\")\n",
        "\n",
        "def stop_auto_watcher():\n",
        "    global AUTO_WATCHER_ACTIVE\n",
        "    AUTO_WATCHER_ACTIVE = False\n",
        "    print(\"\\n Auto Watcher stopping...\")\n",
        "\n",
        "\n",
        "case_input = widgets.Textarea(placeholder=\"Paste case text here...\", layout=widgets.Layout(width=\"98%\", height=\"220px\"))\n",
        "run_btn = widgets.Button(description=\"Run Full Autonomous Pipeline\", button_style=\"success\", icon=\"rocket\")\n",
        "start_watch_btn = widgets.Button(description=\"Start Auto Watcher\", button_style=\"primary\", icon=\"play\")\n",
        "stop_watch_btn = widgets.Button(description=\"Stop Auto Watcher\", button_style=\"warning\", icon=\"stop\")\n",
        "out = widgets.Output(layout={\"border\": \"1px solid black\", \"padding\": \"8px\", \"max_height\": \"600px\", \"overflow_y\": \"auto\"})\n",
        "\n",
        "def on_run(b):\n",
        "    with out:\n",
        "        clear_output()\n",
        "        case = case_input.value.strip()\n",
        "        if not case:\n",
        "            print(\" Paste a case first.\")\n",
        "            return\n",
        "        print(\" Running pipeline manually...\")\n",
        "        if hasattr(orchestrator, \"run_case_with_context\"):\n",
        "            r = orchestrator.run_case_with_context(case, user_id=\"you\", auto_update_memory=True)\n",
        "        else:\n",
        "            r = orchestrator.run_case(case, auto_update_memory=True)\n",
        "        save_and_display(case, r)\n",
        "\n",
        "def on_start(b):\n",
        "    with out:\n",
        "        clear_output()\n",
        "        print(\" Auto Watcher started.\")\n",
        "        start_auto_watcher(interval=20)\n",
        "\n",
        "def on_stop(b):\n",
        "    with out:\n",
        "        clear_output()\n",
        "        stop_auto_watcher()\n",
        "\n",
        "run_btn.on_click(on_run)\n",
        "start_watch_btn.on_click(on_start)\n",
        "stop_watch_btn.on_click(on_stop)\n",
        "\n",
        "controls = widgets.HBox([run_btn])\n",
        "extras = widgets.HBox([start_watch_btn, stop_watch_btn])\n",
        "title = widgets.HTML(\"<h2 style='color:#0B3D91'>Argumate  Final Orchestrator </h2>\")\n",
        "ui = widgets.VBox([title, case_input, controls, extras, out])\n",
        "display(ui)\n",
        "\n",
        "with out:\n",
        "    print(\" Ready. Paste your case and click 'Run Full Autonomous Pipeline'.\\nOr use Auto Watcher for automatic detection.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427,
          "referenced_widgets": [
            "671a5095969d4183b58db6b69a922546",
            "c1e576d650144ff0ab131affc880822f",
            "8f8b20939d3544719d8c50bf0cb264ac",
            "1b1a61af34b74b1ca70a2f48641b6d7a",
            "7d22220150da49f3895de8d0809e9bfb",
            "14df536a58174bd896dd5ee6a17d5dd6",
            "7d14897fcba2495fbf1cfb2b2cbc383b",
            "d1266547398e4b5aacc5bf03d8ef8b28",
            "95c7badd72894e00a3ac6e7003114322",
            "6bab63ac82514755909354c42f8d227a",
            "b0c66912c07f42ceaec0cb8d6a0cd7fc",
            "8fb951b62eed4aa7aed2b5668027583c",
            "066697edd3d34c87a9368e3e8f9b5d79",
            "0d9c5a6bc12b41f2808962d45fdb8fa5",
            "d21a8aa4a6a547ff846eabf9f3b07a76",
            "0d4aaad782ed4585bf1726cc9daeef98",
            "a07df38786ee44398e8e1c3f50413a40",
            "ff1b9d37d15b40058e4484053055a9e4",
            "72205ef9218c40c08ad432bff61265d2",
            "2ac4058d70174771b54a5f43d48a5ca9",
            "90a4c2aeb898483d887d1f2a2b939173",
            "9f50d3f1ff874e8cb5832c6145346039",
            "287a03f25c6640fabe788e0cb4483802"
          ]
        },
        "id": "GE3Sr6V0BENA",
        "outputId": "d3e6e48b-f65c-4702-c687-613d53e17472"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(HTML(value=\"<h2 style='color:#0B3D91'>Argumate  Final Orchestrator </h2>\"), Textarea(value='',"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "671a5095969d4183b58db6b69a922546"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import os, json, time, html, re\n",
        "from datetime import datetime\n",
        "from IPython.display import display, HTML, clear_output\n",
        "import ipywidgets as widgets\n",
        "\n",
        "try:\n",
        "    from fpdf import FPDF\n",
        "except Exception:\n",
        "    !pip install -q fpdf2\n",
        "    from fpdf import FPDF\n",
        "\n",
        "# ---- Paths ----\n",
        "BASE = \"/content/drive/MyDrive/Argumate\"\n",
        "RESULTS_FINAL_DIR = f\"{BASE}/results/final_outputs\"\n",
        "RESULTS_HUMAN_DIR = f\"{BASE}/results/output_argumate_readable\"\n",
        "WATCH_FOLDER = f\"{BASE}/new_cases\"\n",
        "CHECKPOINTS_DIR = f\"{BASE}/checkpoints\"\n",
        "PROCESSED_LOG_PATH = f\"{CHECKPOINTS_DIR}/processed_cases.json\"\n",
        "ENDPOINTS_PATH = f\"{CHECKPOINTS_DIR}/agent_endpoints.json\"\n",
        "GUARDRAIL_PATH = f\"{BASE}/endpoints/guardrail_endpoint.json\"\n",
        "\n",
        "for d in [RESULTS_FINAL_DIR, RESULTS_HUMAN_DIR, WATCH_FOLDER, CHECKPOINTS_DIR]:\n",
        "    os.makedirs(d, exist_ok=True)\n",
        "\n",
        "\n",
        "class LegalPDF(FPDF):\n",
        "    def header(self):\n",
        "        self.set_font(\"Times\", \"B\", 14)\n",
        "        self.set_text_color(11, 61, 145)\n",
        "        self.cell(0, 10, \" Argumate 2.0  Legal AI Report\", ln=1, align=\"C\")\n",
        "        self.set_font(\"Times\", \"\", 10)\n",
        "        self.set_text_color(80, 80, 80)\n",
        "        self.cell(0, 8, f\"Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\", ln=1, align=\"C\")\n",
        "        self.ln(4)\n",
        "    def footer(self):\n",
        "        self.set_y(-15)\n",
        "        self.set_font(\"Times\", \"I\", 9)\n",
        "        self.set_text_color(120, 120, 120)\n",
        "        self.cell(0, 10, f\"Page {self.page_no()} | Argumate 2.0\", 0, 0, \"C\")\n",
        "\n",
        "def generate_pdf(case_text, run_data, pdf_path):\n",
        "    steps = run_data.get(\"result\", {}).get(\"steps\", {})\n",
        "    reasoning = (steps.get(\"reflect\") or {}).get(\"reasoning_plan\", {})\n",
        "    ev = steps.get(\"evaluate_confidence\", {})\n",
        "    facts = steps.get(\"fact_analysis\", {})\n",
        "\n",
        "    pdf = LegalPDF()\n",
        "    pdf.add_page()\n",
        "    pdf.set_auto_page_break(auto=True, margin=15)\n",
        "\n",
        "    def section(title, body):\n",
        "        pdf.set_font(\"Times\", \"B\", 12)\n",
        "        pdf.set_text_color(11, 61, 145)\n",
        "        pdf.multi_cell(0, 8, title)\n",
        "        pdf.set_font(\"Times\", \"\", 11)\n",
        "        pdf.set_text_color(0, 0, 0)\n",
        "        pdf.multi_cell(0, 6, body)\n",
        "        pdf.ln(3)\n",
        "\n",
        "    section(\"1. Parties and Articles\",\n",
        "             f\"Plaintiff: {facts.get('plaintiff','Unknown')}\\nDefendant: {facts.get('defendant','Unknown')}\\nArticles: {facts.get('articles','Not specified')}\")\n",
        "    conf = ev.get(\"confidence_score\", \"N/A\")\n",
        "    rq = (steps.get(\"reflect\") or {}).get(\"reasoning_quality\", \"N/A\")\n",
        "    outc = ev.get(\"predicted_outcome\", \"Unknown\")\n",
        "    section(\"2. Predicted Outcome & Confidence\",\n",
        "             f\"Outcome: {outc}\\nConfidence: {conf}\\nReasoning Quality: {rq}\")\n",
        "    section(\"3. Legal Reasoning\",\n",
        "             f\"Issue: {reasoning.get('issue','N/A')}\\n\\nFacts: {reasoning.get('facts_summary','N/A')}\\n\\nAnalysis: {reasoning.get('analysis','N/A')}\\n\\nConclusion: {reasoning.get('conclusion','N/A')}\")\n",
        "    precs = (steps.get(\"supporting_precedents\") or {}).get(\"supporting_precedents\", [])\n",
        "    section(\"4. Supporting Precedents\", \"\\n\".join([f\"{i+1}. {str(p)[:250]}...\" for i, p in enumerate(precs[:3])]) or \"None found\")\n",
        "    counters = steps.get(\"counter_arguments\", [])\n",
        "    section(\"5. Counter-Arguments\", \"\\n\".join([f\"{i+1}. {c.get('title','')}  {c.get('legal_rationale','')[:200]}\" for i, c in enumerate(counters[:3])]) or \"None generated\")\n",
        "    section(\"6. Reflection Summary\", f\"Reasoning Quality: {rq} | Confidence: {conf}\\nNo inconsistencies detected.\")\n",
        "    final_dec = ev.get(\"final_decision\", f\"Outcome '{outc}' accepted\")\n",
        "    section(\"7. Final Decision\", final_dec)\n",
        "    pdf.output(pdf_path)\n",
        "    return pdf_path\n",
        "\n",
        "\n",
        "def save_and_display(case_text, run_data):\n",
        "    ts = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "    base = f\"argumate_report_{ts}\"\n",
        "    json_path = os.path.join(RESULTS_FINAL_DIR, base + \".json\")\n",
        "    txt_path = os.path.join(RESULTS_FINAL_DIR, base + \".txt\")\n",
        "    html_path = os.path.join(RESULTS_HUMAN_DIR, base + \".html\")\n",
        "    pdf_path = os.path.join(RESULTS_HUMAN_DIR, base + \".pdf\")\n",
        "\n",
        "    with open(json_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(run_data, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "    steps = run_data.get(\"result\", {}).get(\"steps\", {})\n",
        "    facts = steps.get(\"fact_analysis\", {})\n",
        "    ev = steps.get(\"evaluate_confidence\", {})\n",
        "    ref = steps.get(\"reflect\", {})\n",
        "    reasoning = ref.get(\"reasoning_plan\", {})\n",
        "\n",
        "\n",
        "    llm_judge_result, guardrail_result = None, None\n",
        "    try:\n",
        "        if os.path.exists(ENDPOINTS_PATH):\n",
        "            print(\"\\n Running LLMJudgeAgent (endpoint)...\")\n",
        "            llm_judge_result = orchestrator.llm_judge.evaluate_reasoning(ref)\n",
        "    except Exception as e:\n",
        "        print(\" LLMJudgeAgent failed:\", e)\n",
        "\n",
        "    try:\n",
        "        if os.path.exists(GUARDRAIL_PATH):\n",
        "            print(\"\\n Running GuardrailAgent (endpoint)...\")\n",
        "            guardrail_result = guardrail_endpoint(reasoning.get(\"analysis\", \"\") + \" \" + reasoning.get(\"conclusion\", \"\"))\n",
        "    except Exception as e:\n",
        "        print(\" GuardrailAgent failed:\", e)\n",
        "\n",
        "    if llm_judge_result:\n",
        "        print(\"\\n LLMJudgeAgent Evaluation Results:\")\n",
        "        print(json.dumps(llm_judge_result, indent=2))\n",
        "    if guardrail_result:\n",
        "        print(\"\\n GuardrailAgent Safety Check Results:\")\n",
        "        print(json.dumps(guardrail_result, indent=2))\n",
        "\n",
        "    html_report = f\"\"\"\n",
        "    <div style='background:white;color:black;font-family:Georgia,serif;padding:25px;line-height:1.6;max-width:900px;margin:auto;border:1px solid #ccc;border-radius:8px'>\n",
        "    <h2 style='text-align:center;color:#0B3D91'> Final Structured Legal Report</h2>\n",
        "    <h3 style='color:#0B3D91'>1. Parties and Articles</h3>\n",
        "    <b>Plaintiff:</b> {facts.get('plaintiff','Unknown')}<br>\n",
        "    <b>Defendant:</b> {facts.get('defendant','Unknown')}<br>\n",
        "    <b>Articles:</b> {facts.get('articles','Not specified')}<br><br>\n",
        "    <h3 style='color:#0B3D91'>2. Predicted Outcome & Confidence</h3>\n",
        "    Outcome: {ev.get('predicted_outcome','Unknown')}<br>\n",
        "    Confidence: {ev.get('confidence_score','N/A')}<br>\n",
        "    Reasoning Quality: {ref.get('reasoning_quality','N/A')}<br><br>\n",
        "    <h3 style='color:#0B3D91'>3. Legal Reasoning</h3>\n",
        "    <b>Issue:</b> {reasoning.get('issue','N/A')}<br>\n",
        "    <b>Facts:</b> {reasoning.get('facts_summary','N/A')}<br>\n",
        "    <b>Analysis:</b> {reasoning.get('analysis','N/A')}<br>\n",
        "    <b>Conclusion:</b> {reasoning.get('conclusion','N/A')}<br><br>\n",
        "    <h3 style='color:#0B3D91'>4. Supporting Precedents</h3>\"\"\"\n",
        "    for p in (steps.get(\"supporting_precedents\") or {}).get(\"supporting_precedents\", [])[:3]:\n",
        "        html_report += f\" {str(p)[:250]}...<br>\"\n",
        "    html_report += \"<br><h3 style='color:#0B3D91'>5. Counter-Arguments</h3>\"\n",
        "    for c in steps.get(\"counter_arguments\", [])[:3]:\n",
        "        html_report += f\" <b>{c.get('title','')}</b>  {c.get('legal_rationale','')[:200]}<br>\"\n",
        "    html_report += f\"\"\"\n",
        "    <br><h3 style='color:#0B3D91'>6. Reflection Summary</h3>\n",
        "    Reasoning Quality: {ref.get('reasoning_quality','N/A')} | Confidence: {ev.get('confidence_score','N/A')}<br>\n",
        "    No inconsistencies detected.<br><br>\n",
        "    <h3 style='color:#0B3D91'>7. Final Decision</h3>\n",
        "    <b>{ev.get('final_decision') or f\"Outcome '{ev.get('predicted_outcome','Unknown')}' accepted\"}.</b><br><br>\"\"\"\n",
        "    if llm_judge_result:\n",
        "        html_report += f\"\"\"\n",
        "        <h3 style='color:#0B3D91'>8. LLMJudgeAgent Evaluation Summary</h3>\n",
        "        Avg Score: {llm_judge_result.get('average_score','N/A')}<br>\n",
        "        Scores: {json.dumps(llm_judge_result.get('scores',{}))}<br>\n",
        "        Advice: {llm_judge_result.get('improvement_advice','N/A')}<br><br>\"\"\"\n",
        "    if guardrail_result:\n",
        "        html_report += f\"\"\"\n",
        "        <h3 style='color:#0B3D91'>9. GuardrailAgent Ethical Check</h3>\n",
        "        Status: {guardrail_result.get('safety_status','N/A')}<br>\n",
        "        Issues: {', '.join(guardrail_result.get('issues', []))}<br><br>\"\"\"\n",
        "    html_report += \"<p style='color:gray;text-align:center;font-size:0.9em'>Argumate 2.0  AI-Powered Legal Reasoning System</p></div>\"\n",
        "    with open(html_path, \"w\", encoding=\"utf-8\") as f: f.write(html_report)\n",
        "    with open(txt_path, \"w\", encoding=\"utf-8\") as f: f.write(html.unescape(html_report))\n",
        "    try:\n",
        "        generate_pdf(case_text, run_data, pdf_path)\n",
        "    except Exception as e:\n",
        "        print(\" PDF generation failed:\", e)\n",
        "\n",
        "    clear_output()\n",
        "    display(HTML(html_report))\n",
        "    print(f\"\\n Reports saved:\\n- JSON: {json_path}\\n- TXT: {txt_path}\\n- HTML: {html_path}\\n- PDF: {pdf_path}\")\n",
        "\n",
        "\n",
        "AUTO_WATCHER_ACTIVE = False\n",
        "\n",
        "def start_auto_watcher(interval=20):\n",
        "    global AUTO_WATCHER_ACTIVE\n",
        "    AUTO_WATCHER_ACTIVE = True\n",
        "    print(f\" Watching {WATCH_FOLDER} every {interval}s...\\n\")\n",
        "    if os.path.exists(PROCESSED_LOG_PATH):\n",
        "        with open(PROCESSED_LOG_PATH, \"r\", encoding=\"utf-8\") as f:\n",
        "            processed = set(json.load(f))\n",
        "    else:\n",
        "        processed = set()\n",
        "    print(f\"Previously processed files: {len(processed)}\")\n",
        "\n",
        "    try:\n",
        "        while AUTO_WATCHER_ACTIVE:\n",
        "            current_files = [f for f in os.listdir(WATCH_FOLDER) if f.endswith('.txt')]\n",
        "            new_files = [f for f in current_files if f not in processed]\n",
        "            if new_files:\n",
        "                print(f\"\\n Detected {len(new_files)} new case(s): {new_files}\\n\")\n",
        "                for fname in new_files:\n",
        "                    path = os.path.join(WATCH_FOLDER, fname)\n",
        "                    with open(path, encoding=\"utf-8\") as f:\n",
        "                        case_text = f.read()\n",
        "                    print(f\"Running pipeline for {fname}...\\n\")\n",
        "                    if hasattr(orchestrator, \"run_case_with_context\"):\n",
        "                        res = orchestrator.run_case_with_context(case_text, user_id=\"auto\", auto_update_memory=True)\n",
        "                    else:\n",
        "                        res = orchestrator.run_case(case_text, auto_update_memory=True)\n",
        "                    save_and_display(case_text, res)\n",
        "                    processed.add(fname)\n",
        "                with open(PROCESSED_LOG_PATH, \"w\", encoding=\"utf-8\") as f:\n",
        "                    json.dump(sorted(list(processed)), f, indent=2)\n",
        "            else:\n",
        "                print(\" No new files detected. Waiting...\")\n",
        "            time.sleep(interval)\n",
        "    except KeyboardInterrupt:\n",
        "        print(\"\\n Auto Watcher stopped manually.\")\n",
        "    print(\" Auto Watcher loop exited cleanly.\")\n",
        "\n",
        "def stop_auto_watcher():\n",
        "    global AUTO_WATCHER_ACTIVE\n",
        "    AUTO_WATCHER_ACTIVE = False\n",
        "    print(\"\\n Auto Watcher stopping...\")\n",
        "\n",
        "\n",
        "case_input = widgets.Textarea(placeholder=\"Paste case text here...\", layout=widgets.Layout(width=\"98%\", height=\"220px\"))\n",
        "run_btn = widgets.Button(description=\"Run Full Autonomous Pipeline\", button_style=\"success\", icon=\"rocket\")\n",
        "start_watch_btn = widgets.Button(description=\"Start Auto Watcher\", button_style=\"primary\", icon=\"play\")\n",
        "stop_watch_btn = widgets.Button(description=\"Stop Auto Watcher\", button_style=\"warning\", icon=\"stop\")\n",
        "out = widgets.Output(layout={\"border\": \"1px solid black\", \"padding\": \"8px\", \"max_height\": \"600px\", \"overflow_y\": \"auto\"})\n",
        "\n",
        "def on_run(b):\n",
        "    with out:\n",
        "        clear_output()\n",
        "        case = case_input.value.strip()\n",
        "        if not case:\n",
        "            print(\" Paste a case first.\")\n",
        "            return\n",
        "        print(\" Running pipeline manually...\")\n",
        "        if hasattr(orchestrator, \"run_case_with_context\"):\n",
        "            r = orchestrator.run_case_with_context(case, user_id=\"you\", auto_update_memory=True)\n",
        "        else:\n",
        "            r = orchestrator.run_case(case, auto_update_memory=True)\n",
        "        save_and_display(case, r)\n",
        "\n",
        "def on_start(b):\n",
        "    with out:\n",
        "        clear_output()\n",
        "        print(\" Auto Watcher started.\")\n",
        "        start_auto_watcher(interval=20)\n",
        "\n",
        "def on_stop(b):\n",
        "    with out:\n",
        "        clear_output()\n",
        "        stop_auto_watcher()\n",
        "\n",
        "run_btn.on_click(on_run)\n",
        "start_watch_btn.on_click(on_start)\n",
        "stop_watch_btn.on_click(on_stop)\n",
        "\n",
        "controls = widgets.HBox([run_btn])\n",
        "extras = widgets.HBox([start_watch_btn, stop_watch_btn])\n",
        "title = widgets.HTML(\"<h2 style='color:#0B3D91'>Argumate  Final Orchestrator </h2>\")\n",
        "ui = widgets.VBox([title, case_input, controls, extras, out])\n",
        "display(ui)\n",
        "\n",
        "with out:\n",
        "    print(\" Ready. Paste your case and click 'Run Full Autonomous Pipeline'.\\nOr use Auto Watcher for automatic detection.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 975,
          "referenced_widgets": [
            "675f97ecb9a348a98c6f1d4935a7f0f3",
            "92e51abd17ad407a91155ef7f81a178c",
            "c59fbf3d291f45928c659b50c77ed43c",
            "0047d5c5764844ea84d00ce6232bba4f",
            "d16c99fce4d942f69e6dfebd2a480f4b",
            "bdd12708571c4b10943e3ef34e9b6c2b",
            "3ea94a2bcd084bdeb3f392c40d30411a",
            "2d1a9415fc294ef79cd0895fd6be348c",
            "7931dd1fb3b54874b2a7a90d51f665ef",
            "6be92dcc683445c081512697d5acc25b",
            "ba2e09b2c44148bb890cd5de1421ff7b",
            "b15c5d12a59d4c4abe105971f30393a6",
            "44fe45d28e3e4a3b88e7d47e333bc755",
            "c8f95a9b524c4e6d9c0ffa25215a4d55",
            "816b727df5b846f8a72104a0af203d64",
            "fd5749683fb24e9389b4a6db618c11bc",
            "64c8219bb1274ae1aaa95f85699309ad",
            "95c36c2dc6794ba6b3cc7afa99267c77",
            "1dbdc379a26e4f93b239b35975ee721f",
            "d779d83bdca146dca8eb9422afc6189d",
            "b1f38013bc974de8998fab57ef84f824",
            "72cb7a2314224282bfc62c88c4866929",
            "a188f5c23fa84bc4906c13ffdcf20253"
          ]
        },
        "id": "GDE1xdTXExvL",
        "outputId": "2f8adbb4-594e-4f12-85c6-5db169bb5bc4"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(HTML(value=\"<h2 style='color:#0B3D91'>Argumate  Final Orchestrator </h2>\"), Textarea(value='',"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "675f97ecb9a348a98c6f1d4935a7f0f3"
            }
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "e8bb207e1fc64567be40d3767b1d3b37": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fde9251228ea4f48bec524e9087dfa0c",
              "IPY_MODEL_322a9e21240b455c87027c5ed6130c14",
              "IPY_MODEL_ef1084ad23624349bf9293bc8f5fea5d"
            ],
            "layout": "IPY_MODEL_3d5fc522afb94d328bb98750645a6eb9"
          }
        },
        "fde9251228ea4f48bec524e9087dfa0c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_38fa55d586c2442f9fa288b5623d8c89",
            "placeholder": "",
            "style": "IPY_MODEL_056bc0ce8a7a48c5b1b375bb8f83eba8",
            "value": "Loadingcheckpointshards:100%"
          }
        },
        "322a9e21240b455c87027c5ed6130c14": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_779f9f2a1e354c2ab23423e170fb6a63",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2a9d0ba2fb544229b460f2ef18053944",
            "value": 2
          }
        },
        "ef1084ad23624349bf9293bc8f5fea5d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_39b51c613369431b825573c9c5a67429",
            "placeholder": "",
            "style": "IPY_MODEL_02b2dd0edc194646924f72b01388b545",
            "value": "2/2[00:00&lt;00:00,4.11it/s]"
          }
        },
        "3d5fc522afb94d328bb98750645a6eb9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "38fa55d586c2442f9fa288b5623d8c89": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "056bc0ce8a7a48c5b1b375bb8f83eba8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "779f9f2a1e354c2ab23423e170fb6a63": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2a9d0ba2fb544229b460f2ef18053944": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "39b51c613369431b825573c9c5a67429": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "02b2dd0edc194646924f72b01388b545": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9f07a7346afc48e0b0b377f291a3fb98": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_67bebfcde35d480db712fc6678ba3d8b",
              "IPY_MODEL_cc78b2ddfd764610a3e5052903c883fd",
              "IPY_MODEL_116b4137301e4726bd5e87aa5c452918"
            ],
            "layout": "IPY_MODEL_836f2bc515dd4338af7c56c81e04a191"
          }
        },
        "67bebfcde35d480db712fc6678ba3d8b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b849e972eba14dabafc1a708d00b8db4",
            "placeholder": "",
            "style": "IPY_MODEL_ef1f6339389040afaa68cba255930e03",
            "value": "Batches:100%"
          }
        },
        "cc78b2ddfd764610a3e5052903c883fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cdc77a1d5e4c4c819982bbc5eb9d6a32",
            "max": 16,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_58d8e6d6001648af8097b935bf8bf1b4",
            "value": 16
          }
        },
        "116b4137301e4726bd5e87aa5c452918": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1bdb271c88da403e8528595640029056",
            "placeholder": "",
            "style": "IPY_MODEL_92faba3bd223496b99a0c4fa6701a0a6",
            "value": "16/16[01:05&lt;00:00,3.75s/it]"
          }
        },
        "836f2bc515dd4338af7c56c81e04a191": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b849e972eba14dabafc1a708d00b8db4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ef1f6339389040afaa68cba255930e03": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cdc77a1d5e4c4c819982bbc5eb9d6a32": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "58d8e6d6001648af8097b935bf8bf1b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1bdb271c88da403e8528595640029056": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "92faba3bd223496b99a0c4fa6701a0a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2383910e9b254d3aac89758c636b1dbb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_dabd3516b71d47e992120d242faf0f2d",
              "IPY_MODEL_9490b2d4649640a9b13aebe8e80e702c",
              "IPY_MODEL_023c2b522b894514aafd579b0e30d801"
            ],
            "layout": "IPY_MODEL_6797dfec999f4f38ab9a3b2ad7952ea0"
          }
        },
        "dabd3516b71d47e992120d242faf0f2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b6cac523ced74e58bbd7728029a45a5b",
            "placeholder": "",
            "style": "IPY_MODEL_e17079eb2171401ea03e8c3a52ffb7d2",
            "value": "Batches:100%"
          }
        },
        "9490b2d4649640a9b13aebe8e80e702c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_224e4396b811450b8c6878ca54b11e13",
            "max": 32,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_85acd177bd2c484ab5935daead4f3b2d",
            "value": 32
          }
        },
        "023c2b522b894514aafd579b0e30d801": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fa1abe70a1e54cb598c5da07407c745f",
            "placeholder": "",
            "style": "IPY_MODEL_a27c2afb57934fdfb88b6ce110d0df16",
            "value": "32/32[01:52&lt;00:00,1.61s/it]"
          }
        },
        "6797dfec999f4f38ab9a3b2ad7952ea0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b6cac523ced74e58bbd7728029a45a5b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e17079eb2171401ea03e8c3a52ffb7d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "224e4396b811450b8c6878ca54b11e13": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "85acd177bd2c484ab5935daead4f3b2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fa1abe70a1e54cb598c5da07407c745f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a27c2afb57934fdfb88b6ce110d0df16": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1ef4fbb218544265908e43bff472d484": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_265b6a6f386f441890cd871874c65e70",
              "IPY_MODEL_0d720fc7ff8648e8a36a0b29ab557066",
              "IPY_MODEL_c8c2ba343b3e48e188abda7e2a483cfc"
            ],
            "layout": "IPY_MODEL_a4c98cfeb8424e959c9534c51a3305da"
          }
        },
        "265b6a6f386f441890cd871874c65e70": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a9d5461ecffc41b7b5f912da9b5f2405",
            "placeholder": "",
            "style": "IPY_MODEL_fa505698dace49319998aac939ba1eaa",
            "value": "Batches:100%"
          }
        },
        "0d720fc7ff8648e8a36a0b29ab557066": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b28a0113d21c4a75af8b3aa203dea87a",
            "max": 32,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_313a21fe8439409a96d65ab401052fc0",
            "value": 32
          }
        },
        "c8c2ba343b3e48e188abda7e2a483cfc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5b0cf34ff81d4b3494bca46c5f6d96c4",
            "placeholder": "",
            "style": "IPY_MODEL_55e55cc0d3e34df89247027a03a17232",
            "value": "32/32[02:48&lt;00:00,3.47s/it]"
          }
        },
        "a4c98cfeb8424e959c9534c51a3305da": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a9d5461ecffc41b7b5f912da9b5f2405": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fa505698dace49319998aac939ba1eaa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b28a0113d21c4a75af8b3aa203dea87a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "313a21fe8439409a96d65ab401052fc0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5b0cf34ff81d4b3494bca46c5f6d96c4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "55e55cc0d3e34df89247027a03a17232": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "671a5095969d4183b58db6b69a922546": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c1e576d650144ff0ab131affc880822f",
              "IPY_MODEL_8f8b20939d3544719d8c50bf0cb264ac",
              "IPY_MODEL_1b1a61af34b74b1ca70a2f48641b6d7a",
              "IPY_MODEL_7d22220150da49f3895de8d0809e9bfb",
              "IPY_MODEL_14df536a58174bd896dd5ee6a17d5dd6"
            ],
            "layout": "IPY_MODEL_7d14897fcba2495fbf1cfb2b2cbc383b"
          }
        },
        "c1e576d650144ff0ab131affc880822f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d1266547398e4b5aacc5bf03d8ef8b28",
            "placeholder": "",
            "style": "IPY_MODEL_95c7badd72894e00a3ac6e7003114322",
            "value": "<h2 style='color:#0B3D91'>Argumate  Final Orchestrator </h2>"
          }
        },
        "8f8b20939d3544719d8c50bf0cb264ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "TextareaModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "TextareaModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "TextareaView",
            "continuous_update": true,
            "description": "",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_6bab63ac82514755909354c42f8d227a",
            "placeholder": "Paste case text here...",
            "rows": null,
            "style": "IPY_MODEL_b0c66912c07f42ceaec0cb8d6a0cd7fc",
            "value": ""
          }
        },
        "1b1a61af34b74b1ca70a2f48641b6d7a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8fb951b62eed4aa7aed2b5668027583c"
            ],
            "layout": "IPY_MODEL_066697edd3d34c87a9368e3e8f9b5d79"
          }
        },
        "7d22220150da49f3895de8d0809e9bfb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0d9c5a6bc12b41f2808962d45fdb8fa5",
              "IPY_MODEL_d21a8aa4a6a547ff846eabf9f3b07a76"
            ],
            "layout": "IPY_MODEL_0d4aaad782ed4585bf1726cc9daeef98"
          }
        },
        "14df536a58174bd896dd5ee6a17d5dd6": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_287a03f25c6640fabe788e0cb4483802",
            "msg_id": "",
            "outputs": [
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  " Ready. Paste your case and click 'Run Full Autonomous Pipeline'.\n",
                  "Or use Auto Watcher for automatic detection.\n"
                ]
              }
            ]
          }
        },
        "7d14897fcba2495fbf1cfb2b2cbc383b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d1266547398e4b5aacc5bf03d8ef8b28": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "95c7badd72894e00a3ac6e7003114322": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6bab63ac82514755909354c42f8d227a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": "220px",
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "98%"
          }
        },
        "b0c66912c07f42ceaec0cb8d6a0cd7fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8fb951b62eed4aa7aed2b5668027583c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "success",
            "description": "Run Full Autonomous Pipeline",
            "disabled": false,
            "icon": "rocket",
            "layout": "IPY_MODEL_a07df38786ee44398e8e1c3f50413a40",
            "style": "IPY_MODEL_ff1b9d37d15b40058e4484053055a9e4",
            "tooltip": ""
          }
        },
        "066697edd3d34c87a9368e3e8f9b5d79": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0d9c5a6bc12b41f2808962d45fdb8fa5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "primary",
            "description": "Start Auto Watcher",
            "disabled": false,
            "icon": "play",
            "layout": "IPY_MODEL_72205ef9218c40c08ad432bff61265d2",
            "style": "IPY_MODEL_2ac4058d70174771b54a5f43d48a5ca9",
            "tooltip": ""
          }
        },
        "d21a8aa4a6a547ff846eabf9f3b07a76": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "warning",
            "description": "Stop Auto Watcher",
            "disabled": false,
            "icon": "stop",
            "layout": "IPY_MODEL_90a4c2aeb898483d887d1f2a2b939173",
            "style": "IPY_MODEL_9f50d3f1ff874e8cb5832c6145346039",
            "tooltip": ""
          }
        },
        "0d4aaad782ed4585bf1726cc9daeef98": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a07df38786ee44398e8e1c3f50413a40": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ff1b9d37d15b40058e4484053055a9e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "72205ef9218c40c08ad432bff61265d2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2ac4058d70174771b54a5f43d48a5ca9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "90a4c2aeb898483d887d1f2a2b939173": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9f50d3f1ff874e8cb5832c6145346039": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "287a03f25c6640fabe788e0cb4483802": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": "1px solid black",
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": "600px",
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": "auto",
            "padding": "8px",
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "675f97ecb9a348a98c6f1d4935a7f0f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_92e51abd17ad407a91155ef7f81a178c",
              "IPY_MODEL_c59fbf3d291f45928c659b50c77ed43c",
              "IPY_MODEL_0047d5c5764844ea84d00ce6232bba4f",
              "IPY_MODEL_d16c99fce4d942f69e6dfebd2a480f4b",
              "IPY_MODEL_bdd12708571c4b10943e3ef34e9b6c2b"
            ],
            "layout": "IPY_MODEL_3ea94a2bcd084bdeb3f392c40d30411a"
          }
        },
        "92e51abd17ad407a91155ef7f81a178c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2d1a9415fc294ef79cd0895fd6be348c",
            "placeholder": "",
            "style": "IPY_MODEL_7931dd1fb3b54874b2a7a90d51f665ef",
            "value": "<h2 style='color:#0B3D91'>Argumate  Final Orchestrator </h2>"
          }
        },
        "c59fbf3d291f45928c659b50c77ed43c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "TextareaModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "TextareaModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "TextareaView",
            "continuous_update": true,
            "description": "",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_6be92dcc683445c081512697d5acc25b",
            "placeholder": "Paste case text here...",
            "rows": null,
            "style": "IPY_MODEL_ba2e09b2c44148bb890cd5de1421ff7b",
            "value": "The applicant, Mr. Daniel Costa, is a Portuguese national residing in Lisbon. \nHe alleged that his right to privacy under Article 8 of the Convention was violated when the local tax authorities accessed his bank transaction records during a corruption investigation. \n\nAccording to the facts, the financial inspection unit, acting under a judicial warrant, obtained the applicants bank data for the years 20212023. \nThe warrant had been issued by the Lisbon District Court following substantiated suspicions of illicit public contracting. \nThe applicant contends that this constituted an excessive intrusion into his private life and financial autonomy. \n\nHowever, the Government maintained that the interference pursued a legitimate aimnamely, prevention of corruption and enforcement of tax lawand was proportionate in scope. \nOnly specific transactions related to the contracting tender were examined, and data unrelated to the investigation was excluded. \n\nThe Court notes that the applicant was not prosecuted or detained, and that the measure was carried out under strict judicial supervision. \nFurthermore, safeguards such as limited data retention and oversight by the national data protection authority were observed. \n\nThe applicant claims a violation of Article 8 of the European Convention on Human Rights (right to respect for private and family life).\n\nRequested outcome: determination whether the States interference constituted a violation or no violation under Article 8.\n"
          }
        },
        "0047d5c5764844ea84d00ce6232bba4f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b15c5d12a59d4c4abe105971f30393a6"
            ],
            "layout": "IPY_MODEL_44fe45d28e3e4a3b88e7d47e333bc755"
          }
        },
        "d16c99fce4d942f69e6dfebd2a480f4b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c8f95a9b524c4e6d9c0ffa25215a4d55",
              "IPY_MODEL_816b727df5b846f8a72104a0af203d64"
            ],
            "layout": "IPY_MODEL_fd5749683fb24e9389b4a6db618c11bc"
          }
        },
        "bdd12708571c4b10943e3ef34e9b6c2b": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_a188f5c23fa84bc4906c13ffdcf20253",
            "msg_id": "",
            "outputs": [
              {
                "output_type": "display_data",
                "data": {
                  "text/plain": "<IPython.core.display.HTML object>",
                  "text/html": "\n    <div style='background:white;color:black;font-family:Georgia,serif;padding:25px;line-height:1.6;max-width:900px;margin:auto;border:1px solid #ccc;border-radius:8px'>\n    <h2 style='text-align:center;color:#0B3D91'> Final Structured Legal Report</h2>\n    <h3 style='color:#0B3D91'>1. Parties and Articles</h3>\n    <b>Plaintiff:</b> Daniel Costa<br>\n    <b>Defendant:</b> The Respondent<br>\n    <b>Articles:</b> ['8']<br><br>\n    <h3 style='color:#0B3D91'>2. Predicted Outcome & Confidence</h3>\n    Outcome: Non-Violation<br>\n    Confidence: 0.9<br>\n    Reasoning Quality: 0.87<br><br>\n    <h3 style='color:#0B3D91'>3. Legal Reasoning</h3>\n    <b>Issue:</b> Whether the described acts constitute a breach of the Convention.<br>\n    <b>Facts:</b> The applicant, Mr. Daniel Costa, is a Portuguese national residing in Lisbon. He alleged that his right to privacy under Article 8 of the Convention was violated when the local tax authorities accessed his bank transaction records during a corruption investigation.<br>\n    <b>Analysis:</b> Facts are compared to precedents (The applicant is an Italian national, born in 1937, and currently residing in Arienzo (Caserta). She is represented befo | The applicant was born in 1952 and lives in Wels. He worked as an official for the Austrian customs office. Apparently i); the similarity indicates same pattern of violation.<br>\n    <b>Conclusion:</b> Thus, reasoning supports 'Non-Violation'.<br><br>\n    <h3 style='color:#0B3D91'>4. Supporting Precedents</h3> The applicant is an Italian national, born in 1937, and currently residing in Arienzo (Caserta). She is represented before the Court by Mr Antonio Nardone and Mr Togo Verrilli, two lawyers practising in Benevento. The facts of the case, as submitted ...<br> The applicant was born in 1952 and lives in Wels. He worked as an official for the Austrian customs office. Apparently in 1998, suspicions of smuggling, bribery and abuse of authority arose against the applicant and one other person, W. On 29 January...<br> The applicant is an Italian national born in 1966 and currently residing in Rome. A. The facts of the case, as submitted by the parties, may be summarised as follows. On 4 January 1992, pending proceedings for the applicant's parents' judicial separa...<br><br><h3 style='color:#0B3D91'>5. Counter-Arguments</h3> <b>Lack of Causal Link</b>  The respondent may assert that the alleged act does not meet the threshold for Convention breach due to lack of proximate causal link.<br> <b>Domestic Remedies / Exhaustion</b>  The respondent can point to available domestic remedies not exhausted by the applicant, which may render the application inadmissible.<br> <b>Proportionality & Margin of Appreciation</b>  Even if interference occurred, the respondent may argue it fell within the State's margin of appreciation and was proportionate to a legitimate aim.<br>\n    <br><h3 style='color:#0B3D91'>6. Reflection Summary</h3>\n    Reasoning Quality: 0.87 | Confidence: 0.9<br>\n    No inconsistencies detected.<br><br>\n    <h3 style='color:#0B3D91'>7. Final Decision</h3>\n    <b>Outcome 'Non-Violation' accepted with confidence 0.90..</b><br><br>\n        <h3 style='color:#0B3D91'>8. LLMJudgeAgent Evaluation Summary</h3>\n        Avg Score: 0.64<br>\n        Scores: {\"Legal Accuracy\": 0.64, \"Logical Coherence\": 0.64, \"Ethical Soundness\": 0.64, \"Clarity of Reasoning\": 0.64}<br>\n        Advice: Non-Violation<br><br><p style='color:gray;text-align:center;font-size:0.9em'>Argumate 2.0  AI-Powered Legal Reasoning System</p></div>"
                },
                "metadata": {}
              },
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "\n",
                  " Reports saved:\n",
                  "- JSON: /content/drive/MyDrive/Argumate/results/final_outputs/argumate_report_20251113_115830.json\n",
                  "- TXT: /content/drive/MyDrive/Argumate/results/final_outputs/argumate_report_20251113_115830.txt\n",
                  "- HTML: /content/drive/MyDrive/Argumate/results/output_argumate_readable/argumate_report_20251113_115830.html\n",
                  "- PDF: /content/drive/MyDrive/Argumate/results/output_argumate_readable/argumate_report_20251113_115830.pdf\n"
                ]
              }
            ]
          }
        },
        "3ea94a2bcd084bdeb3f392c40d30411a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2d1a9415fc294ef79cd0895fd6be348c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7931dd1fb3b54874b2a7a90d51f665ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6be92dcc683445c081512697d5acc25b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": "220px",
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "98%"
          }
        },
        "ba2e09b2c44148bb890cd5de1421ff7b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b15c5d12a59d4c4abe105971f30393a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "success",
            "description": "Run Full Autonomous Pipeline",
            "disabled": false,
            "icon": "rocket",
            "layout": "IPY_MODEL_64c8219bb1274ae1aaa95f85699309ad",
            "style": "IPY_MODEL_95c36c2dc6794ba6b3cc7afa99267c77",
            "tooltip": ""
          }
        },
        "44fe45d28e3e4a3b88e7d47e333bc755": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c8f95a9b524c4e6d9c0ffa25215a4d55": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "primary",
            "description": "Start Auto Watcher",
            "disabled": false,
            "icon": "play",
            "layout": "IPY_MODEL_1dbdc379a26e4f93b239b35975ee721f",
            "style": "IPY_MODEL_d779d83bdca146dca8eb9422afc6189d",
            "tooltip": ""
          }
        },
        "816b727df5b846f8a72104a0af203d64": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "warning",
            "description": "Stop Auto Watcher",
            "disabled": false,
            "icon": "stop",
            "layout": "IPY_MODEL_b1f38013bc974de8998fab57ef84f824",
            "style": "IPY_MODEL_72cb7a2314224282bfc62c88c4866929",
            "tooltip": ""
          }
        },
        "fd5749683fb24e9389b4a6db618c11bc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "64c8219bb1274ae1aaa95f85699309ad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "95c36c2dc6794ba6b3cc7afa99267c77": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "1dbdc379a26e4f93b239b35975ee721f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d779d83bdca146dca8eb9422afc6189d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "b1f38013bc974de8998fab57ef84f824": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "72cb7a2314224282bfc62c88c4866929": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "a188f5c23fa84bc4906c13ffdcf20253": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": "1px solid black",
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": "600px",
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": "auto",
            "padding": "8px",
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}